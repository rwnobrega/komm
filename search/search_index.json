{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Komm","text":"<p>A Python library for communication systems.</p> <p>Komm is an open-source library for Python 3 providing tools for analysis and simulation of analog and digital communication systems. This project is inspired by many other communication systems libraries, such as MATLAB\u00ae Communications System Toolbox\u2122, GNU Radio, CommPy, and SageMath. Komm is licensed under the GNU General Public License v3.0.</p>"},{"location":"#quick-installation","title":"Quick Installation","text":"<pre><code>pip install komm\n</code></pre> <p>For more installation options and source code, please visit the project's development page.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>Check out our library reference for information on the classes and functions available.</p>"},{"location":"nav/","title":"Nav","text":"<ul> <li>Home</li> <li>Library reference</li> <li>Algebra<ul> <li>BinaryPolynomial</li> <li>BinaryPolynomialFraction</li> <li>FiniteBifield</li> </ul> </li> <li>Channels<ul> <li>AWGNChannel</li> <li>DiscreteMemorylessChannel</li> <li>BinarySymmetricChannel</li> <li>BinaryErasureChannel</li> <li>ZChannel</li> </ul> </li> <li>Error control<ul> <li>Block codes</li> <li>BlockCode</li> <li>SystematicBlockCode</li> <li>CyclicCode</li> <li>HammingCode</li> <li>SimplexCode</li> <li>GolayCode</li> <li>RepetitionCode</li> <li>SingleParityCheckCode</li> <li>CordaroWagnerCode</li> <li>ReedMullerCode</li> <li>BCHCode</li> <li>Lexicode</li> <li>PolarCode</li> <li>SlepianArray</li> <li>Convolutional codes</li> <li>ConvolutionalCode</li> <li>LowRateConvolutionalCode</li> <li>HighRateConvolutionalCode</li> <li>TerminatedConvolutionalCode</li> <li>ViterbiStreamDecoder</li> <li>Decoders</li> <li>BCJRDecoder</li> <li>BerlekampDecoder</li> <li>ExhaustiveSearchDecoder</li> <li>ReedDecoder</li> <li>SCDecoder</li> <li>SyndromeTableDecoder</li> <li>ViterbiDecoder</li> <li>WagnerDecoder</li> <li>Checksum</li> <li>CyclicRedundancyCheck</li> </ul> </li> <li>Finite-state machines<ul> <li>MooreMachine</li> <li>MealyMachine</li> </ul> </li> <li>Modulation<ul> <li>Modulation</li> <li>PAModulation</li> <li>QAModulation</li> <li>ASKModulation</li> <li>PSKModulation</li> <li>APSKModulation</li> </ul> </li> <li>Pulse formatting<ul> <li>Pulse</li> <li>RectangularPulse</li> <li>ManchesterPulse</li> <li>SincPulse</li> <li>RaisedCosinePulse</li> <li>RootRaisedCosinePulse</li> <li>GaussianPulse</li> </ul> </li> <li>Sequences<ul> <li>Binary sequences</li> <li>BinarySequence</li> <li>BarkerSequence</li> <li>WalshHadamardSequence</li> <li>LFSRSequence</li> <li>GoldSequence</li> <li>KasamiSequence</li> <li>Complex sequences</li> <li>ComplexSequence</li> <li>ZadoffChuSequence</li> </ul> </li> <li>Source coding<ul> <li>Lossless coding</li> <li>FixedToVariableCode</li> <li>ShannonCode</li> <li>FanoCode</li> <li>HuffmanCode</li> <li>VariableToFixedCode</li> <li>TunstallCode</li> <li>LempelZiv78Code</li> <li>LempelZivWelchCode</li> <li>Integer coding</li> <li>UnaryCode</li> <li>FibonacciCode</li> <li>Quantization</li> <li>ScalarQuantizer</li> <li>UniformQuantizer</li> <li>LloydMaxQuantizer</li> </ul> </li> <li>Sources<ul> <li>DiscreteMemorylessSource</li> </ul> </li> <li>Utilities<ul> <li>bits_to_int</li> <li>int_to_bits</li> <li>sampling_rate_compress</li> <li>sampling_rate_expand</li> <li>fourier_transform</li> <li>boxplus</li> <li>gaussian_q</li> <li>gaussian_q_inv</li> <li>marcum_q</li> <li>autocorrelation</li> <li>cyclic_autocorrelation</li> <li>entropy</li> <li>binary_entropy</li> <li>binary_entropy_inv</li> <li>relative_entropy</li> </ul> </li> </ul>"},{"location":"ref/","title":"Library reference","text":""},{"location":"ref/#algebra","title":"Algebra","text":"<ul> <li><code>BinaryPolynomial</code> \u2013 Binary polynomial.</li> <li><code>BinaryPolynomialFraction</code> \u2013 Binary polynomial fraction.</li> <li><code>FiniteBifield</code> \u2013 Finite field with binary characteristic.</li> </ul>"},{"location":"ref/#channels","title":"Channels","text":"<ul> <li><code>AWGNChannel</code> \u2013 Additive white Gaussian noise (AWGN) channel.</li> <li><code>DiscreteMemorylessChannel</code> \u2013 General discrete memoryless channel (DMC).</li> <li><code>BinarySymmetricChannel</code> \u2013 Binary symmetric channel (BSC).</li> <li><code>BinaryErasureChannel</code> \u2013 Binary erasure channel (BEC).</li> <li><code>ZChannel</code> \u2013 Z-channel.</li> </ul>"},{"location":"ref/#error-control","title":"Error control","text":""},{"location":"ref/#block-codes","title":"Block codes","text":"<ul> <li><code>BlockCode</code> \u2013 General binary linear block code.</li> <li><code>SystematicBlockCode</code> \u2013 Systematic linear block code.</li> <li><code>CyclicCode</code> \u2013 General binary cyclic code.</li> <li><code>HammingCode</code> \u2013 Hamming code.</li> <li><code>SimplexCode</code> \u2013 Simplex (maximum-length) code.</li> <li><code>GolayCode</code> \u2013 Binary Golay code.</li> <li><code>RepetitionCode</code> \u2013 Repetition code.</li> <li><code>SingleParityCheckCode</code> \u2013 Single parity-check code.</li> <li><code>CordaroWagnerCode</code> \u2013 Cordaro\u2013Wagner code.</li> <li><code>ReedMullerCode</code> \u2013 Reed\u2013Muller code.</li> <li><code>BCHCode</code> \u2013 Bose\u2013Ray-Chaudhuri\u2013Hocquenghem (BCH) code.</li> <li><code>Lexicode</code> \u2013 Lexicographic code (lexicode).</li> <li><code>PolarCode</code> \u2013 Polar (Ar\u0131kan) code.</li> <li><code>SlepianArray</code> \u2013 Slepian array (standard array) for a linear block code.</li> </ul>"},{"location":"ref/#convolutional-codes","title":"Convolutional codes","text":"<ul> <li><code>ConvolutionalCode</code> \u2013 Binary convolutional encoder.</li> <li><code>LowRateConvolutionalCode</code> \u2013 Low-rate convolutional encoder.</li> <li><code>HighRateConvolutionalCode</code> \u2013 High-rate convolutional encoder.</li> <li><code>TerminatedConvolutionalCode</code> \u2013 Terminated convolutional code.</li> <li><code>ViterbiStreamDecoder</code> \u2013 Convolutional stream decoder using Viterbi algorithm.</li> </ul>"},{"location":"ref/#decoders","title":"Decoders","text":"<ul> <li><code>BCJRDecoder</code> \u2013 Bahl\u2013Cocke\u2013Jelinek\u2013Raviv (BCJR) decoder for terminated convolutional codes.</li> <li><code>BerlekampDecoder</code> \u2013 Berlekamp decoder for BCH codes.</li> <li><code>ExhaustiveSearchDecoder</code> \u2013 Exhaustive search decoder for general block codes.</li> <li><code>ReedDecoder</code> \u2013 Reed decoder for Reed-Muller codes.</li> <li><code>SCDecoder</code> \u2013 Successive cancellation decoder for Polar codes.</li> <li><code>SyndromeTableDecoder</code> \u2013 Syndrome table decoder for general block codes.</li> <li><code>ViterbiDecoder</code> \u2013 Viterbi decoder for terminated convolutional codes.</li> <li><code>WagnerDecoder</code> \u2013 Wagner decoder for single parity-check codes.</li> </ul>"},{"location":"ref/#checksum","title":"Checksum","text":"<ul> <li><code>CyclicRedundancyCheck</code> \u2013 Cyclic redundancy check (CRC) [Not implemented yet].</li> </ul>"},{"location":"ref/#finite-state-machines","title":"Finite-state machines","text":"<ul> <li><code>MooreMachine</code> \u2013 Finite-state Moore machine.</li> <li><code>MealyMachine</code> \u2013 Finite-state Mealy machine.</li> </ul>"},{"location":"ref/#modulation","title":"Modulation","text":"<ul> <li><code>Modulation</code> \u2013 General modulation scheme.</li> <li><code>PAModulation</code> \u2013 Pulse-amplitude modulation (PAM).</li> <li><code>QAModulation</code> \u2013 Quadrature-amplitude modulation (QAM).</li> <li><code>ASKModulation</code> \u2013 Amplitude-shift keying (ASK) modulation.</li> <li><code>PSKModulation</code> \u2013 Phase-shift keying (PSK) modulation.</li> <li><code>APSKModulation</code> \u2013 Amplitude- and phase-shift keying (APSK) modulation.</li> </ul>"},{"location":"ref/#pulse-formatting","title":"Pulse formatting","text":"<ul> <li><code>Pulse</code> \u2013 General pulse [Not implemented yet].</li> <li><code>RectangularPulse</code> \u2013 Rectangular pulse.</li> <li><code>ManchesterPulse</code> \u2013 Manchester pulse.</li> <li><code>SincPulse</code> \u2013 Sinc pulse.</li> <li><code>RaisedCosinePulse</code> \u2013 Raised-cosine pulse.</li> <li><code>RootRaisedCosinePulse</code> \u2013 Root-raised-cosine pulse.</li> <li><code>GaussianPulse</code> \u2013 Gaussian pulse.</li> </ul>"},{"location":"ref/#sequences","title":"Sequences","text":""},{"location":"ref/#binary-sequences","title":"Binary sequences","text":"<ul> <li><code>BinarySequence</code> \u2013 General binary sequence.</li> <li><code>BarkerSequence</code> \u2013 Barker sequence.</li> <li><code>WalshHadamardSequence</code> \u2013 Walsh\u2013Hadamard sequence.</li> <li><code>LFSRSequence</code> \u2013 Linear-feedback shift register (LFSR) sequence.</li> <li><code>GoldSequence</code> \u2013 Gold sequence [Not implemented yet].</li> <li><code>KasamiSequence</code> \u2013 Kasami sequence [Not implemented yet].</li> </ul>"},{"location":"ref/#complex-sequences","title":"Complex sequences","text":"<ul> <li><code>ComplexSequence</code> \u2013 General complex sequence.</li> <li><code>ZadoffChuSequence</code> \u2013 Zadoff\u2013Chu sequence.</li> </ul>"},{"location":"ref/#source-coding","title":"Source coding","text":""},{"location":"ref/#lossless-coding","title":"Lossless coding","text":"<ul> <li><code>FixedToVariableCode</code> \u2013 General fixed-to-variable length code.</li> <li><code>ShannonCode</code> \u2013 Binary Shannon code.</li> <li><code>FanoCode</code> \u2013 Binary Fano code.</li> <li><code>HuffmanCode</code> \u2013 Binary Huffman code.</li> <li><code>VariableToFixedCode</code> \u2013 General variable-to-fixed length code.</li> <li><code>TunstallCode</code> \u2013 Binary Tunstall code.</li> <li><code>LempelZiv78Code</code> \u2013 Lempel\u2013Ziv 78 (LZ78 or LZ2) code.</li> <li><code>LempelZivWelchCode</code> \u2013 Lempel\u2013Ziv\u2013Welch (LZW) code.</li> </ul>"},{"location":"ref/#integer-coding","title":"Integer coding","text":"<ul> <li><code>UnaryCode</code> \u2013 Unary code.</li> <li><code>FibonacciCode</code> \u2013 Fibonacci code.</li> </ul>"},{"location":"ref/#quantization","title":"Quantization","text":"<ul> <li><code>ScalarQuantizer</code> \u2013 General scalar quantizer.</li> <li><code>UniformQuantizer</code> \u2013 Uniform scalar quantizer.</li> <li><code>LloydMaxQuantizer</code> \u2013 Lloyd\u2013Max scalar quantizer.</li> </ul>"},{"location":"ref/#sources","title":"Sources","text":"<ul> <li><code>DiscreteMemorylessSource</code> \u2013 Discrete memoryless source (DMS).</li> </ul>"},{"location":"ref/#utilities","title":"Utilities","text":"<ul> <li><code>bits_to_int</code> \u2013 Converts a bit array to its integer representation (LSB first).</li> <li><code>int_to_bits</code> \u2013 Converts an integer, or array of integers, to their bit representations (LSB first).</li> <li><code>sampling_rate_compress</code> \u2013 Performs sampling rate compression (downsampling).</li> <li><code>sampling_rate_expand</code> \u2013 Performs sampling rate expansion (upsampling).</li> <li><code>fourier_transform</code> \u2013 Computes the Fourier transform.</li> <li><code>boxplus</code> \u2013 Computes the box-plus operation.</li> <li><code>gaussian_q</code> \u2013 Computes the Gaussian Q-function.</li> <li><code>gaussian_q_inv</code> \u2013 Computes the inverse Gaussian Q-function.</li> <li><code>marcum_q</code> \u2013 Computes the Marcum Q-function.</li> <li><code>autocorrelation</code> \u2013 Computes the autocorrelation $R[\\ell]$ of a real or complex sequence $x[n]$.</li> <li><code>cyclic_autocorrelation</code> \u2013 Computes the cyclic autocorrelation $\\tilde{R}[\\ell]$ of a real or complex sequence $x[n]$.</li> <li><code>entropy</code> \u2013 Computes the entropy of a random variable with a given pmf.</li> <li><code>binary_entropy</code> \u2013 Computes the binary entropy function.</li> <li><code>binary_entropy_inv</code> \u2013 Computes the inverse of the binary entropy function.</li> <li><code>relative_entropy</code> \u2013 Computes the relative entropy (Kullback\u2013Leibler divergence) between two pmfs.</li> </ul>"},{"location":"ref/APSKModulation/","title":"komm.APSKModulation","text":"<p>Amplitude- and phase-shift keying (APSK) modulation. It is a complex modulation scheme in which the constellation is the union (concatenation) of component PSK constellations, called rings. More precisely, consider $K$ rings $\\mathbf{X}_k$, for $k \\in [0 : K)$, where the $k$-th ring has order $M_k$, amplitude $A_k$, and phase offset $\\phi_k$. The $i$-th constellation symbol of the $k$-th ring is given by $$     x_{k,i} = A_k \\exp \\left( \\mathrm{j} \\frac{2 \\pi i}{M_k} \\right) \\exp(\\mathrm{j} \\phi_k),     \\quad k \\in [0 : K),     \\quad i \\in [0 : M_k). $$ The resulting APSK constellation is therefore given by $$     \\mathbf{X} = \\begin{bmatrix}         \\mathbf{X}_0 \\\\         \\vdots \\\\         \\mathbf{X}_{K-1}     \\end{bmatrix}, $$ which has order $M = M_0 + M_1 + \\cdots + M_{K-1}$. The order $M_k$ of each ring need not be a power of $2$; however, the order $M$ of the constructed APSK modulation must be.</p> <p>Parameters:</p> <ul> <li> <code>orders</code> (<code>tuple[int, ...]</code>)         \u2013          <p>A $K$-tuple with the orders $M_k$ of each ring, for $k \\in [0 : K)$. The sum $M_0 + M_1 + \\cdots + M_{K-1}$ must be a power of $2$.</p> </li> <li> <code>amplitudes</code> (<code>tuple[float, ...]</code>)         \u2013          <p>A $K$-tuple with the amplitudes $A_k$ of each ring, for $k \\in [0 : K)$.</p> </li> <li> <code>phase_offsets</code> (<code>float | tuple[float, ...]</code>)         \u2013          <p>A $K$-tuple with the phase offsets $\\phi_k$ of each ring, for $k \\in [0 : K)$. If specified as a single float $\\phi$, then it is assumed that $\\phi_k = \\phi$ for all $k \\in [0 : K)$. The default value is <code>0.0</code>.</p> </li> <li> <code>labeling</code> (<code>Literal['natural'] | ArrayLike</code>)         \u2013          <p>The binary labeling of the modulation. Can be specified either as a 2D-array of integers (see base class for details), or as a string. In the latter case, the string must be equal to <code>'natural'</code>. The default value is <code>'natural'</code>.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>The $8$-APSK modulation with $(M_0, M_1) = (4, 4)$, $(A_0, A_1) = (1, 2)$, and $(\\phi_0, \\phi_1) = (0, 0)$ is depicted below.      </p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.constellation\narray([ 1.+0.j,  0.+1.j, -1.+0.j, -0.-1.j,\n        2.+0.j,  0.+2.j, -2.+0.j, -0.-2.j])\n</code></pre> </li> <li> <p>The $16$-APSK modulation with $(M_0, M_1) = (8, 8)$, $(A_0, A_1) = (1, 2)$, and $(\\phi_0, \\phi_1) = (0, \\pi/8)$ is depicted below.      </p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(\n...     orders=(8, 8),\n...     amplitudes=(1.0, 2.0),\n...     phase_offsets=(0.0, np.pi/8)\n... )\n&gt;&gt;&gt; apsk.constellation.round(3)\narray([ 1.   +0.j   ,  0.707+0.707j,  0.   +1.j   , -0.707+0.707j,\n       -1.   +0.j   , -0.707-0.707j, -0.   -1.j   ,  0.707-0.707j,\n        1.848+0.765j,  0.765+1.848j, -0.765+1.848j, -1.848+0.765j,\n       -1.848-0.765j, -0.765-1.848j,  0.765-1.848j,  1.848-0.765j])\n</code></pre> </li> <li> <p>The $16$-APSK modulation with $(M_0, M_1) = (4, 12)$, $(A_0, A_1) = (\\sqrt{2}, 3)$, and $(\\phi_0, \\phi_1) = (\\pi/4, 0)$ is depicted below.      </p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(\n...     orders=(4, 12),\n...     amplitudes=(np.sqrt(2), 3.0),\n...     phase_offsets=(np.pi/4, 0.0)\n... )\n&gt;&gt;&gt; apsk.constellation.round(3)\narray([ 1.   +1.j   , -1.   +1.j   , -1.   -1.j   ,  1.   -1.j   ,\n        3.   +0.j   ,  2.598+1.5j  ,  1.5  +2.598j,  0.   +3.j   ,\n       -1.5  +2.598j, -2.598+1.5j  , -3.   +0.j   , -2.598-1.5j  ,\n       -1.5  -2.598j, -0.   -3.j   ,  1.5  -2.598j,  2.598-1.5j  ])\n</code></pre> </li> </ol>"},{"location":"ref/APSKModulation/#constellation","title":"<code>constellation</code><code>  Array1D[complexfloating] </code>  <code>cached</code> <code>property</code>","text":"<p>The constellation $\\mathbf{X}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.constellation\narray([ 1.+0.j,  0.+1.j, -1.+0.j, -0.-1.j,\n        2.+0.j,  0.+2.j, -2.+0.j, -0.-2.j])\n</code></pre>"},{"location":"ref/APSKModulation/#labeling","title":"<code>labeling</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The labeling $\\mathbf{Q}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.labeling\narray([[0, 0, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 1, 1],\n       [1, 0, 0],\n       [1, 0, 1],\n       [1, 1, 0],\n       [1, 1, 1]])\n</code></pre>"},{"location":"ref/APSKModulation/#inverse_labeling","title":"<code>inverse_labeling</code><code>  dict[tuple[int, ...], int] </code>  <code>cached</code> <code>property</code>","text":"<p>The inverse labeling of the modulation. It is a dictionary that maps each binary tuple to the corresponding constellation index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.inverse_labeling\n{(0, 0, 0): 0,\n (0, 0, 1): 1,\n (0, 1, 0): 2,\n (0, 1, 1): 3,\n (1, 0, 0): 4,\n (1, 0, 1): 5,\n (1, 1, 0): 6,\n (1, 1, 1): 7}\n</code></pre>"},{"location":"ref/APSKModulation/#order","title":"<code>order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The order $M$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.order\n8\n</code></pre>"},{"location":"ref/APSKModulation/#bits_per_symbol","title":"<code>bits_per_symbol</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number $m$ of bits per symbol of the modulation. It is given by $$     m = \\log_2 M, $$ where $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.bits_per_symbol\n3\n</code></pre>"},{"location":"ref/APSKModulation/#energy_per_symbol","title":"<code>energy_per_symbol</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average symbol energy $E_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   E_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} \\lVert x_i \\rVert^2, $$ where $\\lVert x_i \\rVert^2$ is the energy of constellation symbol $x_i$, and $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.energy_per_symbol\n2.5\n</code></pre>"},{"location":"ref/APSKModulation/#energy_per_bit","title":"<code>energy_per_bit</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average bit energy $E_\\mathrm{b}$ of the constellation. It assumes equiprobable symbols. It is given by $$     E_\\mathrm{b} = \\frac{E_\\mathrm{s}}{m}, $$ where $E_\\mathrm{s}$ is the average symbol energy, and $m$ is the number of bits per symbol of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.energy_per_bit\n0.8333333333333334\n</code></pre>"},{"location":"ref/APSKModulation/#symbol_mean","title":"<code>symbol_mean</code><code>  complex </code>  <code>cached</code> <code>property</code>","text":"<p>The mean $\\mu_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   \\mu_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} x_i. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.symbol_mean\n0j\n</code></pre>"},{"location":"ref/APSKModulation/#minimum_distance","title":"<code>minimum_distance</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The minimum Euclidean distance $d_\\mathrm{min}$ of the constellation. It is given by $$     d_\\mathrm{min} = \\min_ { i, j \\in [0:M), ~ i \\neq j } \\lVert x_i - x_j \\rVert. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.minimum_distance\n1.0\n</code></pre>"},{"location":"ref/APSKModulation/#modulate","title":"<code>modulate()</code>","text":"<p>Modulates one or more sequences of bits to their corresponding constellation symbols.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $m$, or a multidimensional array where the last dimension is a multiple of $m$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[complexfloating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension divided by $m$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apsk = komm.APSKModulation(orders=(4, 4), amplitudes=(1.0, 2.0))\n&gt;&gt;&gt; apsk.modulate([0, 0, 0, 0, 1, 1, 0, 0, 0])\narray([ 1.+0.j, -0.-1.j,  1.+0.j])\n</code></pre>"},{"location":"ref/APSKModulation/#demodulate_hard","title":"<code>demodulate_hard()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of hard bits ($\\mathtt{0}$ or $\\mathtt{1}$) using hard-decision decoding.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/APSKModulation/#demodulate_soft","title":"<code>demodulate_soft()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of soft bits (L-values) using soft-decision decoding. The soft bits are the log-likelihood ratios of the bits, where positive values correspond to bit $\\mathtt{0}$ and negative values correspond to bit $\\mathtt{1}$.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The received sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> <li> <code>snr</code> (<code>float</code>)         \u2013          <p>The signal-to-noise ratio (SNR) of the channel. It should be a positive real number. The default value is <code>1.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/ASKModulation/","title":"komm.ASKModulation","text":"<p>Amplitude-shift keying (ASK) modulation. It is a complex modulation scheme in which the points of the constellation symbols are uniformly arranged in a ray. More precisely, the $i$-th constellation symbol is given by $$     x_i = iA \\exp(\\mathrm{j}\\phi), \\quad i \\in [0 : M), $$ where $M$ is the order (a power of $2$), $A$ is the base amplitude, and $\\phi$ is the phase offset of the modulation.</p> <p>Parameters:</p> <ul> <li> <code>order</code> (<code>int</code>)         \u2013          <p>The order $M$ of the modulation. It must be a power of $2$.</p> </li> <li> <code>base_amplitude</code> (<code>float</code>)         \u2013          <p>The base amplitude $A$ of the constellation. The default value is <code>1.0</code>.</p> </li> <li> <code>phase_offset</code> (<code>float</code>)         \u2013          <p>The phase offset $\\phi$ of the constellation. The default value is <code>0.0</code>.</p> </li> <li> <code>labeling</code> (<code>Literal['natural', 'reflected'] | ArrayLike</code>)         \u2013          <p>The binary labeling of the modulation. Can be specified either as a 2D-array of integers (see base class for details), or as a string. In the latter case, the string must be either <code>'natural'</code> or <code>'reflected'</code>. The default value is <code>'reflected'</code>, corresponding to the Gray labeling.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>The $4$-ASK modulation with base amplitude $A = 1$, phase offset $\\phi = 0$, and Gray labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.constellation\narray([0.+0.j, 1.+0.j, 2.+0.j, 3.+0.j])\n&gt;&gt;&gt; ask.labeling\narray([[0, 0],\n       [0, 1],\n       [1, 1],\n       [1, 0]])\n</code></pre> </li> <li> <p>The $4$-ASK modulation with base amplitude $A = 2\\sqrt{2}$, phase offset $\\phi = \\pi/4$, and natural labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(\n...     order=4,\n...     base_amplitude=2*np.sqrt(2),\n...     phase_offset=np.pi/4,\n...     labeling='natural',\n... )\n&gt;&gt;&gt; ask.constellation\narray([0.+0.j, 2.+2.j, 4.+4.j, 6.+6.j])\n&gt;&gt;&gt; ask.labeling\narray([[0, 0],\n       [0, 1],\n       [1, 0],\n       [1, 1]])\n</code></pre> </li> </ol>"},{"location":"ref/ASKModulation/#constellation","title":"<code>constellation</code><code>  Array1D[complexfloating] </code>  <code>cached</code> <code>property</code>","text":"<p>The constellation $\\mathbf{X}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.constellation\narray([0.+0.j, 1.+0.j, 2.+0.j, 3.+0.j])\n</code></pre>"},{"location":"ref/ASKModulation/#labeling","title":"<code>labeling</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The labeling $\\mathbf{Q}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.labeling\narray([[0, 0],\n       [0, 1],\n       [1, 1],\n       [1, 0]])\n</code></pre>"},{"location":"ref/ASKModulation/#inverse_labeling","title":"<code>inverse_labeling</code><code>  dict[tuple[int, ...], int] </code>  <code>cached</code> <code>property</code>","text":"<p>The inverse labeling of the modulation. It is a dictionary that maps each binary tuple to the corresponding constellation index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.inverse_labeling\n{(0, 0): 0, (0, 1): 1, (1, 1): 2, (1, 0): 3}\n</code></pre>"},{"location":"ref/ASKModulation/#order","title":"<code>order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The order $M$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.order\n4\n</code></pre>"},{"location":"ref/ASKModulation/#bits_per_symbol","title":"<code>bits_per_symbol</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number $m$ of bits per symbol of the modulation. It is given by $$     m = \\log_2 M, $$ where $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.bits_per_symbol\n2\n</code></pre>"},{"location":"ref/ASKModulation/#energy_per_symbol","title":"<code>energy_per_symbol</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average symbol energy $E_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   E_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} \\lVert x_i \\rVert^2, $$ where $\\lVert x_i \\rVert^2$ is the energy of constellation symbol $x_i$, and $M$ is the order of the modulation.</p> <p>For the ASK, it is given by $$     E_\\mathrm{s} = \\frac{A^2}{6} (M - 1) (2M - 1). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.energy_per_symbol\n3.5\n</code></pre>"},{"location":"ref/ASKModulation/#energy_per_bit","title":"<code>energy_per_bit</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average bit energy $E_\\mathrm{b}$ of the constellation. It assumes equiprobable symbols. It is given by $$     E_\\mathrm{b} = \\frac{E_\\mathrm{s}}{m}, $$ where $E_\\mathrm{s}$ is the average symbol energy, and $m$ is the number of bits per symbol of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.energy_per_bit\n1.75\n</code></pre>"},{"location":"ref/ASKModulation/#symbol_mean","title":"<code>symbol_mean</code><code>  complex </code>  <code>cached</code> <code>property</code>","text":"<p>The mean $\\mu_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   \\mu_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} x_i. $$</p> <p>For the ASK, it is given by $$     \\mu_\\mathrm{s} = \\frac{A}{2} (M-1) \\exp(\\mathrm{j}\\phi). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.symbol_mean\n(1.5+0j)\n</code></pre>"},{"location":"ref/ASKModulation/#minimum_distance","title":"<code>minimum_distance</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The minimum Euclidean distance $d_\\mathrm{min}$ of the constellation. It is given by $$     d_\\mathrm{min} = \\min_ { i, j \\in [0:M), ~ i \\neq j } \\lVert x_i - x_j \\rVert. $$</p> <p>For the ASK, it is given by $$     d_\\mathrm{min} = A. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.minimum_distance\n1.0\n</code></pre>"},{"location":"ref/ASKModulation/#modulate","title":"<code>modulate()</code>","text":"<p>Modulates one or more sequences of bits to their corresponding constellation symbols.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $m$, or a multidimensional array where the last dimension is a multiple of $m$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[complexfloating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension divided by $m$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ask = komm.ASKModulation(4)\n&gt;&gt;&gt; ask.modulate([0, 0, 1, 1, 0, 0, 0, 1])\narray([0.+0.j, 2.+0.j, 0.+0.j, 1.+0.j])\n</code></pre>"},{"location":"ref/ASKModulation/#demodulate_hard","title":"<code>demodulate_hard()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of hard bits ($\\mathtt{0}$ or $\\mathtt{1}$) using hard-decision decoding.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/ASKModulation/#demodulate_soft","title":"<code>demodulate_soft()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of soft bits (L-values) using soft-decision decoding. The soft bits are the log-likelihood ratios of the bits, where positive values correspond to bit $\\mathtt{0}$ and negative values correspond to bit $\\mathtt{1}$.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The received sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> <li> <code>snr</code> (<code>float</code>)         \u2013          <p>The signal-to-noise ratio (SNR) of the channel. It should be a positive real number. The default value is <code>1.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/AWGNChannel/","title":"komm.AWGNChannel","text":"<p>Additive white Gaussian noise (AWGN) channel. It is defined by $$     Y_n = X_n + Z_n, $$ where $X_n$ is the channel input signal, $Y_n$ is the channel output signal, and $Z_n$ is the noise, which is iid according to a Gaussian distribution with zero mean. The channel signal-to-noise ratio is calculated by $$     \\snr = \\frac{P}{N}, $$ where $P = \\mathrm{E}[X^2_n]$ is the average power of the input signal, and $N = \\mathrm{E}[Z^2_n]$ is the average power (and variance) of the noise. For more details, see CT06, Ch. 9.</p> <p>Parameters:</p> <ul> <li> <code>signal_power</code> (<code>float | Literal['measured']</code>)         \u2013          <p>The input signal power $P$. If equal to the string <code>'measured'</code>, then every time the channel is invoked the input signal power will be computed from the input itself (i.e., its squared Euclidean norm).</p> </li> <li> <code>snr</code> (<code>float</code>)         \u2013          <p>The channel signal-to-noise ratio $\\snr$ (linear, not decibel). The default value is <code>np.inf</code>, which corresponds to a noiseless channel.</p> </li> </ul>"},{"location":"ref/AWGNChannel/#noise_power","title":"<code>noise_power</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The noise power $N$.</p>"},{"location":"ref/AWGNChannel/#capacity","title":"<code>capacity()</code>","text":"<p>Returns the channel capacity $C$. It is given by $C = \\frac{1}{2}\\log_2(1 + \\snr)$, in bits per dimension.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; awgn = komm.AWGNChannel(signal_power=1.0, snr=63.0)\n&gt;&gt;&gt; awgn.capacity()\nnp.float64(3.0)\n</code></pre>"},{"location":"ref/AWGNChannel/#__call__","title":"<code>__call__()</code>","text":"<p>Transmits the input signal through the channel and returns the output signal.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input signal $X_n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output signal $Y_n$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; awgn = komm.AWGNChannel(signal_power=5.0, snr=200.0)\n&gt;&gt;&gt; x = [1.0, 3.0, -3.0, -1.0, -1.0, 1.0, 3.0, 1.0, -1.0, 3.0]\n&gt;&gt;&gt; awgn(x).round(2)\narray([ 1.05,  2.84, -2.88, -0.85, -1.31,  0.79,  3.02,  0.95, -1.  ,  2.87])\n</code></pre>"},{"location":"ref/BCHCode/","title":"komm.BCHCode","text":"<p>Bose\u2013Ray-Chaudhuri\u2013Hocquenghem (BCH) code. For given parameters $\\mu \\geq 2$ and $\\delta$ satisfying $2 \\leq \\delta \\leq 2^{\\mu} - 1$, a binary BCH code is a cyclic code with generator polynomial given by $$     g(X) = \\mathrm{lcm} \\left\\{ \\phi_1(X), \\phi_2(X), \\ldots, \\phi_{\\delta - 1}(X) \\right\\}, $$ where $\\phi_i(X)$ is the minimal polynomial of $\\alpha^i$, and $\\alpha$ is a primitive element of $\\mathrm{GF}(2^\\mu)$. The parameter $\\delta$ must be a Bose distance. The resulting code is denoted by $\\bch(\\mu, \\delta)$, and has the following parameters, where $\\delta = 2 \\tau + 1$:</p> <ul> <li>Length: $n = 2^{\\mu} - 1$</li> <li>Dimension: $k \\geq n - \\mu \\tau$</li> <li>Redundancy: $m \\leq \\mu \\tau$</li> <li>Minimum distance: $d \\geq \\delta$</li> </ul> <p>Only narrow-sense and primitive BCH codes are implemented. For more details, see LC04, Ch. 6 and HP03, Sec. 5.1.</p> <p>The table below lists the possible values of $\\delta$ for $2 \\leq \\mu \\leq 10$.</p> $\\mu$ $n$ Bose distances $\\delta$ $2$ $3$ $3$ $3$ $7$ $3$, $7$ $4$ $15$ $3$, $5$, $7$, $15$ $5$ $31$ $3$, $5$, $7$, $11$, $15$, $31$ $6$ $63$ $3$, $5$, $7$, $9$, $11$, $13$, $15$, $21$, $23$, $27$, $31$, $63$ $7$ $127$ $3$, $5$, $7$, $9$, $11$, $13$, $15$, $19$, $21$, $23$, $27$, $29$, $31$, $43$, $47$, $55$, $63$, $127$ $8$ $255$ $3$, $5$, $7$, $9$, $11$, $13$, $15$, $17$, $19$, $21$, $23$, $25$, $27$, $29$, $31$, $37$, $39$, $43$, $45$, $47$, $51$, $53$, $55$, $59$, $61$, $63$, $85$, $87$, $91$, $95$, $111$, $119$, $127$, $255$ $9$ $511$ $3$, $5$, $7$, $9$, $11$, $13$, $15$, $17$, $19$, $21$, $23$, $25$, $27$, $29$, $31$, $35$, $37$, $39$, $41$, $43$, $45$, $47$, $51$, $53$, $55$, $57$, $59$, $61$, $63$, $73$, $75$, $77$, $79$, $83$, $85$, $87$, $91$, $93$, $95$, $103$, $107$, $109$, $111$, $117$, $119$, $123$, $125$, $127$, $171$, $175$, $183$, $187$, $191$, $219$, $223$, $239$, $255$, $511$ $10$ $1023$ $3$, $5$, $7$, $9$, $11$, $13$, $15$, $17$, $19$, $21$, $23$, $25$, $27$, $29$, $31$, $33$, $35$, $37$, $39$, $41$, $43$, $45$, $47$, $49$, $51$, $53$, $55$, $57$, $59$, $61$, $63$, $69$, $71$, $73$, $75$, $77$, $79$, $83$, $85$, $87$, $89$, $91$, $93$, $95$, $99$, $101$, $103$, $105$, $107$, $109$, $111$, $115$, $117$, $119$, $121$, $123$, $125$, $127$, $147$, $149$, $151$, $155$, $157$, $159$, $165$, $167$, $171$, $173$, $175$, $179$, $181$, $183$, $187$, $189$, $191$, $205$, $207$, $213$, $215$, $219$, $221$, $223$, $231$, $235$, $237$, $239$, $245$, $247$, $251$, $253$, $255$, $341$, $343$, $347$, $351$, $363$, $367$, $375$, $379$, $383$, $439$, $447$, $479$, $495$, $511$, $1023$ Notes <ul> <li>For $\\delta = 3$ it reduces to the Hamming code.</li> <li>For $\\delta = 2^{\\mu} - 1$ it reduces to the repetition code.</li> </ul> <p>Parameters:</p> <ul> <li> <code>mu</code> (<code>int</code>)         \u2013          <p>The parameter $\\mu$ of the BCH code.</p> </li> <li> <code>delta</code> (<code>int</code>)         \u2013          <p>The Bose distance $\\delta$ of the BCH code.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BCHCode(mu=5, delta=7)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(31, 16, 15)\n&gt;&gt;&gt; code.generator_polynomial\nBinaryPolynomial(0b1000111110101111)\n&gt;&gt;&gt; code.minimum_distance()\n7\n</code></pre> <pre><code>&gt;&gt;&gt; komm.BCHCode(mu=7, delta=31)\nBCHCode(mu=7, delta=31)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.BCHCode(mu=7, delta=32)\nTraceback (most recent call last):\n...\nValueError: 'delta' must be a Bose distance (next one is 43)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.BCHCode(mu=7, delta=43)\nBCHCode(mu=7, delta=43)\n</code></pre>"},{"location":"ref/BCJRDecoder/","title":"komm.BCJRDecoder","text":"<p>Bahl\u2013Cocke\u2013Jelinek\u2013Raviv (BCJR) decoder for terminated convolutional codes. For more details, see LC04, Sec. 12.6.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>TerminatedConvolutionalCode</code>)         \u2013          <p>The terminated convolutional code to be used for decoding.</p> </li> <li> <code>output_type</code> (<code>Literal['hard', 'soft']</code>)         \u2013          <p>The type of the output. Either <code>'hard'</code> or <code>'soft'</code>. Default is <code>'soft'</code>.</p> </li> </ul> Notes <ul> <li>Input type: <code>soft</code> (L-values).</li> <li>Output type: <code>hard</code> (bits) or <code>soft</code> (L-values).</li> </ul>"},{"location":"ref/BCJRDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; convolutional_code = komm.ConvolutionalCode(\n...     feedforward_polynomials=[[0b11, 0b1]],\n...     feedback_polynomials=[0b11],\n... )\n&gt;&gt;&gt; code = komm.TerminatedConvolutionalCode(\n...     convolutional_code,\n...     num_blocks=3,\n...     mode=\"zero-termination\",\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; decoder = komm.BCJRDecoder(code)\n&gt;&gt;&gt; decoder([-0.8, -0.1, -1.0, +0.5, +1.8, -1.1, -1.6, +1.6])\narray([-0.47774884, -0.61545527,  1.03018771])\n</code></pre> <pre><code>&gt;&gt;&gt; decoder = komm.BCJRDecoder(code, output_type=\"hard\")\n&gt;&gt;&gt; decoder([-0.8, -0.1, -1.0, +0.5, +1.8, -1.1, -1.6, +1.6])\narray([1, 1, 0])\n</code></pre>"},{"location":"ref/BarkerSequence/","title":"komm.BarkerSequence","text":"<p>Barker sequence. A Barker sequence is a binary sequence with autocorrelation $R[\\ell]$ satisfying $|R[\\ell]| \\leq 1$, for $\\ell \\neq 0$. The only known Barker sequences (up to negation and reversion) are shown in the table below. For more details, see Wikipedia: Barker code.</p> Length $L$ Barker sequence $b[n]$ $2$ $01$ and $00$ $3$ $001$ $4$ $0010$ and $0001$ $5$ $00010$ $7$ $0001101$ $11$ $00011101101$ $13$ $0000011001010$ <p>Parameters:</p> <ul> <li> <code>length</code> (<code>int</code>)         \u2013          <p>Length of the Barker sequence. Must be in the set $\\{ 2, 3, 4, 5, 7, 11, 13 \\}$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; barker = komm.BarkerSequence(length=13)\n&gt;&gt;&gt; barker.polar_sequence\narray([ 1,  1,  1,  1,  1, -1, -1,  1,  1, -1,  1, -1,  1])\n&gt;&gt;&gt; barker.autocorrelation()\narray([13,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1])\n</code></pre>"},{"location":"ref/BerlekampDecoder/","title":"komm.BerlekampDecoder","text":"<p>Berlekamp decoder for BCH codes. For more details, see LC04, Sec. 6.3.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>BCHCode</code>)         \u2013          <p>The BCH code to be used for decoding.</p> </li> </ul> Notes <ul> <li>Input type: <code>hard</code> (bits).</li> <li>Output type: <code>hard</code> (bits).</li> </ul>"},{"location":"ref/BerlekampDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BCHCode(4, 7)\n&gt;&gt;&gt; decoder = komm.BerlekampDecoder(code)\n&gt;&gt;&gt; decoder([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])\narray([0, 0, 0, 0, 0])\n</code></pre>"},{"location":"ref/BinaryErasureChannel/","title":"komm.BinaryErasureChannel","text":"<p>Binary erasure channel (BEC). It is a discrete memoryless channel with input alphabet $\\mathcal{X} = \\{ 0, 1 \\}$ and output alphabet $\\mathcal{Y} = \\{ 0, 1, 2 \\}$. The channel is characterized by a parameter $\\epsilon$, called the erasure probability. With probability $1 - \\epsilon$, the output symbol is identical to the input symbol, and with probability $\\epsilon$, the output symbol is replaced by an erasure symbol (denoted by $2$). For more details, see CT06, Sec. 7.1.5.</p> <p>Parameters:</p> <ul> <li> <code>erasure_probability</code> (<code>float</code>)         \u2013          <p>The channel erasure probability $\\epsilon$. Must satisfy $0 \\leq \\epsilon \\leq 1$. Default value is <code>0.0</code>, which corresponds to a noiseless channel.</p> </li> </ul>"},{"location":"ref/BinaryErasureChannel/#input_cardinality","title":"<code>input_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel input cardinality $|\\mathcal{X}|$.</p> <p>For the BEC, it is given by $|\\mathcal{X}| = 2$.</p>"},{"location":"ref/BinaryErasureChannel/#output_cardinality","title":"<code>output_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel output cardinality $|\\mathcal{Y}|$.</p> <p>For the BEC, it is given by $|\\mathcal{Y}| = 3$.</p>"},{"location":"ref/BinaryErasureChannel/#transition_matrix","title":"<code>transition_matrix</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The channel transition probability matrix $p_{Y \\mid X}$.</p> <p>For the BEC, it is given by $$     p_{Y \\mid X} =     \\begin{bmatrix}         1 - \\epsilon &amp; 0 &amp; \\epsilon \\\\         0 &amp; 1 - \\epsilon &amp; \\epsilon     \\end{bmatrix}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bec = komm.BinaryErasureChannel(0.2)\n&gt;&gt;&gt; bec.transition_matrix\narray([[0.8, 0. , 0.2],\n       [0. , 0.8, 0.2]])\n</code></pre>"},{"location":"ref/BinaryErasureChannel/#mutual_information","title":"<code>mutual_information()</code>","text":"<p>Returns the mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$ of the channel.</p> <p>Parameters:</p> <ul> <li> <code>input_pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function $p_X$ of the channel input $X$. It must be a valid pmf, that is, all of its values must be non-negative and sum up to $1$.</p> </li> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$.</p> </li> </ul> <p>For the BEC, it is given by $$     \\mathrm{I}(X ; Y) = (1 - \\epsilon) \\, \\Hb(\\pi), $$ in bits, where $\\pi = \\Pr[X = 1]$, and $\\Hb$ is the binary entropy function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bec = komm.BinaryErasureChannel(0.2)\n&gt;&gt;&gt; bec.mutual_information([0.45, 0.55])\nnp.float64(0.7942195631902467)\n</code></pre>"},{"location":"ref/BinaryErasureChannel/#capacity","title":"<code>capacity()</code>","text":"<p>Returns the channel capacity $C$.</p> <p>Parameters:</p> <ul> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The channel capacity $C$.</p> </li> </ul> <p>For the BEC, it is given by $$     C = 1 - \\epsilon, $$ in bits.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bec = komm.BinaryErasureChannel(0.2)\n&gt;&gt;&gt; bec.capacity()\nnp.float64(0.8)\n</code></pre>"},{"location":"ref/BinaryErasureChannel/#__call__","title":"<code>__call__()</code>","text":"<p>Transmits the input sequence through the channel and returns the output sequence.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bec = komm.BinaryErasureChannel(0.2)\n&gt;&gt;&gt; bec([1, 1, 1, 0, 0, 0, 1, 0, 1, 0])\narray([1, 1, 1, 0, 2, 0, 1, 0, 2, 0])\n</code></pre>"},{"location":"ref/BinaryPolynomial/","title":"komm.BinaryPolynomial","text":"<p>Binary polynomial. A binary polynomial is a polynomial whose coefficients are elements in the finite field $\\mathbb{F}_2 = \\{ 0, 1 \\}$.</p> <p>The default constructor of the class expects the following:</p> <p>Parameters:</p> <ul> <li> <code>value</code> (<code>SupportsInt</code>)         \u2013          <p>An integer whose binary digits represent the coefficients of the polynomial\u2014the leftmost bit standing for the highest degree term. For example, the binary polynomial $X^4 + X^3 + X$ is represented by the integer <code>0b11010</code> = <code>0o32</code> = <code>26</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.BinaryPolynomial(0b11010)  # X^4 + X^3 + X\nBinaryPolynomial(0b11010)\n</code></pre> <p>See also the class methods <code>from_coefficients</code> and <code>from_exponents</code> for alternative ways to construct a binary polynomial.</p> Algebraic structure <p>The binary polynomials form an Euclidean domain. The following operations are supported: addition (<code>+</code>), subtraction (<code>-</code>), multiplication (<code>*</code>), euclidean division (<code>//</code>), modulo (<code>%</code>), and exponentiation (<code>**</code>).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; poly1 = komm.BinaryPolynomial(0b10111)  # X^4 + X^2 + X + 1\n&gt;&gt;&gt; poly2 = komm.BinaryPolynomial(0b101)  # X^2 + 1\n&gt;&gt;&gt; poly1 + poly2  # X^4 + X\nBinaryPolynomial(0b10010)\n&gt;&gt;&gt; poly1 - poly2  # X^4 + X\nBinaryPolynomial(0b10010)\n&gt;&gt;&gt; poly1 * poly2  # X^6 + X^3 + X + 1\nBinaryPolynomial(0b1001011)\n&gt;&gt;&gt; poly1 // poly2  # X^2\nBinaryPolynomial(0b100)\n&gt;&gt;&gt; poly1 % poly2  # X + 1\nBinaryPolynomial(0b11)\n&gt;&gt;&gt; poly1 ** 2  # X^8 + X^4 + X^2 + 1\nBinaryPolynomial(0b100010101)\n</code></pre>"},{"location":"ref/BinaryPolynomial/#from_coefficients","title":"<code>from_coefficients()</code>  <code>classmethod</code>","text":"<p>Constructs a binary polynomial from its coefficients.</p> <p>Parameters:</p> <ul> <li> <code>coefficients</code> (<code>ArrayLike</code>)         \u2013          <p>The coefficients of the binary polynomial\u2014the $i$-th element of the array standing for the coefficient of $X^i$. For example, <code>[0, 1, 0, 1, 1]</code> represents the binary polynomial $X^4 + X^3 + X$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.BinaryPolynomial.from_coefficients([0, 1, 0, 1, 1])  # X^4 + X^3 + X\nBinaryPolynomial(0b11010)\n</code></pre>"},{"location":"ref/BinaryPolynomial/#from_exponents","title":"<code>from_exponents()</code>  <code>classmethod</code>","text":"<p>Constructs a binary polynomial from its exponents.</p> <p>Parameters:</p> <ul> <li> <code>exponents</code> (<code>ArrayLike</code>)         \u2013          <p>The exponents of the nonzero terms of the binary polynomial. For example, <code>[1, 3, 4]</code> represents the binary polynomial $X^4 + X^3 + X$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.BinaryPolynomial.from_exponents([1, 3, 4])  # X^4 + X^3 + X\nBinaryPolynomial(0b11010)\n</code></pre>"},{"location":"ref/BinaryPolynomial/#degree","title":"<code>degree</code><code>  int </code>  <code>property</code>","text":"<p>The degree of the binary polynomial.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; poly = komm.BinaryPolynomial(0b11010)  # X^4 + X^3 + X\n&gt;&gt;&gt; poly.degree\n4\n</code></pre>"},{"location":"ref/BinaryPolynomial/#coefficients","title":"<code>coefficients()</code>","text":"<p>Returns the coefficients of the binary polynomial.</p> <p>Parameters:</p> <ul> <li> <code>width</code> (<code>int | None</code>)         \u2013          <p>If this parameter is specified, the output will be filled with zeros on the right so that the its length will be the specified value.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>coefficients</code>  (<code>NDArray[integer]</code>)          \u2013          <p>Coefficients of the binary polynomial. The $i$-th element of the array stands for the coefficient of $X^i$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; poly = komm.BinaryPolynomial(0b11010)  # X^4 + X^3 + X\n&gt;&gt;&gt; poly.coefficients()\narray([0, 1, 0, 1, 1])\n&gt;&gt;&gt; poly.coefficients(width=8)\narray([0, 1, 0, 1, 1, 0, 0, 0])\n</code></pre>"},{"location":"ref/BinaryPolynomial/#exponents","title":"<code>exponents()</code>","text":"<p>Returns the exponents of the binary polynomial.</p> <p>Returns:</p> <ul> <li> <code>exponents</code>  (<code>NDArray[integer]</code>)          \u2013          <p>Exponents of the nonzero terms of the binary polynomial. The exponents are returned in ascending order.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; poly = komm.BinaryPolynomial(0b11010)  # X^4 + X^3 + X\n&gt;&gt;&gt; poly.exponents()\narray([1, 3, 4])\n</code></pre>"},{"location":"ref/BinaryPolynomial/#reciprocal","title":"<code>reciprocal()</code>","text":"<p>Returns the reciprocal (reflexion) of the binary polynomial. The reciprocal of a binary polynomial is the polynomial with the coefficients in reversed order, that is, the coefficient of $X^i$ becomes the coefficient of $X^{n-i}$, where $n$ is the degree of the polynomial.</p> <p>Returns:</p> <ul> <li> <code>result</code>  (<code>BinaryPolynomial</code>)          \u2013          <p>The binary polynomial with the reversed coefficients.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; poly = komm.BinaryPolynomial(0b11010)  # X^4 + X^3 + X\n&gt;&gt;&gt; poly.reciprocal()  # X^3 + X + 1\nBinaryPolynomial(0b1011)\n</code></pre>"},{"location":"ref/BinaryPolynomial/#evaluate","title":"<code>evaluate()</code>","text":"<p>Evaluates the binary polynomial at a given point. Uses Horner's method.</p> <p>Parameters:</p> <ul> <li> <code>point</code> (<code>RingElement</code>)         \u2013          <p>The point at which the polynomial is evaluated. It must be an element of a ring in which multiplication by integers is defined.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>result</code>  (<code>RingElement</code>)          \u2013          <p>The result of evaluating the binary polynomial at <code>point</code>. It has the same type as <code>point</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; poly = komm.BinaryPolynomial(0b11010)  # X^4 + X^3 + X\n&gt;&gt;&gt; poly.evaluate(komm.Integer(7))  # same as 7**4 + 7**3 + 7\nInteger(2751)\n</code></pre>"},{"location":"ref/BinaryPolynomial/#is_irreducible","title":"<code>is_irreducible()</code>","text":"<p>Checks whether the binary polynomial is irreducible. A binary polynomial is irreducible if it is not divisible by any other nonconstant binary polynomial of smaller degree.</p> <p>This method checks the irreducibility using Rabin's irreducibility test.</p> <p>Returns:</p> <ul> <li> <code>result</code>  (<code>bool</code>)          \u2013          <p><code>True</code>, if the binary polynomial is irreducible; <code>False</code>, otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.BinaryPolynomial(0b11011).is_irreducible()\nFalse\n&gt;&gt;&gt; komm.BinaryPolynomial(0b11111).is_irreducible()\nTrue\n&gt;&gt;&gt; komm.BinaryPolynomial(0b10011).is_irreducible()\nTrue\n</code></pre>"},{"location":"ref/BinaryPolynomial/#is_primitive","title":"<code>is_primitive()</code>","text":"<p>Checks whether the binary polynomial is primitive. A binary polynomial of degree $m$ is primitive if it is irreducible and if the smallest positive integer $n$ such that the polynomial divides $X^n + 1$ is $n = 2^m - 1$.</p> <p>Returns:</p> <ul> <li> <code>result</code>  (<code>bool</code>)          \u2013          <p><code>True</code>, if the binary polynomial is primitive; <code>False</code>, otherwise.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.BinaryPolynomial(0b11011).is_primitive()\nFalse\n&gt;&gt;&gt; komm.BinaryPolynomial(0b11111).is_primitive()\nFalse\n&gt;&gt;&gt; komm.BinaryPolynomial(0b10011).is_primitive()\nTrue\n</code></pre>"},{"location":"ref/BinaryPolynomial/#xgcd","title":"<code>xgcd()</code>  <code>classmethod</code>","text":"<p>Performs the extended Euclidean algorithm on two given binary polynomials.</p>"},{"location":"ref/BinaryPolynomial/#gcd","title":"<code>gcd()</code>  <code>classmethod</code>","text":"<p>Computes the greatest common divisor (gcd) of the arguments.</p>"},{"location":"ref/BinaryPolynomial/#lcm","title":"<code>lcm()</code>  <code>classmethod</code>","text":"<p>Computes the least common multiple (lcm) of the arguments.</p>"},{"location":"ref/BinaryPolynomialFraction/","title":"komm.BinaryPolynomialFraction","text":"<p>Binary polynomial fraction. A binary polynomial fraction is a ratio of two binary polynomials.</p> <p>Parameters:</p> <ul> <li> <code>numerator</code> (<code>SupportsInt</code>)         \u2013          <p>The numerator of the fraction.</p> </li> <li> <code>denominator</code> (<code>SupportsInt</code>)         \u2013          <p>The denominator of the fraction.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.BinaryPolynomialFraction(0b11010, 0b101)  # (X^4 + X^3 + X) / (X^2 + 1)\nBinaryPolynomialFraction(0b11010, 0b101)\n</code></pre> Algebraic structure <p>The binary polynomial fractions form a field. The following operations are supported: addition (<code>+</code>), subtraction (<code>-</code>), multiplication (<code>*</code>), division (<code>/</code>), and exponentiation (<code>**</code>).</p>"},{"location":"ref/BinarySequence/","title":"komm.BinarySequence","text":"<p>General binary sequence. It may be represented either in bit format, denoted by $b[n]$, with elements in the set $\\{ 0, 1 \\}$, or in polar format, denoted by $x[n]$, with elements in the set $\\{ \\pm 1 \\}$. The correspondences $0 \\mapsto +1$ and $1 \\mapsto -1$ from bit format to polar format is assumed.</p> <p>The constructor expects either the bit sequence or the polar sequence.</p> <p>Parameters:</p> <ul> <li> <code>bit_sequence</code> (<code>ArrayLike | None</code>)         \u2013          <p>The binary sequence in bit format, $b[n] \\in \\{ 0, 1 \\}$.</p> </li> <li> <code>polar_sequence</code> (<code>ArrayLike | None</code>)         \u2013          <p>The binary sequence in polar format, $x[n] \\in \\{ \\pm 1 \\}$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; seq = komm.BinarySequence(bit_sequence=[0, 1, 1, 0])\n&gt;&gt;&gt; seq.bit_sequence\narray([0, 1, 1, 0])\n&gt;&gt;&gt; seq.polar_sequence\narray([ 1, -1, -1,  1])\n</code></pre> <pre><code>&gt;&gt;&gt; seq = komm.BinarySequence(polar_sequence=[1, -1, -1, 1])\n&gt;&gt;&gt; seq.bit_sequence\narray([0, 1, 1, 0])\n&gt;&gt;&gt; seq.polar_sequence\narray([ 1, -1, -1,  1])\n</code></pre>"},{"location":"ref/BinarySequence/#length","title":"<code>length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The length (or period) $L$ of the binary sequence.</p>"},{"location":"ref/BinarySequence/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>Returns the autocorrelation $R[\\ell]$ of the binary sequence in polar format. See <code>komm.autocorrelation</code> for more details.</p> <p>Parameters:</p> <ul> <li> <code>shifts</code> (<code>ArrayLike | None</code>)         \u2013          <p>See the corresponding parameter in <code>komm.autocorrelation</code>.</p> </li> <li> <code>normalized</code> (<code>bool</code>)         \u2013          <p>See the corresponding parameter in <code>komm.autocorrelation</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[floating]</code>         \u2013          <p>The autocorrelation $R[\\ell]$ of the binary sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; seq = komm.BinarySequence(bit_sequence=[0, 1, 1, 0])\n&gt;&gt;&gt; seq.autocorrelation()\narray([ 4, -1, -2,  1])\n</code></pre>"},{"location":"ref/BinarySequence/#cyclic_autocorrelation","title":"<code>cyclic_autocorrelation()</code>","text":"<p>Returns the cyclic autocorrelation $\\tilde{R}[\\ell]$ of the binary sequence in polar format. See <code>komm.cyclic_autocorrelation</code> for more details.</p> <p>Parameters:</p> <ul> <li> <code>shifts</code> (<code>ArrayLike | None</code>)         \u2013          <p>See the corresponding parameter in <code>komm.cyclic_autocorrelation</code>.</p> </li> <li> <code>normalized</code> (<code>bool</code>)         \u2013          <p>See the corresponding parameter in <code>komm.cyclic_autocorrelation</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[floating]</code>         \u2013          <p>The cyclic autocorrelation $\\tilde{R}[\\ell]$ of the binary sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; seq = komm.BinarySequence(bit_sequence=[0, 1, 1, 0])\n&gt;&gt;&gt; seq.cyclic_autocorrelation()\narray([ 4,  0, -4,  0])\n</code></pre>"},{"location":"ref/BinarySymmetricChannel/","title":"komm.BinarySymmetricChannel","text":"<p>Binary symmetric channel (BSC). It is a discrete memoryless channel with input and output alphabets $\\mathcal{X} = \\mathcal{Y} = \\{ 0, 1 \\}$. The channel is characterized by a parameter $p$, called the crossover probability. With probability $1 - p$, the output symbol is identical to the input symbol, and with probability $p$, the output symbol is flipped. Equivalently, the channel can be modeled as $$     Y_n = X_n + Z_n, $$ where $Z_n$ are iid Bernoulli random variables with $\\Pr[Z_n = 1] = p$. For more details, see CT06, Sec. 7.1.4.</p> <p>Parameters:</p> <ul> <li> <code>crossover_probability</code> (<code>float</code>)         \u2013          <p>The channel crossover probability $p$. Must satisfy $0 \\leq p \\leq 1$. The default value is <code>0.0</code>, which corresponds to a noiseless channel.</p> </li> </ul>"},{"location":"ref/BinarySymmetricChannel/#input_cardinality","title":"<code>input_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel input cardinality $|\\mathcal{X}|$.</p> <p>For the BSC, it is given by $|\\mathcal{X}| = 2$.</p>"},{"location":"ref/BinarySymmetricChannel/#output_cardinality","title":"<code>output_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel output cardinality $|\\mathcal{Y}|$.</p> <p>For the BSC, it is given by $|\\mathcal{Y}| = 2$.</p>"},{"location":"ref/BinarySymmetricChannel/#transition_matrix","title":"<code>transition_matrix</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The channel transition probability matrix $p_{Y \\mid X}$.</p> <p>For the BSC, it is given by $$     p_{Y \\mid X} = \\begin{bmatrix} 1-p &amp; p \\\\ p &amp; 1-p \\end{bmatrix}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bsc = komm.BinarySymmetricChannel(0.2)\n&gt;&gt;&gt; bsc.transition_matrix\narray([[0.8, 0.2],\n       [0.2, 0.8]])\n</code></pre>"},{"location":"ref/BinarySymmetricChannel/#mutual_information","title":"<code>mutual_information()</code>","text":"<p>Returns the mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$ of the channel.</p> <p>Parameters:</p> <ul> <li> <code>input_pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function $p_X$ of the channel input $X$. It must be a valid pmf, that is, all of its values must be non-negative and sum up to $1$.</p> </li> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$.</p> </li> </ul> <p>For the BSC, it is given by $$     \\mathrm{I}(X ; Y) = \\Hb(p + \\pi - 2 p \\pi) - \\Hb(p), $$ in bits, where $\\pi = \\Pr[X = 1]$, and $\\Hb$ is the binary entropy function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bsc = komm.BinarySymmetricChannel(0.2)\n&gt;&gt;&gt; bsc.mutual_information([0.45, 0.55])\nnp.float64(0.2754734936803773)\n</code></pre>"},{"location":"ref/BinarySymmetricChannel/#capacity","title":"<code>capacity()</code>","text":"<p>Returns the channel capacity $C$.</p> <p>Parameters:</p> <ul> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The channel capacity $C$.</p> </li> </ul> <p>For the BSC, it is given by $$     C = 1 - \\Hb(p), $$ in bits, where $\\Hb$ is the binary entropy function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bsc = komm.BinarySymmetricChannel(0.2)\n&gt;&gt;&gt; bsc.capacity()\nnp.float64(0.2780719051126377)\n</code></pre>"},{"location":"ref/BinarySymmetricChannel/#__call__","title":"<code>__call__()</code>","text":"<p>Transmits the input sequence through the channel and returns the output sequence.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bsc = komm.BinarySymmetricChannel(0.2)\n&gt;&gt;&gt; bsc([1, 1, 1, 0, 0, 0, 1, 0, 1, 0])\narray([1, 1, 1, 0, 1, 0, 1, 0, 0, 0])\n</code></pre>"},{"location":"ref/BlockCode/","title":"komm.BlockCode","text":"<p>General binary linear block code. It is characterized by its generator matrix $G \\in \\mathbb{B}^{k \\times n}$, and by its check matrix $H \\in \\mathbb{B}^{m \\times n}$, which are related by $G H^\\transpose = 0$. The parameters $n$, $k$, and $m$ are called the code length, dimension, and redundancy, respectively, and are related by $k + m = n$. For more details, see LC04, Ch. 3.</p> <p>The constructor expects either the generator matrix or the check matrix.</p> <p>Parameters:</p> <ul> <li> <code>generator_matrix</code> (<code>ArrayLike | None</code>)         \u2013          <p>The generator matrix $G$ of the code, which is a $k \\times n$ binary matrix.</p> </li> <li> <code>check_matrix</code> (<code>ArrayLike | None</code>)         \u2013          <p>The check matrix $H$ of the code, which is a $m \\times n$ binary matrix.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(5, 2, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0]])\n&gt;&gt;&gt; code.check_matrix\narray([[0, 1, 1, 0, 0],\n       [1, 1, 0, 1, 0],\n       [1, 0, 0, 0, 1]])\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(check_matrix=[\n...     [0, 1, 1, 0, 0],\n...     [1, 1, 0, 1, 0],\n...     [1, 0, 0, 0, 1],\n... ])\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(5, 2, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0]])\n&gt;&gt;&gt; code.check_matrix\narray([[0, 1, 1, 0, 0],\n       [1, 1, 0, 1, 0],\n       [1, 0, 0, 0, 1]])\n</code></pre>"},{"location":"ref/BlockCode/#length","title":"<code>length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The length $n$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.length\n5\n</code></pre>"},{"location":"ref/BlockCode/#dimension","title":"<code>dimension</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The dimension $k$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.dimension\n2\n</code></pre>"},{"location":"ref/BlockCode/#redundancy","title":"<code>redundancy</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The redundancy $m$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.redundancy\n3\n</code></pre>"},{"location":"ref/BlockCode/#rate","title":"<code>rate</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The rate $R = k/n$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.rate\n0.4\n</code></pre>"},{"location":"ref/BlockCode/#generator_matrix","title":"<code>generator_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The generator matrix $G \\in \\mathbb{B}^{k \\times n}$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(check_matrix=[\n...     [0, 1, 1, 0, 0],\n...     [1, 1, 0, 1, 0],\n...     [1, 0, 0, 0, 1],\n... ])\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0]])\n</code></pre>"},{"location":"ref/BlockCode/#check_matrix","title":"<code>check_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The check matrix $H \\in \\mathbb{B}^{m \\times n}$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.check_matrix\narray([[0, 1, 1, 0, 0],\n       [1, 1, 0, 1, 0],\n       [1, 0, 0, 0, 1]])\n</code></pre>"},{"location":"ref/BlockCode/#encode","title":"<code>encode()</code>","text":"<p>Applies the encoding mapping $\\Enc : \\mathbb{B}^k \\to \\mathbb{B}^n$ of the code. This method takes one or more sequences of messages and returns their corresponding codeword sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $k$, or a multidimensional array where the last dimension is a multiple of $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension expanded from $bk$ to $bn$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.encode([0, 0])  # Sequence with single message\narray([0, 0, 0, 0, 0])\n&gt;&gt;&gt; code.encode([0, 0, 1, 1])  # Sequence with two messages\narray([0, 0, 0, 0, 0, 1, 1, 1, 0, 1])\n&gt;&gt;&gt; code.encode([[0, 0],  # 2D array of single messages\n...              [1, 1]])\narray([[0, 0, 0, 0, 0],\n       [1, 1, 1, 0, 1]])\n&gt;&gt;&gt; code.encode([[0, 0, 1, 1],  # 2D array of two messages\n...              [1, 1, 1, 0]])\narray([[0, 0, 0, 0, 0, 1, 1, 1, 0, 1],\n       [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]])\n</code></pre>"},{"location":"ref/BlockCode/#inverse_encode","title":"<code>inverse_encode()</code>","text":"<p>Applies the inverse encoding partial mapping $\\Enc^{-1} : \\mathbb{B}^n \\rightharpoonup \\mathbb{B}^k$ of the code. This method takes one or more sequences of codewords and returns their corresponding message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the input contains any invalid codewords.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.inverse_encode([0, 0, 0, 0, 0])  # Sequence with single codeword\narray([0, 0])\n&gt;&gt;&gt; code.inverse_encode([0, 0, 0, 0, 0, 1, 1, 1, 0, 1])  # Sequence with two codewords\narray([0, 0, 1, 1])\n&gt;&gt;&gt; code.inverse_encode([[0, 0, 0, 0, 0],  # 2D array of single codewords\n...                      [1, 1, 1, 0, 1]])\narray([[0, 0],\n       [1, 1]])\n&gt;&gt;&gt; code.inverse_encode([[0, 0, 0, 0, 0, 1, 1, 1, 0, 1],  # 2D array of two codewords\n...                      [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]])\narray([[0, 0, 1, 1],\n       [1, 1, 1, 0]])\n</code></pre>"},{"location":"ref/BlockCode/#check","title":"<code>check()</code>","text":"<p>Applies the check mapping $\\mathrm{Chk} : \\mathbb{B}^n \\to \\mathbb{B}^m$ of the code. This method takes one or more sequences of received words and returns their corresponding syndrome sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bm$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.check([1, 1, 1, 0, 1])  # Sequence with single received word\narray([0, 0, 0])\n&gt;&gt;&gt; code.check([1, 1, 1, 0, 1, 1, 1, 1, 1, 1])  # Sequence with two received words\narray([0, 0, 0, 0, 1, 0])\n&gt;&gt;&gt; code.check([[1, 1, 1, 0, 1],  # 2D array of single received words\n...             [1, 1, 1, 1, 1]])\narray([[0, 0, 0],\n       [0, 1, 0]])\n&gt;&gt;&gt; code.check([[1, 1, 1, 0, 1, 1, 1, 1, 1, 1],  # 2D array of two received words\n...             [1, 1, 1, 1, 1, 0, 0, 0, 1, 1]])\narray([[0, 0, 0, 0, 1, 0],\n       [0, 1, 0, 0, 1, 1]])\n</code></pre>"},{"location":"ref/BlockCode/#codewords","title":"<code>codewords()</code>  <code>cached</code>","text":"<p>Returns the codewords of the code. This is a $2^k \\times n$ matrix whose rows are all the codewords. The codeword in row $i$ corresponds to the message obtained by expressing $i$ in binary with $k$ bits (MSB in the right).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.codewords()\narray([[0, 0, 0, 0, 0],\n       [1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0],\n       [1, 1, 1, 0, 1]])\n</code></pre>"},{"location":"ref/BlockCode/#codeword_weight_distribution","title":"<code>codeword_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the codeword weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of codewords of Hamming weight $w$, for $w \\in [0 : n]$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.codeword_weight_distribution()\narray([1, 0, 0, 2, 1, 0])\n</code></pre>"},{"location":"ref/BlockCode/#minimum_distance","title":"<code>minimum_distance()</code>  <code>cached</code>","text":"<p>Returns the minimum distance $d$ of the code. This is equal to the minimum Hamming weight of the non-zero codewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.minimum_distance()\n3\n</code></pre>"},{"location":"ref/BlockCode/#coset_leaders","title":"<code>coset_leaders()</code>  <code>cached</code>","text":"<p>Returns the coset leaders of the code. This is a $2^m \\times n$ matrix whose rows are all the coset leaders. The coset leader in row $i$ corresponds to the syndrome obtained by expressing $i$ in binary with $m$ bits (MSB in the right), and whose Hamming weight is minimal. This may be used as a LUT for syndrome-based decoding.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.coset_leaders()\narray([[0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 1],\n       [1, 1, 0, 0, 0],\n       [1, 0, 0, 0, 0],\n       [1, 0, 1, 0, 0]])\n</code></pre>"},{"location":"ref/BlockCode/#coset_leader_weight_distribution","title":"<code>coset_leader_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the coset leader weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of coset leaders of weight $w$, for $w \\in [0 : n]$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.coset_leader_weight_distribution()\narray([1, 5, 2, 0, 0, 0])\n</code></pre>"},{"location":"ref/BlockCode/#packing_radius","title":"<code>packing_radius()</code>  <code>cached</code>","text":"<p>Returns the packing radius of the code. This is also called the error-correcting capability of the code, and is equal to $\\lfloor (d - 1) / 2 \\rfloor$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.packing_radius()\n1\n</code></pre>"},{"location":"ref/BlockCode/#covering_radius","title":"<code>covering_radius()</code>  <code>cached</code>","text":"<p>Returns the covering radius of the code. This is equal to the maximum Hamming weight of the coset leaders.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[\n...     [1, 0, 0, 1, 1],\n...     [0, 1, 1, 1, 0],\n... ])\n&gt;&gt;&gt; code.covering_radius()\n2\n</code></pre>"},{"location":"ref/ComplexSequence/","title":"komm.ComplexSequence","text":"<p>General complex sequence. It is denoted by $x[n]$, with elements in $\\mathbb{C}$. Its length (or period) is denoted by $L$.</p> <p>Parameters:</p> <ul> <li> <code>sequence</code> (<code>ArrayLike</code>)         \u2013          <p>The complex sequence. Must be a 1D-array of length $L$ with elements in $\\mathbb{C}$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; seq = ComplexSequence([1, 1j, -1, -1j])\n&gt;&gt;&gt; seq.sequence\narray([ 1.+0.j,  0.+1.j, -1.+0.j, -0.-1.j])\n</code></pre>"},{"location":"ref/ComplexSequence/#length","title":"<code>length</code>  <code>cached</code> <code>property</code>","text":"<p>The length (or period) $L$ of the complex sequence.</p>"},{"location":"ref/ComplexSequence/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>Returns the autocorrelation $R[\\ell]$ of the complex sequence. See <code>komm.autocorrelation</code> for more details.</p> <p>Parameters:</p> <ul> <li> <code>shifts</code> (<code>ArrayLike | None</code>)         \u2013          <p>See the corresponding parameter in <code>komm.autocorrelation</code>.</p> </li> <li> <code>normalized</code> (<code>bool</code>)         \u2013          <p>See the corresponding parameter in <code>komm.autocorrelation</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[complexfloating]</code>         \u2013          <p>The autocorrelation $R[\\ell]$ of the complex sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; seq = ComplexSequence([1, 1j, -1, -1j])\n&gt;&gt;&gt; seq.autocorrelation(shifts=[-2, -1, 0, 1, 2])\narray([-2.+0.j,  0.-3.j,  4.+0.j,  0.+3.j, -2.+0.j])\n</code></pre>"},{"location":"ref/ComplexSequence/#cyclic_autocorrelation","title":"<code>cyclic_autocorrelation()</code>","text":"<p>Returns the cyclic autocorrelation $\\tilde{R}[\\ell]$ of the complex sequence. See <code>komm.cyclic_autocorrelation</code> for more details.</p> <p>Parameters:</p> <ul> <li> <code>shifts</code> (<code>ArrayLike | None</code>)         \u2013          <p>See the corresponding parameter in <code>komm.cyclic_autocorrelation</code>.</p> </li> <li> <code>normalized</code> (<code>bool</code>)         \u2013          <p>See the corresponding parameter in <code>komm.cyclic_autocorrelation</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[complexfloating]</code>         \u2013          <p>The cyclic autocorrelation $\\tilde{R}[\\ell]$ of the complex sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; seq = ComplexSequence([1, 1j, -1, -1j])\n&gt;&gt;&gt; seq.cyclic_autocorrelation(shifts=[-2, -1, 0, 1, 2])\narray([-4.+0.j,  0.-4.j,  4.+0.j,  0.+4.j, -4.+0.j])\n</code></pre>"},{"location":"ref/ConvolutionalCode/","title":"komm.ConvolutionalCode","text":"<p>Binary convolutional encoder. It is characterized by a matrix of feedforward polynomials $P(D)$, of shape $k \\times n$, and (optionally) by a vector of feedback polynomials $q(D)$, of length $k$. The parameters $k$ and $n$ are the number of input and output bits per block, respectively. In this class, the encoder is realized in controllable canonical form. For more details, see McE98, JZ15, and LC04, Chs. 11, 12.</p> <p>Parameters:</p> <ul> <li> <code>feedforward_polynomials</code> (<code>ArrayLike</code>)         \u2013          <p>The matrix of feedforward polynomials $P(D)$, which is a $k \\times n$ matrix whose entries are either binary polynomials or integers to be converted to the former.</p> </li> <li> <code>feedback_polynomials</code> (<code>ArrayLike | None</code>)         \u2013          <p>The vector of feedback polynomials $q(D)$, which is a $k$-vector whose entries are either binary polynomials or integers to be converted to the former. The default value corresponds to no feedback, that is, $q_i(D) = 1$ for all $i \\in [0 : k)$.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>Consider the encoder with parameters $(n, k, \\sigma) = (3, 2, 7)$ depicted below.</p> <p> </p> <p>Its matrix of feedforward polynomials is given by $$     P(D) =     \\begin{bmatrix}         D^4 + D^3 + 1  &amp;  D^4 + D^2 + D + 1  &amp;  0 \\\\         0  &amp;  D^3 + D  &amp;  D^3 + D^2 + 1     \\end{bmatrix}. $$</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode(\n...     feedforward_polynomials=[\n...         [0b11001, 0b10111,      0],\n...         [      0,  0b1010, 0b1101],\n...     ],\n... )\n&gt;&gt;&gt; code = komm.ConvolutionalCode(\n...     feedforward_polynomials=[[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]],\n... )\n</code></pre> </li> <li> <p>Consider the feedback encoder with parameters $(n, k, \\sigma) = (2, 1, 4)$ depicted below.</p> <p> </p> <p>Its matrix of feedforward polynomials is given by $$     P(D) =     \\begin{bmatrix}         D^4 + D^2 + D + 1 &amp;&amp; D^4 + D^3 + 1     \\end{bmatrix}, $$ and its vector of feedback polynomials is given by $$     q(D) =     \\begin{bmatrix}         D^4 + D^2 + D + 1     \\end{bmatrix}. $$</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode(\n...     feedforward_polynomials=[[0b10111, 0b11001]],\n...     feedback_polynomials=[0b10111],\n... )\n&gt;&gt;&gt; code = komm.ConvolutionalCode(\n...     feedforward_polynomials=[[0o27, 0o31]],\n...     feedback_polynomials=[0o27],\n... )\n</code></pre> </li> </ol>"},{"location":"ref/ConvolutionalCode/#num_input_bits","title":"<code>num_input_bits</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of input bits per block, $k$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; code.num_input_bits\n2\n</code></pre>"},{"location":"ref/ConvolutionalCode/#num_output_bits","title":"<code>num_output_bits</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of output bits per block, $n$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; code.num_output_bits\n3\n</code></pre>"},{"location":"ref/ConvolutionalCode/#degree","title":"<code>degree</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The degree $\\sigma$ of the encoder. This corresponds to the number of delay elements in the encoder realization.</p> <p>For a convolutional encoder realized in controllable canonical form, the degree $\\sigma$ is equal to the overall constraint length $\\nu$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; code.degree\n7\n</code></pre>"},{"location":"ref/ConvolutionalCode/#generator_matrix","title":"<code>generator_matrix</code><code>  Array2D[object_] </code>  <code>cached</code> <code>property</code>","text":"<p>Returns the (transform-domain) generator matrix (also known as transfer function matrix) $G(D)$ of the encoder. This is a $k \\times n$ array of binary polynomial fractions.</p> <p>For a convolutional code with matrix of feedforward polynomials $$     P(D) =     \\begin{bmatrix}         p_{0,0}(D)   &amp; p_{0,1}(D)   &amp; \\cdots &amp; p_{0,n-1}(D)   \\\\         p_{1,0}(D)   &amp; p_{1,1}(D)   &amp; \\cdots &amp; p_{1,n-1}(D)   \\\\         \\vdots       &amp; \\vdots       &amp; \\ddots &amp; \\vdots         \\\\         p_{k-1,0}(D) &amp; p_{k-1,1}(D) &amp; \\cdots &amp; p_{k-1,n-1}(D)     \\end{bmatrix}, $$ and vector of feedback polynomials $$     q(D) =     \\begin{bmatrix}         q_0(D)     \\\\         q_1(D)     \\\\         \\vdots     \\\\         q_{k-1}(D)     \\end{bmatrix}, $$ the generator matrix is given by $$     G(D) =     \\begin{bmatrix}         p_{0,0}(D)/q_0(D)       &amp; p_{0,1}(D)/q_0(D)       &amp; \\cdots &amp; p_{0,n-1}(D)/q_0(D)       \\\\         p_{1,0}(D)/q_1(D)       &amp; p_{1,1}(D)/q_1(D)       &amp; \\cdots &amp; p_{1,n-1}(D)/q_1(D)       \\\\         \\vdots                  &amp; \\vdots                  &amp; \\ddots &amp; \\vdots                    \\\\         p_{k-1,0}(D)/q_{k-1}(D) &amp; p_{k-1,1}(D)/q_{k-1}(D) &amp; \\cdots &amp; p_{k-1,n-1}(D)/q_{k-1}(D)     \\end{bmatrix}. $$</p> <p>Examples:</p> <p>If matrix of feedforward polynomials is $$     P(D) =     \\begin{bmatrix}         D^4 + D^2 + D + 1 &amp;&amp; D^4 + D^3 + 1     \\end{bmatrix} $$ and vector of feedback polynomials is $$     q(D) =     \\begin{bmatrix}         D^4 + D^2 + D + 1     \\end{bmatrix}, $$ then the generator matrix is given by $$     G(D) =     \\begin{bmatrix}         1 &amp; \\frac{D^4 + D^3 + 1}{D^4 + D^2 + D + 1}     \\end{bmatrix}. $$</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o27, 0o31]], [0o27])\n&gt;&gt;&gt; for row in code.generator_matrix:\n...     print(\"[\" + \", \".join(str(x) for x in row) + \"]\")\n[0b1/0b1, 0b11001/0b10111]\n</code></pre>"},{"location":"ref/ConvolutionalCode/#constraint_lengths","title":"<code>constraint_lengths</code><code>  Array1D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The constraint lengths $\\nu_i$ of the encoder, for $i \\in [0 : k)$. These are defined by $$     \\nu_i = \\max \\{ \\deg p_{i,0}(D), \\deg p_{i,1}(D), \\ldots, \\deg p_{i,n-1}(D), \\deg q_i(D) \\}, $$ where $p_{i,j}(D) / q_i(D)$ are the entries of the $i$-th row of the generator matrix $G(D)$, satisfying $$     \\gcd(p_{i,0}(D), p_{i,1}(D), \\ldots, p_{i,n-1}(D), q_i(D)) = 1. $$ This is a $k$-array of integers.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; code.constraint_lengths\narray([4, 3])\n</code></pre>"},{"location":"ref/ConvolutionalCode/#overall_constraint_length","title":"<code>overall_constraint_length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The overall constraint length $\\nu$ of the encoder, defined by $$     \\nu = \\sum_{i \\in [0:k)} \\nu_i, $$ where $\\nu_i$ are the constraint lengths of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; code.overall_constraint_length\n7\n</code></pre>"},{"location":"ref/ConvolutionalCode/#memory_order","title":"<code>memory_order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The memory order $\\mu$ of the encoder. It is given by $$     \\mu = \\max_{i \\in [0:k)} \\nu_i, $$ where $\\nu_i$ are the constraint lengths of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; code.memory_order\n4\n</code></pre>"},{"location":"ref/ConvolutionalCode/#state_space_representation","title":"<code>state_space_representation()</code>  <code>cached</code>","text":"<p>Returns the matrices $(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\mathbf{D})$ corresponding to the state-space representation of the encoder realization. The state-space representation of the encoder is given by $$ \\begin{aligned}     s_{t+1} &amp; = s_t \\mathbf{A} + u_t \\mathbf{B}, \\\\     v_t &amp; = s_t \\mathbf{C} + u_t \\mathbf{D}, \\end{aligned} $$ where</p> <ul> <li>$u_t \\in \\mathbb{B}^k$ is the input block,</li> <li>$v_t \\in \\mathbb{B}^n$ is the output block,</li> <li>$s_t \\in \\mathbb{B}^\\sigma$ is the state,</li> <li>$\\mathbf{A} \\in \\mathbb{B}^{\\sigma \\times \\sigma}$ is the state matrix,</li> <li>$\\mathbf{B} \\in \\mathbb{B}^{k \\times \\sigma}$ is the control matrix,</li> <li>$\\mathbf{C} \\in \\mathbb{B}^{\\sigma \\times n}$ is the observation matrix,</li> <li>$\\mathbf{D} \\in \\mathbb{B}^{k \\times n}$ is the transition matrix.</li> </ul> <p>Returns:</p> <ul> <li> <code>state_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The state matrix $\\mathbf{A}$ of the encoder.</p> </li> <li> <code>control_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The control matrix $\\mathbf{B}$ of the encoder.</p> </li> <li> <code>observation_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The observation matrix $\\mathbf{C}$ of the encoder.</p> </li> <li> <code>transition_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The transition matrix $\\mathbf{D}$ of the encoder.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; A_mat, B_mat, C_mat, D_mat = code.state_space_representation()\n&gt;&gt;&gt; A_mat\narray([[0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0, 0]])\n&gt;&gt;&gt; B_mat\narray([[1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0]])\n&gt;&gt;&gt; C_mat\narray([[0, 1, 0],\n       [0, 1, 0],\n       [1, 0, 0],\n       [1, 1, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       [0, 1, 1]])\n&gt;&gt;&gt; D_mat\narray([[1, 1, 0],\n       [0, 0, 1]])\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o27, 0o31]], [0o27])\n&gt;&gt;&gt; A_mat, B_mat, C_mat, D_mat = code.state_space_representation()\n&gt;&gt;&gt; A_mat\narray([[1, 1, 0, 0],\n       [1, 0, 1, 0],\n       [0, 0, 0, 1],\n       [1, 0, 0, 0]])\n&gt;&gt;&gt; B_mat\narray([[1, 0, 0, 0]])\n&gt;&gt;&gt; C_mat\narray([[0, 1],\n       [0, 1],\n       [0, 1],\n       [0, 0]])\n&gt;&gt;&gt; D_mat\narray([[1, 1]])\n</code></pre>"},{"location":"ref/ConvolutionalCode/#finite_state_machine","title":"<code>finite_state_machine()</code>  <code>cached</code>","text":"<p>Returns the finite-state (Mealy) machine of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0b111, 0b101]])\n&gt;&gt;&gt; code.finite_state_machine()\nMealyMachine(transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n             outputs=[[0, 3], [1, 2], [3, 0], [2, 1]])\n</code></pre>"},{"location":"ref/ConvolutionalCode/#is_catastrophic","title":"<code>is_catastrophic()</code>  <code>cached</code>","text":"<p>Returns whether the encoder is catastrophic. A convolutional encoder is catastrophic if there exists an infinite-weight input sequence that generates a finite-weight output sequence.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0b111, 0b101]])\n&gt;&gt;&gt; code.is_catastrophic()\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0b11, 0b101]])\n&gt;&gt;&gt; code.is_catastrophic()\nTrue\n</code></pre>"},{"location":"ref/ConvolutionalCode/#free_distance","title":"<code>free_distance()</code>  <code>cached</code>","text":"<p>Returns the free distance $d_\\mathrm{free}$ of the code. This is equal to the minimum Hamming weight among all possible non-zero output sequences.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0o31, 0o27, 0o0], [0o0, 0o12, 0o15]])\n&gt;&gt;&gt; code.free_distance()\n5\n</code></pre>"},{"location":"ref/ConvolutionalCode/#encode","title":"<code>encode()</code>","text":"<p>Encodes a given bit sequence, starting from the all-zero state.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The bit sequence to be encoded. Must be a 1D-array of bits, with length multiple of $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The encoded bit sequence. It is a 1D-array of bits, with length multiple of $n$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0b111, 0b101]])\n&gt;&gt;&gt; code.encode([1, 1, 1, 1])\narray([1, 1, 0, 1, 1, 0, 1, 0])\n</code></pre>"},{"location":"ref/ConvolutionalCode/#encode_with_state","title":"<code>encode_with_state()</code>","text":"<p>Encodes a given bit sequence, starting from a given state.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The bit sequence to be encoded. Must be a 1D-array of bits, with length multiple of $k$.</p> </li> <li> <code>initial_state</code> (<code>ArrayLike</code>)         \u2013          <p>The initial state. Must be a 1D-array of length $\\sigma$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The encoded bit sequence. It is a 1D-array of bits, with length multiple of $n$.</p> </li> <li> <code>final_state</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The final state. It is a 1D-array of length $\\sigma$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ConvolutionalCode([[0b111, 0b101]])\n&gt;&gt;&gt; code.encode_with_state([1, 1, 1, 1], [0, 0])\n(array([1, 1, 0, 1, 1, 0, 1, 0]), array([1, 1]))\n&gt;&gt;&gt; code.encode_with_state([1, 1, 1, 1], [1, 1])\n(array([1, 0, 1, 0, 1, 0, 1, 0]), array([1, 1]))\n</code></pre>"},{"location":"ref/CordaroWagnerCode/","title":"komm.CordaroWagnerCode","text":"<p>Cordaro\u2013Wagner code. For a given length $n \\geq 2$, it is the linear block code with dimension $k = 2$ which is optimum for the BSC with sufficiently small crossover probability. For more details, see CW67.</p> <ul> <li>Length: $n$</li> <li>Dimension: $k = 2$</li> <li>Redundancy: $m = n - 2$</li> <li>Minimum distance: $d = \\left\\lceil 2n / 3 \\right\\rceil - 1$</li> </ul> <p>Parameters:</p> <ul> <li> <code>n</code> (<code>int</code>)         \u2013          <p>The length $n$ of the code. Must satisfy $n \\geq 2$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.CordaroWagnerCode(11)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(11, 2, 9)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n7\n&gt;&gt;&gt; code.codeword_weight_distribution()\narray([1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0])\n&gt;&gt;&gt; code.coset_leader_weight_distribution()\narray([  1,  11,  55, 165, 226,  54,   0,   0,   0,   0,   0,   0])\n</code></pre>"},{"location":"ref/CyclicCode/","title":"komm.CyclicCode","text":"<p>General binary cyclic code. A cyclic code is a linear block code such that, if $c$ is a codeword, then every cyclic shift of $c$ is also a codeword. It is characterized by its generator polynomial $g(X)$, of degree $m$ (the redundancy of the code), and by its check polynomial $h(X)$, of degree $k$ (the dimension of the code). Those polynomials are related by $g(X) h(X) = X^n + 1$, where $n = k + m$ is the length of the code.</p> <p>Examples of generator polynomials can be found in the table below.</p> Code $(n, k, d)$ Generator polynomial $g(X)$ Integer representation Hamming $(7,4,3)$ $X^3 + X + 1$ <code>0b1011 = 0o13 = 11</code> Simplex $(7,3,4)$ $X^4 + X^2 + X +   1$ <code>0b10111 = 0o27 = 23</code> BCH $(15,5,7)$ $X^{10} + X^8 + X^5 + X^4 + X^2 + X + 1$ <code>0b10100110111 = 0o2467 = 1335</code> Golay $(23,12,7)$ $X^{11} + X^9 + X^7 + X^6 + X^5 + X + 1$ <code>0b101011100011 = 0o5343 = 2787</code> <p>For more details, see LC04, Ch. 5 and McE04, Ch. 8.</p> <p>The constructor expects either the generator polynomial or the check polynomial.</p> <p>Parameters:</p> <ul> <li> <code>length</code> (<code>int</code>)         \u2013          <p>The length $n$ of the code.</p> </li> <li> <code>generator_polynomial</code> (<code>SupportsInt | None</code>)         \u2013          <p>The generator polynomial $g(X)$ of the code, of degree $m$ (the redundancy of the code), specified either as a binary polynomial or as an integer to be converted to the former.</p> </li> <li> <code>check_polynomial</code> (<code>SupportsInt | None</code>)         \u2013          <p>The check polynomial $h(X)$ of the code, of degree $k$ (the dimension of the code), specified either as a binary polynomial or as an integer to be converted to the former.</p> </li> <li> <code>systematic</code> (<code>bool</code>)         \u2013          <p>Whether the encoder is systematic. Default is <code>True</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.CyclicCode(length=23, generator_polynomial=0b101011100011)  # Golay (23, 12)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(23, 12, 11)\n&gt;&gt;&gt; code.minimum_distance()\n7\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.CyclicCode(length=23, check_polynomial=0b1010010011111)  # Golay (23, 12)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(23, 12, 11)\n&gt;&gt;&gt; code.minimum_distance()\n7\n</code></pre>"},{"location":"ref/CyclicCode/#length","title":"<code>length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The length $n$ of the code.</p>"},{"location":"ref/CyclicCode/#dimension","title":"<code>dimension</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The dimension $k$ of the code.</p>"},{"location":"ref/CyclicCode/#redundancy","title":"<code>redundancy</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The redundancy $m$ of the code.</p>"},{"location":"ref/CyclicCode/#rate","title":"<code>rate</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The rate $R = k/n$ of the code.</p>"},{"location":"ref/CyclicCode/#generator_matrix","title":"<code>generator_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The generator matrix $G \\in \\mathbb{B}^{k \\times n}$ of the code.</p>"},{"location":"ref/CyclicCode/#check_matrix","title":"<code>check_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The check matrix $H \\in \\mathbb{B}^{m \\times n}$ of the code.</p>"},{"location":"ref/CyclicCode/#encode","title":"<code>encode()</code>","text":"<p>Applies the encoding mapping $\\Enc : \\mathbb{B}^k \\to \\mathbb{B}^n$ of the code. This method takes one or more sequences of messages and returns their corresponding codeword sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $k$, or a multidimensional array where the last dimension is a multiple of $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension expanded from $bk$ to $bn$, where $b$ is a positive integer.</p> </li> </ul>"},{"location":"ref/CyclicCode/#inverse_encode","title":"<code>inverse_encode()</code>","text":"<p>Applies the inverse encoding partial mapping $\\Enc^{-1} : \\mathbb{B}^n \\rightharpoonup \\mathbb{B}^k$ of the code. This method takes one or more sequences of codewords and returns their corresponding message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the input contains any invalid codewords.</p> </li> </ul>"},{"location":"ref/CyclicCode/#check","title":"<code>check()</code>","text":"<p>Applies the check mapping $\\mathrm{Chk} : \\mathbb{B}^n \\to \\mathbb{B}^m$ of the code. This method takes one or more sequences of received words and returns their corresponding syndrome sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bm$, where $b$ is a positive integer.</p> </li> </ul>"},{"location":"ref/CyclicCode/#codewords","title":"<code>codewords()</code>  <code>cached</code>","text":"<p>Returns the codewords of the code. This is a $2^k \\times n$ matrix whose rows are all the codewords. The codeword in row $i$ corresponds to the message obtained by expressing $i$ in binary with $k$ bits (MSB in the right).</p>"},{"location":"ref/CyclicCode/#codeword_weight_distribution","title":"<code>codeword_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the codeword weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of codewords of Hamming weight $w$, for $w \\in [0 : n]$.</p>"},{"location":"ref/CyclicCode/#minimum_distance","title":"<code>minimum_distance()</code>  <code>cached</code>","text":"<p>Returns the minimum distance $d$ of the code. This is equal to the minimum Hamming weight of the non-zero codewords.</p>"},{"location":"ref/CyclicCode/#coset_leaders","title":"<code>coset_leaders()</code>  <code>cached</code>","text":"<p>Returns the coset leaders of the code. This is a $2^m \\times n$ matrix whose rows are all the coset leaders. The coset leader in row $i$ corresponds to the syndrome obtained by expressing $i$ in binary with $m$ bits (MSB in the right), and whose Hamming weight is minimal. This may be used as a LUT for syndrome-based decoding.</p>"},{"location":"ref/CyclicCode/#coset_leader_weight_distribution","title":"<code>coset_leader_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the coset leader weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of coset leaders of weight $w$, for $w \\in [0 : n]$.</p>"},{"location":"ref/CyclicCode/#packing_radius","title":"<code>packing_radius()</code>  <code>cached</code>","text":"<p>Returns the packing radius of the code. This is also called the error-correcting capability of the code, and is equal to $\\lfloor (d - 1) / 2 \\rfloor$.</p>"},{"location":"ref/CyclicCode/#covering_radius","title":"<code>covering_radius()</code>  <code>cached</code>","text":"<p>Returns the covering radius of the code. This is equal to the maximum Hamming weight of the coset leaders.</p>"},{"location":"ref/CyclicRedundancyCheck/","title":"komm.CyclicRedundancyCheck","text":"<p>Cyclic redundancy check (CRC) [Not implemented yet].</p>"},{"location":"ref/DiscreteMemorylessChannel/","title":"komm.DiscreteMemorylessChannel","text":"<p>General discrete memoryless channel (DMC). It is defined by an input alphabet $\\mathcal{X}$, an output alphabet $\\mathcal{Y}$, and a transition probability matrix $p_{Y \\mid X}$. Here, for simplicity, the input and output alphabets are always taken as $\\mathcal{X} = [0 : |\\mathcal{X}|)$ and $\\mathcal{Y} = [0 : |\\mathcal{Y}|)$, respectively. The transition probability matrix $p_{Y \\mid X}$, of size $|\\mathcal{X}|$-by-$|\\mathcal{Y}|$, gives the conditional probability of receiving $Y = y$ given that $X = x$ is transmitted. For more details, see CT06, Ch. 7.</p> <p>Parameters:</p> <ul> <li> <code>transition_matrix</code> (<code>ArrayLike</code>)         \u2013          <p>The channel transition probability matrix $p_{Y \\mid X}$. The element in row $x \\in \\mathcal{X}$ and column $y \\in \\mathcal{Y}$ must be equal to $p_{Y \\mid X}(y \\mid x)$.</p> </li> </ul>"},{"location":"ref/DiscreteMemorylessChannel/#input_cardinality","title":"<code>input_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel input cardinality $|\\mathcal{X}|$.</p>"},{"location":"ref/DiscreteMemorylessChannel/#output_cardinality","title":"<code>output_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel output cardinality $|\\mathcal{Y}|$.</p>"},{"location":"ref/DiscreteMemorylessChannel/#transition_matrix","title":"<code>transition_matrix</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The channel transition probability matrix $p_{Y \\mid X}$.</p>"},{"location":"ref/DiscreteMemorylessChannel/#mutual_information","title":"<code>mutual_information()</code>","text":"<p>Returns the mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$ of the channel.</p> <p>Parameters:</p> <ul> <li> <code>input_pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function $p_X$ of the channel input $X$. It must be a valid pmf, that is, all of its values must be non-negative and sum up to $1$.</p> </li> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$.</p> </li> </ul> <p>The mutual information is given by $$     \\mathrm{I}(X; Y) = \\mathrm{H}(X) - \\mathrm{H}(X \\mid Y), $$ where $\\mathrm{H}(X)$ is the the entropy of $X$ and $\\mathrm{H}(X \\mid Y)$ is the conditional entropy of $X$ given $Y$. By default, the base of the logarithm is $2$, in which case the mutual information is measured in bits. See CT06, Ch. 2.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dmc = komm.DiscreteMemorylessChannel([\n...     [0.6, 0.3, 0.1],\n...     [0.7, 0.1, 0.2],\n...     [0.5, 0.05, 0.45],\n... ])\n&gt;&gt;&gt; dmc.mutual_information([1/3, 1/3, 1/3])\nnp.float64(0.12381109879798724)\n&gt;&gt;&gt; dmc.mutual_information([1/3, 1/3, 1/3], base=3)\nnp.float64(0.07811610605402552)\n&gt;&gt;&gt; dmc.mutual_information([1/3, 1/3, 1/3], base='e')\nnp.float64(0.08581931405385379)\n</code></pre>"},{"location":"ref/DiscreteMemorylessChannel/#capacity","title":"<code>capacity()</code>","text":"<p>Returns the channel capacity $C$.</p> <p>Parameters:</p> <ul> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The channel capacity $C$.</p> </li> </ul> <p>The channel capacity is given by $$     C = \\max_{p_X} \\mathrm{I}(X; Y). $$ This method computes the channel capacity via the Arimoto\u2013Blahut algorithm. See CT06, Sec. 10.8.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dmc = komm.DiscreteMemorylessChannel([\n...     [0.6, 0.3, 0.1],\n...     [0.7, 0.1, 0.2],\n...     [0.5, 0.05, 0.45],\n... ])\n&gt;&gt;&gt; dmc.capacity()\nnp.float64(0.1616318609548566)\n&gt;&gt;&gt; dmc.capacity(base=3)\nnp.float64(0.10197835020154389)\n&gt;&gt;&gt; dmc.capacity(base='e')\nnp.float64(0.11203466870951606)\n</code></pre>"},{"location":"ref/DiscreteMemorylessChannel/#__call__","title":"<code>__call__()</code>","text":"<p>Transmits the input sequence through the channel and returns the output sequence.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dmc = komm.DiscreteMemorylessChannel([\n...     [0.9, 0.05, 0.05],\n...     [0.0, 0.5, 0.5],\n... ])\n&gt;&gt;&gt; dmc([1, 1, 1, 0, 0, 0, 1, 0, 1, 0])\narray([2, 1, 2, 0, 0, 2, 2, 0, 1, 0])\n</code></pre>"},{"location":"ref/DiscreteMemorylessSource/","title":"komm.DiscreteMemorylessSource","text":"<p>Discrete memoryless source (DMS). It is defined by an alphabet $\\mathcal{X}$ and a probability mass function (pmf) $p_X$. Here, for simplicity, the alphabet is always taken as $\\mathcal{X} = [0 : |\\mathcal{X}|)$. The pmf $p_X$ gives the probability of the source emitting the symbol $X = x$.</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike | int</code>)         \u2013          <p>Either the source pmf $p_X$, in which case the element at position $x \\in \\mathcal{X}$ must be equal to $p_X(x)$, or an integer $n \\geq 1$, in which case a uniform distribution over $n$ symbols is used.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.DiscreteMemorylessSource([1/2, 1/4, 1/8, 1/8])\nDiscreteMemorylessSource(pmf=[0.5, 0.25, 0.125, 0.125])\n</code></pre> <pre><code>&gt;&gt;&gt; komm.DiscreteMemorylessSource(4)\nDiscreteMemorylessSource(pmf=[0.25, 0.25, 0.25, 0.25])\n</code></pre>"},{"location":"ref/DiscreteMemorylessSource/#cardinality","title":"<code>cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The cardinality $|\\mathcal{X}|$ of the source alphabet.</p>"},{"location":"ref/DiscreteMemorylessSource/#entropy","title":"<code>entropy()</code>","text":"<p>Returns the source entropy $\\mathrm{H}(X)$. See <code>komm.entropy</code> for more details.</p> <p>Parameters:</p> <ul> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>See <code>komm.entropy</code>. The default value is $2.0$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dms = komm.DiscreteMemorylessSource([1/2, 1/4, 1/8, 1/8])\n&gt;&gt;&gt; dms.entropy()\nnp.float64(1.75)\n&gt;&gt;&gt; dms.entropy(base=4)\nnp.float64(0.875)\n</code></pre>"},{"location":"ref/DiscreteMemorylessSource/#__call__","title":"<code>__call__()</code>","text":"<p>Returns random samples from the source.</p> <p>Parameters:</p> <ul> <li> <code>shape</code> (<code>int | tuple[int, ...]</code>)         \u2013          <p>The shape of the output array. If <code>shape</code> is an integer, the output array will have shape <code>(shape,)</code>. The default value is <code>()</code>, which returns a single sample.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[integer]</code>         \u2013          <p>An array of shape <code>shape</code> with random samples from the source.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dms = komm.DiscreteMemorylessSource([0.5, 0.4, 0.1])\n&gt;&gt;&gt; dms()\narray(1)\n&gt;&gt;&gt; dms(10)\narray([0, 1, 1, 0, 2, 1, 1, 0, 0, 0])\n&gt;&gt;&gt; dms((2, 5))\narray([[2, 1, 1, 0, 0],\n       [1, 0, 1, 1, 1]])\n</code></pre>"},{"location":"ref/ExhaustiveSearchDecoder/","title":"komm.ExhaustiveSearchDecoder","text":"<p>Exhaustive search decoder for general block codes. This decoder implements a brute-force search over all possible codewords to find the one that is closest (in terms of Hamming distance, for hard-decision decoding, or Euclidean distance, for soft-decision decoding) to the received word.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>BlockCode</code>)         \u2013          <p>The block code to be used for decoding.</p> </li> <li> <code>input_type</code> (<code>Literal['hard', 'soft']</code>)         \u2013          <p>The type of the input. Either <code>'hard'</code> or <code>'soft'</code>. Default is <code>'hard'</code>.</p> </li> </ul> Notes <ul> <li>Input type: <code>hard</code> (bits) or <code>soft</code> (either L-values or channel outputs).</li> <li>Output type: <code>hard</code> (bits).</li> </ul>"},{"location":"ref/ExhaustiveSearchDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HammingCode(3)\n&gt;&gt;&gt; decoder = komm.ExhaustiveSearchDecoder(code, input_type=\"hard\")\n&gt;&gt;&gt; decoder([[1, 1, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0]])\narray([[1, 1, 0, 0],\n       [1, 0, 1, 1]])\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.HammingCode(3)\n&gt;&gt;&gt; decoder = komm.ExhaustiveSearchDecoder(code, input_type=\"soft\")\n&gt;&gt;&gt; decoder([[-1, -1, +1, -1, +1, -1, -1], [-1, +1, -1, -1, +1, +1, +1]])\narray([[1, 1, 0, 0],\n       [1, 0, 1, 1]])\n</code></pre>"},{"location":"ref/FanoCode/","title":"komm.FanoCode","text":"<p>Binary Fano code. It is a fixed-to-variable length code in which the source words are first sorted in descending order of probability and then are recursively partitioned into two groups of approximately equal total probability, assigning bit $\\mathtt{0}$ to one group and bit $\\mathtt{1}$ to the other, until each source word is assigned a unique codeword. For more details, see Wikipedia: Shannon\u2013Fano coding.</p> Notes <p>Fano codes are always prefix-free (hence uniquely decodable).</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function of the source.</p> </li> <li> <code>source_block_size</code> (<code>int</code>)         \u2013          <p>The source block size $k$. The default value is $k = 1$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pmf = [0.7, 0.15, 0.15]\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FanoCode(pmf, 1)\n&gt;&gt;&gt; code.enc_mapping\n{(0,): (0,),\n (1,): (1, 0),\n (2,): (1, 1)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(1.3)\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FanoCode(pmf, 2)\n&gt;&gt;&gt; code.enc_mapping\n{(0, 0): (0,),\n (0, 1): (1, 0, 0),\n (0, 2): (1, 0, 1),\n (1, 0): (1, 1, 0),\n (1, 1): (1, 1, 1, 1, 0, 0),\n (1, 2): (1, 1, 1, 1, 0, 1),\n (2, 0): (1, 1, 1, 0),\n (2, 1): (1, 1, 1, 1, 1, 0),\n (2, 2): (1, 1, 1, 1, 1, 1)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(1.1975)\n</code></pre>"},{"location":"ref/FibonacciCode/","title":"komm.FibonacciCode","text":"<p>Fibonacci code. It is an integer code. For the definition of this code, see Wikipedia: Fibonacci coding.</p>"},{"location":"ref/FibonacciCode/#encode","title":"<code>encode()</code>","text":"<p>Encode the input integer array.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input integer array. It must be a one-dimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of bits corresponding to the input integer array.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FibonacciCode()\n&gt;&gt;&gt; code.encode([4, 1, 3])\narray([1, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n</code></pre>"},{"location":"ref/FibonacciCode/#decode","title":"<code>decode()</code>","text":"<p>Decode the input bit array.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input bit array. It must be a one-dimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of integers corresponding to the input bit array.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FibonacciCode()\n&gt;&gt;&gt; code.decode([1, 0, 1, 1, 1, 1, 0, 0, 1, 1])\narray([4, 1, 3])\n</code></pre>"},{"location":"ref/FiniteBifield/","title":"komm.FiniteBifield","text":"<p>Finite field with binary characteristic. Objects of this class represent a finite field $\\mathrm{GF}(2^k)$ (also known as Galois field), with characteristic $2$ and degree $k$.</p> <p>Parameters:</p> <ul> <li> <code>degree</code> (<code>int</code>)         \u2013          <p>Degree $k$ of the finite field. Must be a positive integer.</p> </li> <li> <code>modulus</code> (<code>BinaryPolynomial | int | None</code>)         \u2013          <p>Modulus $p(X)$ of the field, specified either as a binary polynomial or as an integer to be converted to the former. Must be an irreducible polynomial. If not specified, the modulus is chosen from the list of default primitive polynomials.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; field = komm.FiniteBifield(4)\n&gt;&gt;&gt; field\nFiniteBifield(4)\n&gt;&gt;&gt; (field.characteristic, field.degree, field.order)\n(2, 4, 16)\n&gt;&gt;&gt; field.modulus\nBinaryPolynomial(0b10011)\n</code></pre> <pre><code>&gt;&gt;&gt; field = komm.FiniteBifield(4, modulus=0b11001)\n&gt;&gt;&gt; field\nFiniteBifield(4, modulus=0b11001)\n&gt;&gt;&gt; (field.characteristic, field.degree, field.order)\n(2, 4, 16)\n&gt;&gt;&gt; field.modulus\nBinaryPolynomial(0b11001)\n</code></pre> Construction of elements <p>To construct elements of the finite field, call the finite field object. For example, <code>field(0b1101)</code> will construct the element whose polynomial representation is $X^3 + X^2 + 1$.</p> Algebraic structure <p>The following operations are supported: addition (<code>+</code>), subtraction (<code>-</code>), multiplication (<code>*</code>), division (<code>/</code>), and exponentiation (<code>**</code>).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; field = komm.FiniteBifield(4)\n&gt;&gt;&gt; x = field(0b1011)\n&gt;&gt;&gt; y = field(0b1100)\n&gt;&gt;&gt; x + y\n0b111\n&gt;&gt;&gt; x - y\n0b111\n&gt;&gt;&gt; x * y\n0b1101\n&gt;&gt;&gt; x / y\n0b10\n&gt;&gt;&gt; x**2\n0b1001\n</code></pre> Further methods on elements <p>The following methods are available on elements of the finite field:</p> <ul> <li><code>logarithm(base)</code>: Returns the logarithm of the element, with respect to a given base.</li> <li><code>conjugates()</code>: Returns the conjugates of the element.</li> <li><code>minimal_polynomial()</code>: Returns the minimal polynomial of the element.</li> </ul> <p>For more details, see LC04, Sec. 2.5.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; field = komm.FiniteBifield(4)\n&gt;&gt;&gt; x = field(0b1011)\n&gt;&gt;&gt; base = field(0b10)\n&gt;&gt;&gt; x.logarithm(base)\n7\n&gt;&gt;&gt; x.conjugates()\n[0b1011, 0b1001, 0b1101, 0b1110]\n&gt;&gt;&gt; x.minimal_polynomial()\nBinaryPolynomial(0b11001)\n</code></pre>"},{"location":"ref/FiniteBifield/#characteristic","title":"<code>characteristic</code><code>  int </code>  <code>property</code>","text":"<p>The characteristic $2$ of the finite field.</p>"},{"location":"ref/FiniteBifield/#order","title":"<code>order</code><code>  int </code>  <code>property</code>","text":"<p>The order (number of elements) of the finite field. It is given by $2^k$.</p>"},{"location":"ref/FixedToVariableCode/","title":"komm.FixedToVariableCode","text":"<p>General fixed-to-variable length code. A fixed-to-variable length code with source alphabet $\\mathcal{S}$, target alphabet $\\mathcal{T}$, and source block size $k$ is defined by an encoding mapping $\\Enc : \\mathcal{S}^k \\to \\mathcal{T}^+$, where the domain is the set of all $k$-tuples with entries in $\\mathcal{S}$, and the co-domain is the set of all finite-length, non-empty tuples with entries in $\\mathcal{T}$. Here we assume that $\\mathcal{S} = [0:S)$ and $\\mathcal{T} = [0:T)$, for integers $S \\geq 2$ and $T \\geq 2$. The elements in the image of $\\Enc$ are called codewords.</p>"},{"location":"ref/FixedToVariableCode/#from_enc_mapping","title":"<code>from_enc_mapping()</code>  <code>classmethod</code>","text":"<p>Constructs a fixed-to-variable length code from the encoding mapping $\\Enc$.</p> <p>Parameters:</p> <ul> <li> <code>enc_mapping</code> (<code>dict[Word, Word]</code>)         \u2013          <p>The encoding mapping $\\Enc$. Must be a dictionary whose keys are all the $k$-tuples of integers in $[0:S)$ and whose values are non-empty tuples of integers in $[0:T)$.</p> </li> </ul> Notes <p>The source block size $k$ is inferred from the domain of the encoding mapping, and the source and target cardinalities $S$ and $T$ are inferred from the maximum values in the domain and co-domain, respectively.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_enc_mapping({\n...     (0,): (0,),\n...     (1,): (1, 0),\n...     (2,): (1, 1),\n... })\n&gt;&gt;&gt; code.source_cardinality, code.target_cardinality, code.source_block_size\n(3, 2, 1)\n&gt;&gt;&gt; code.codewords\n[(0,), (1, 0), (1, 1)]\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_enc_mapping({\n...     (0, 0): (0,),\n...     (0, 1): (1, 1),\n...     (1, 0): (1, 1, 0),\n...     (1, 1): (1, 0, 1),\n... })\n&gt;&gt;&gt; code.source_cardinality, code.target_cardinality, code.source_block_size\n(2, 2, 2)\n&gt;&gt;&gt; code.codewords\n[(0,), (1, 1), (1, 1, 0), (1, 0, 1)]\n</code></pre>"},{"location":"ref/FixedToVariableCode/#from_codewords","title":"<code>from_codewords()</code>  <code>classmethod</code>","text":"<p>Constructs a fixed-to-variable length code from the source cardinality $S$ and a list of codewords.</p> <p>Parameters:</p> <ul> <li> <code>source_cardinality</code> (<code>int</code>)         \u2013          <p>The source cardinality $S$. Must be an integer greater than or equal to $2$.</p> </li> <li> <code>codewords</code> (<code>list[Word]</code>)         \u2013          <p>The codewords of the code. Must be a list of length $S^k$ containing tuples of integers in $[0:T)$, where $T$ is the target cardinality of the code. The tuple in position $i$ must be equal to $\\Enc(u)$, where $u$ is the $i$-th element in the lexicographic ordering of $[0:S)^k$.</p> </li> </ul> Notes <p>The source block size $k$ is inferred from the length of the codewords, and the target cardinality $T$ is inferred from the maximum value in the codewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(\n...     source_cardinality=3,\n...     codewords=[(0,), (1,0), (1,1)],\n... )\n&gt;&gt;&gt; code.source_cardinality, code.target_cardinality, code.source_block_size\n(3, 2, 1)\n&gt;&gt;&gt; code.enc_mapping\n{(0,): (0,),\n (1,): (1, 0),\n (2,): (1, 1)}\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(\n...     source_cardinality=2,\n...     codewords=[(0,), (1,1), (1,1,0), (1,0,1)]\n... )\n&gt;&gt;&gt; (code.source_cardinality, code.target_cardinality, code.source_block_size)\n(2, 2, 2)\n&gt;&gt;&gt; code.enc_mapping\n{(0, 0): (0,),\n (0, 1): (1, 1),\n (1, 0): (1, 1, 0),\n (1, 1): (1, 0, 1)}\n</code></pre>"},{"location":"ref/FixedToVariableCode/#source_cardinality","title":"<code>source_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The source cardinality $S$ of the code. It is the number of symbols in the source alphabet.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.source_cardinality\n3\n</code></pre>"},{"location":"ref/FixedToVariableCode/#target_cardinality","title":"<code>target_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The target cardinality $T$ of the code. It is the number of symbols in the target alphabet.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.target_cardinality\n2\n</code></pre>"},{"location":"ref/FixedToVariableCode/#source_block_size","title":"<code>source_block_size</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The source block size $k$ of the code. It is the number of symbols in each source block.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.source_block_size\n1\n</code></pre>"},{"location":"ref/FixedToVariableCode/#size","title":"<code>size</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of codewords in the code. It is equal to $S^k$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.size\n3\n</code></pre>"},{"location":"ref/FixedToVariableCode/#enc_mapping","title":"<code>enc_mapping</code><code>  dict[Word, Word] </code>  <code>cached</code> <code>property</code>","text":"<p>The encoding mapping $\\Enc$ of the code. It is a dictionary of length $S^k$ whose keys are all the $k$-tuples of integers in $[0:S)$ and whose values are the corresponding codewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.enc_mapping\n{(0,): (0,), (1,): (1, 0), (2,): (1, 1)}\n</code></pre>"},{"location":"ref/FixedToVariableCode/#codewords","title":"<code>codewords</code><code>  list[Word] </code>  <code>cached</code> <code>property</code>","text":"<p>The codewords of the code. They correspond to the image of the encoding mapping $\\Enc$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_enc_mapping({\n...     (0,): (0,),\n...     (1,): (1, 0),\n...     (2,): (1, 1),\n... })\n&gt;&gt;&gt; code.codewords\n[(0,), (1, 0), (1, 1)]\n</code></pre>"},{"location":"ref/FixedToVariableCode/#is_uniquely_decodable","title":"<code>is_uniquely_decodable()</code>  <code>cached</code>","text":"<p>Returns whether the code is uniquely decodable. A code is uniquely decodable if there is a unique way to parse any concatenation of codewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.is_uniquely_decodable()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (0,1), (1,1)])\n&gt;&gt;&gt; code.is_uniquely_decodable()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (0,1), (1,0)])\n&gt;&gt;&gt; code.is_uniquely_decodable()  # 010 can be parsed as 0|10 or 01|0\nFalse\n</code></pre>"},{"location":"ref/FixedToVariableCode/#is_prefix_free","title":"<code>is_prefix_free()</code>  <code>cached</code>","text":"<p>Returns whether the code is prefix-free. A code is prefix-free if no codeword is a prefix of any other codeword.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.is_prefix_free()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (0,1), (1,1)])\n&gt;&gt;&gt; code.is_prefix_free()\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (0,1), (1,0)])\n&gt;&gt;&gt; code.is_prefix_free()\nFalse\n</code></pre>"},{"location":"ref/FixedToVariableCode/#kraft_parameter","title":"<code>kraft_parameter()</code>  <code>cached</code>","text":"<p>Computes the Kraft parameter $K$ of the code. This quantity is given by $$     K = \\sum_{u \\in \\mathcal{S}^k} T^{-{\\ell_u}}, $$ where $\\ell_u$ is the length of the codeword $\\Enc(u)$, $T$ is the target cardinality, and $k$ is the source block size.</p> <p>Returns:</p> <ul> <li> <code>kraft_parameter</code>  (<code>float</code>)          \u2013          <p>The Kraft parameter $K$ of the code.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(5, [(0,0,0), (0,0,1), (0,1,0), (1,0,1), (1,1)])\n&gt;&gt;&gt; code.kraft_parameter()\nnp.float64(0.75)\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(4, [(0,), (1,0), (1,1,0), (1,1,1)])\n&gt;&gt;&gt; code.kraft_parameter()\nnp.float64(1.0)\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(4, [(0,0), (1,1), (0,), (1,)])\n&gt;&gt;&gt; code.kraft_parameter()\nnp.float64(1.5)\n</code></pre>"},{"location":"ref/FixedToVariableCode/#rate","title":"<code>rate()</code>","text":"<p>Computes the expected rate $R$ of the code, considering a given pmf. This quantity is given by $$     R = \\frac{\\bar{n}}{k}, $$ where $\\bar{n}$ is the expected codeword length, assuming iid source symbols drawn from $p_X$, and $k$ is the source block size. It is measured in $T$-ary digits per source symbol.</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The (first-order) probability mass function $p_X$ to be considered.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>rate</code>  (<code>float</code>)          \u2013          <p>The expected rate $R$ of the code.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.rate([1/2, 1/4, 1/4])\nnp.float64(1.5)\n</code></pre>"},{"location":"ref/FixedToVariableCode/#encode","title":"<code>encode()</code>","text":"<p>Encodes a sequence of source symbols using the code, which must be uniquely decodable.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be encoded. Must be a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code) and have a length that is a multiple of the source block size $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of encoded symbols. It is a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_enc_mapping({\n...     (0, 0): (0,),\n...     (0, 1): (1, 1),\n...     (1, 0): (1, 0, 0),\n...     (1, 1): (1, 0, 1),\n... })\n</code></pre> <pre><code>&gt;&gt;&gt; code.encode([0, 1, 0, 0])\narray([1, 1, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; code.encode([0, 1, 0])  # Not a multiple of the source block size\nTraceback (most recent call last):\n...\nValueError: length of input must be a multiple of block size 2 (got 3)\n</code></pre> <pre><code>&gt;&gt;&gt; code.encode([0, 7, 0, 0])  # 07 is not a valid source word\nTraceback (most recent call last):\n...\nValueError: input contains invalid word\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (0,1), (1,0)])\n&gt;&gt;&gt; code.encode([0, 1, 0])  # Code is not uniquely decodable\nTraceback (most recent call last):\n...\nValueError: code is not uniquely decodable\n</code></pre>"},{"location":"ref/FixedToVariableCode/#decode","title":"<code>decode()</code>","text":"<p>Decodes a sequence of target symbols using the code, which must be uniquely decodable.</p> Warning <p>Decoding for non-prefix-free codes is not implemented yet.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be decoded. Must be a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code). Also, the sequence must be a concatenation of codewords (i.e., the output of the <code>encode</code> method).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of decoded symbols. It is a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code) with a length that is a multiple of the source block size $k$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_enc_mapping({\n...     (0, 0): (0,),\n...     (0, 1): (1, 1),\n...     (1, 0): (1, 0, 0),\n...     (1, 1): (1, 0, 1),\n... })\n</code></pre> <pre><code>&gt;&gt;&gt; code.decode([1, 1, 0])\narray([0, 1, 0, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; code.decode([0, 0, 1])  # Not a concatenation of codewords\nTraceback (most recent call last):\n...\nValueError: input contains invalid word\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.FixedToVariableCode.from_codewords(3, [(0,), (0,1), (1,0)])\n&gt;&gt;&gt; code.decode([0, 1, 0])  # Code is not uniquely decodable\nTraceback (most recent call last):\n...\nValueError: code is not uniquely decodable\n</code></pre>"},{"location":"ref/GaussianPulse/","title":"komm.GaussianPulse","text":"<p>Gaussian pulse. It is a pulse with spectrum given by $$     \\hat{p}(f) = \\frac{1}{\\sqrt{2 \\pi} \\bar{B}} \\mathrm{e}^{-\\frac{1}{2} (f / \\bar{B})^2}, $$ where the $\\bar{B} = B / \\sqrt{\\ln 2}$, and $B$ is the half-power bandwidth of the filter.</p> <p>The waveform of the Gaussian pulse is depicted below for $B = 0.5$, and for $B = 1$.</p> <p> </p> <p>Parameters:</p> <ul> <li> <code>half_power_bandwidth</code> (<code>float</code>)         \u2013          <p>The half-power bandwidth $B$ of the pulse. The default value is <code>1.0</code>.</p> </li> </ul>"},{"location":"ref/GaussianPulse/#waveform","title":"<code>waveform()</code>","text":"<p>The waveform $p(t)$ of the pulse.</p> <p>For the Gaussian pulse, it is given by $$     p(t) = \\mathrm{e}^{-\\frac{1}{2} (2 \\pi \\bar{B} t)^2}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.GaussianPulse(half_power_bandwidth=0.25)\n&gt;&gt;&gt; pulse.waveform(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.169, 0.367, 0.641, 0.895, 1.   , 0.895, 0.641, 0.367, 0.169])\n</code></pre>"},{"location":"ref/GaussianPulse/#spectrum","title":"<code>spectrum()</code>","text":"<p>The spectrum $\\hat{p}(f)$ of the pulse.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.GaussianPulse(half_power_bandwidth=0.25)\n&gt;&gt;&gt; np.abs(pulse.spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )).round(3)\narray([0.005, 0.059, 0.332, 0.939, 1.329, 0.939, 0.332, 0.059, 0.005])\n</code></pre>"},{"location":"ref/GaussianPulse/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>The autocorrelation function $R(\\tau)$ of the pulse.</p> <p>For the Gaussian pulse, it is given by $$     R(\\tau) = \\frac{1}{2 \\sqrt{\\pi} \\bar{B}} \\mathbb{e}^{-(\\pi \\bar{B} \\tau)^2}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.GaussianPulse(half_power_bandwidth=0.25)\n&gt;&gt;&gt; pulse.autocorrelation(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.386, 0.569, 0.752, 0.889, 0.939, 0.889, 0.752, 0.569, 0.386])\n</code></pre>"},{"location":"ref/GaussianPulse/#energy_density_spectrum","title":"<code>energy_density_spectrum()</code>","text":"<p>The energy density spectrum $S(f)$ of the pulse.</p> <p>For the Gaussian pulse, it is given by $$     S(f) = \\frac{1}{2 \\pi \\bar{B}^2} \\mathrm{e}^{-(f / \\bar{B})^2}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.GaussianPulse(half_power_bandwidth=0.25)\n&gt;&gt;&gt; pulse.energy_density_spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.   , 0.003, 0.11 , 0.883, 1.765, 0.883, 0.11 , 0.003, 0.   ])\n</code></pre>"},{"location":"ref/GaussianPulse/#support","title":"<code>support</code><code>  tuple[float, float] </code>  <code>cached</code> <code>property</code>","text":"<p>The support of the pulse waveform $p(t)$, defined as the interval $[a, b]$ where $p(t)$ is non-zero.</p> <p>For the Gaussian pulse, the support is given by $(-\\infty, \\infty)$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.GaussianPulse(half_power_bandwidth=0.25)\n&gt;&gt;&gt; pulse.support\n(-inf, inf)\n</code></pre>"},{"location":"ref/GaussianPulse/#taps","title":"<code>taps()</code>","text":"<p>Returns the FIR taps of the pulse.</p> <p>Parameters:</p> <ul> <li> <code>samples_per_symbol</code> (<code>int</code>)         \u2013          <p>The number of samples per symbol.</p> </li> <li> <code>span</code> (<code>tuple[int, int] | None</code>)         \u2013          <p>The time span to consider for the taps. This parameter is optional for pulses with finite support (defaults to $[0, 1]$), but required for pulses with infinite support.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.GaussianPulse(half_power_bandwidth=0.25)\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-1, 1)).round(3)\narray([0.169, 0.367, 0.641, 0.895, 1.   , 0.895, 0.641, 0.367, 0.169])\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-16, 16)).shape\n(129,)\n</code></pre>"},{"location":"ref/GolayCode/","title":"komm.GolayCode","text":"<p>Binary Golay code. It is the linear block code with parity submatrix $$ P = \\begin{bmatrix}     1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 \\\\     0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\     0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\     1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\     1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\\\     1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\\\     0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\\\     0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\\\     0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\\\     1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\\\     1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 \\\\     1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix} $$</p> <p>The Golay code has the following parameters:</p> <ul> <li>Length: $23$</li> <li>Dimension: $12$</li> <li>Minimum distance: $7$</li> </ul> Notes <ul> <li>The binary Golay code is a perfect code.</li> </ul> <p>Parameters:</p> <ul> <li> <code>extended</code> (<code>bool</code>)         \u2013          <p>If <code>True</code>, constructs the code in extended version. The default value is <code>False</code>.</p> </li> </ul> <p>This class represents the code in systematic form, with the information set on the left.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.GolayCode()\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(23, 12, 11)\n&gt;&gt;&gt; code.minimum_distance()\n7\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.GolayCode(extended=True)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(24, 12, 12)\n&gt;&gt;&gt; code.minimum_distance()\n8\n</code></pre>"},{"location":"ref/GoldSequence/","title":"komm.GoldSequence","text":"<p>Gold sequence [Not implemented yet].</p>"},{"location":"ref/HammingCode/","title":"komm.HammingCode","text":"<p>Hamming code. For a given parameter $\\mu \\geq 2$, it is the linear block code with check matrix whose columns are all the $2^\\mu - 1$ nonzero binary $\\mu$-tuples. The Hamming code has the following parameters:</p> <ul> <li>Length: $n = 2^\\mu - 1$</li> <li>Dimension: $k = 2^\\mu - \\mu - 1$</li> <li>Redundancy: $m = \\mu$</li> <li>Minimum distance: $d = 3$</li> </ul> <p>In its extended version, the Hamming code has the following parameters:</p> <ul> <li>Length: $n = 2^\\mu$</li> <li>Dimension: $k = 2^\\mu - \\mu - 1$</li> <li>Redundancy: $m = \\mu + 1$</li> <li>Minimum distance: $d = 4$</li> </ul> <p>For more details, see LC04, Sec. 4.1.</p> Notes <ul> <li>For $\\mu = 2$ it reduces to the repetition code of length $3$.</li> <li>Its dual is the simplex code.</li> <li>Hamming codes are perfect codes.</li> </ul> <p>Parameters:</p> <ul> <li> <code>mu</code> (<code>int</code>)         \u2013          <p>The parameter $\\mu$ of the code. Must satisfy $\\mu \\geq 2$.</p> </li> <li> <code>extended</code> (<code>bool</code>)         \u2013          <p>Whether to use the extended version of the Hamming code. Default is <code>False</code>.</p> </li> </ul> <p>This class represents the code in systematic form, with the information set on the left.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HammingCode(3)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(7, 4, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 0, 1, 1, 0],\n       [0, 1, 0, 0, 1, 0, 1],\n       [0, 0, 1, 0, 0, 1, 1],\n       [0, 0, 0, 1, 1, 1, 1]])\n&gt;&gt;&gt; code.check_matrix\narray([[1, 1, 0, 1, 1, 0, 0],\n       [1, 0, 1, 1, 0, 1, 0],\n       [0, 1, 1, 1, 0, 0, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n3\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.HammingCode(3, extended=True)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(8, 4, 4)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 0, 1, 1, 0, 1],\n       [0, 1, 0, 0, 1, 0, 1, 1],\n       [0, 0, 1, 0, 0, 1, 1, 1],\n       [0, 0, 0, 1, 1, 1, 1, 0]])\n&gt;&gt;&gt; code.check_matrix\narray([[1, 1, 0, 1, 1, 0, 0, 0],\n       [1, 0, 1, 1, 0, 1, 0, 0],\n       [0, 1, 1, 1, 0, 0, 1, 0],\n       [1, 1, 1, 0, 0, 0, 0, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n4\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/","title":"komm.HighRateConvolutionalCode","text":"<p>High-rate convolutional encoder. It is an $(n, n-1)$ recursive systematic convolutional encoder defined by a single check row $h(D) \\in \\mathbb{F}_2[D]^n$ and realized in observable canonical form. By convention, the first $n - 1$ positions represent the information bits.</p> <p>Parameters:</p> <ul> <li> <code>h_row</code> (<code>ArrayLike</code>)         \u2013          <p>The check row $h(D)$ of the encoder. Must be an $n$-vector whose entries are either binary polynomials or integers to be converted to the former.</p> </li> </ul> <p>Examples:</p> <p>Consider the high-rate convolutional encoder with $(n, k, \\sigma) = (4, 3, 3)$ depicted below.</p> <p></p> <p>Its check row is given by $$     h(D) =     \\begin{bmatrix}         D^3 + D  &amp;&amp;  D^3 + D^2 + 1  &amp;&amp;  D^3 + D + 1  &amp;&amp;  D^3 + 1     \\end{bmatrix}. $$</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0b1010, 0b1101, 0b1011, 0b1001])\n&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n</code></pre> <p>Please refer to the table of optimal high-rate convolutional codes.</p>"},{"location":"ref/HighRateConvolutionalCode/#num_input_bits","title":"<code>num_input_bits</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of input bits per block, $k$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.num_input_bits\n3\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#num_output_bits","title":"<code>num_output_bits</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of output bits per block, $n$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.num_output_bits\n4\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#degree","title":"<code>degree</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The degree $\\sigma$ of the encoder. This corresponds to the number of delay elements in the encoder realization.</p> <p>For a high-rate convolutional encoder realized in observable canonical form, the degree $\\sigma$ is the maximum degree of the polynomials in the check row $h(D)$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.degree\n3\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#generator_matrix","title":"<code>generator_matrix</code><code>  Array2D[object_] </code>  <code>cached</code> <code>property</code>","text":"<p>Returns the (transform-domain) generator matrix (also known as transfer function matrix) $G(D)$ of the encoder. This is a $k \\times n$ array of binary polynomial fractions.</p> <p>For a high-rate convolutional code with check row $$     h(D) =     \\begin{bmatrix}         h_0(D)  &amp;&amp;  h_1(D)  &amp;&amp;  \\cdots  &amp;&amp;  h_{n-1}(D)     \\end{bmatrix}, $$ the generator matrix is given by $$     G(D) =     \\begin{bmatrix}         1      &amp; 0      &amp; \\cdots &amp; 0      &amp; h_0(D) / h_{n-1}(D)     \\\\[1ex]         0      &amp; 1      &amp; \\cdots &amp; 0      &amp; h_1(D) / h_{n-1}(D)     \\\\[1ex]         \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots                  \\\\[1ex]         0      &amp; 0      &amp; \\cdots &amp; 1      &amp; h_{n-2}(D) / h_{n-1}(D)     \\end{bmatrix}. $$</p> <p>Examples:</p> <p>If the check row is $$     h(D) =     \\begin{bmatrix}         D^3 + D  &amp;&amp;  D^3 + D^2 + 1  &amp;&amp;  D^3 + D + 1  &amp;&amp;  D^3 + 1     \\end{bmatrix}, $$ then the generator matrix is $$     G(D) =     \\begin{bmatrix}         1 &amp; 0 &amp; 0 &amp; \\frac{D^3 + D}{D^3 + 1} \\\\[1ex]         0 &amp; 1 &amp; 0 &amp; \\frac{D^3 + D^2 + 1}{D^3 + 1} \\\\[1ex]         0 &amp; 0 &amp; 1 &amp; \\frac{D^3 + D + 1}{D^3 + 1}     \\end{bmatrix}. $$</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; for row in code.generator_matrix:\n...     print(\"[\" + \", \".join(str(x).ljust(12) for x in row) + \"]\")\n[0b1/0b1     , 0b0/0b1     , 0b0/0b1     , 0b110/0b111 ]\n[0b0/0b1     , 0b1/0b1     , 0b0/0b1     , 0b1101/0b1001]\n[0b0/0b1     , 0b0/0b1     , 0b1/0b1     , 0b1011/0b1001]\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#constraint_lengths","title":"<code>constraint_lengths</code><code>  Array1D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The constraint lengths $\\nu_i$ of the encoder, for $i \\in [0 : k)$. These are defined by $$     \\nu_i = \\max \\{ \\deg p_{i,0}(D), \\deg p_{i,1}(D), \\ldots, \\deg p_{i,n-1}(D), \\deg q_i(D) \\}, $$ where $p_{i,j}(D) / q_i(D)$ are the entries of the $i$-th row of the generator matrix $G(D)$, satisfying $$     \\gcd(p_{i,0}(D), p_{i,1}(D), \\ldots, p_{i,n-1}(D), q_i(D)) = 1. $$ This is a $k$-array of integers.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.constraint_lengths\narray([3, 3, 3])\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#overall_constraint_length","title":"<code>overall_constraint_length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The overall constraint length $\\nu$ of the encoder, defined by $$     \\nu = \\sum_{i \\in [0:k)} \\nu_i, $$ where $\\nu_i$ are the constraint lengths of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.overall_constraint_length\n9\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#memory_order","title":"<code>memory_order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The memory order $\\mu$ of the encoder. It is given by $$     \\mu = \\max_{i \\in [0:k)} \\nu_i, $$ where $\\nu_i$ are the constraint lengths of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.memory_order\n3\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#state_space_representation","title":"<code>state_space_representation()</code>  <code>cached</code>","text":"<p>Returns the matrices $(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\mathbf{D})$ corresponding to the state-space representation of the encoder realization. The state-space representation of the encoder is given by $$ \\begin{aligned}     s_{t+1} &amp; = s_t \\mathbf{A} + u_t \\mathbf{B}, \\\\     v_t &amp; = s_t \\mathbf{C} + u_t \\mathbf{D}, \\end{aligned} $$ where</p> <ul> <li>$u_t \\in \\mathbb{B}^k$ is the input block,</li> <li>$v_t \\in \\mathbb{B}^n$ is the output block,</li> <li>$s_t \\in \\mathbb{B}^\\sigma$ is the state,</li> <li>$\\mathbf{A} \\in \\mathbb{B}^{\\sigma \\times \\sigma}$ is the state matrix,</li> <li>$\\mathbf{B} \\in \\mathbb{B}^{k \\times \\sigma}$ is the control matrix,</li> <li>$\\mathbf{C} \\in \\mathbb{B}^{\\sigma \\times n}$ is the observation matrix,</li> <li>$\\mathbf{D} \\in \\mathbb{B}^{k \\times n}$ is the transition matrix.</li> </ul> <p>Returns:</p> <ul> <li> <code>state_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The state matrix $\\mathbf{A}$ of the encoder.</p> </li> <li> <code>control_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The control matrix $\\mathbf{B}$ of the encoder.</p> </li> <li> <code>observation_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The observation matrix $\\mathbf{C}$ of the encoder.</p> </li> <li> <code>transition_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The transition matrix $\\mathbf{D}$ of the encoder.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; A_mat, B_mat, C_mat, D_mat = code.state_space_representation()\n&gt;&gt;&gt; A_mat\narray([[0, 1, 0],\n       [0, 0, 1],\n       [1, 0, 0]])\n&gt;&gt;&gt; B_mat\narray([[1, 0, 1],\n       [0, 1, 0],\n       [0, 0, 1]])\n&gt;&gt;&gt; C_mat\narray([[0, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 0, 0, 1]])\n&gt;&gt;&gt; D_mat\narray([[1, 0, 0, 0],\n       [0, 1, 0, 1],\n       [0, 0, 1, 1]])\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#finite_state_machine","title":"<code>finite_state_machine()</code>  <code>cached</code>","text":"<p>Returns the finite-state (Mealy) machine of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; fsm = code.finite_state_machine()\n&gt;&gt;&gt; (fsm.num_input_symbols, fsm.num_output_symbols, fsm.num_states)\n(8, 16, 8)\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#is_catastrophic","title":"<code>is_catastrophic()</code>  <code>cached</code>","text":"<p>Returns whether the encoder is catastrophic. A convolutional encoder is catastrophic if there exists an infinite-weight input sequence that generates a finite-weight output sequence.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.is_catastrophic()\nFalse\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#free_distance","title":"<code>free_distance()</code>  <code>cached</code>","text":"<p>Returns the free distance $d_\\mathrm{free}$ of the code. This is equal to the minimum Hamming weight among all possible non-zero output sequences.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.free_distance()\n4\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#encode","title":"<code>encode()</code>","text":"<p>Encodes a given bit sequence, starting from the all-zero state.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The bit sequence to be encoded. Must be a 1D-array of bits, with length multiple of $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The encoded bit sequence. It is a 1D-array of bits, with length multiple of $n$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.encode([1, 1, 1, 1, 1, 1])\narray([1, 1, 1, 0, 1, 1, 1, 0])\n</code></pre>"},{"location":"ref/HighRateConvolutionalCode/#encode_with_state","title":"<code>encode_with_state()</code>","text":"<p>Encodes a given bit sequence, starting from a given state.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The bit sequence to be encoded. Must be a 1D-array of bits, with length multiple of $k$.</p> </li> <li> <code>initial_state</code> (<code>ArrayLike</code>)         \u2013          <p>The initial state. Must be a 1D-array of length $\\sigma$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The encoded bit sequence. It is a 1D-array of bits, with length multiple of $n$.</p> </li> <li> <code>final_state</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The final state. It is a 1D-array of length $\\sigma$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HighRateConvolutionalCode([0o12, 0o15, 0o13, 0o11])\n&gt;&gt;&gt; code.encode_with_state([1, 1, 1, 1, 1, 1], [0, 0, 0])\n(array([1, 1, 1, 0, 1, 1, 1, 0]), array([1, 0, 1]))\n&gt;&gt;&gt; code.encode_with_state([1, 1, 1, 1, 1, 1], [1, 0, 1])\n(array([1, 1, 1, 1, 1, 1, 1, 0]), array([1, 1, 0]))\n</code></pre>"},{"location":"ref/HuffmanCode/","title":"komm.HuffmanCode","text":"<p>Binary Huffman code. It is an optimal (minimal expected rate) fixed-to-variable length code for a given probability mass function. For more details, see Say06, Sec. 3.2.</p> Notes <p>Huffman codes are always prefix-free (hence uniquely decodable).</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function of the source.</p> </li> <li> <code>source_block_size</code> (<code>int</code>)         \u2013          <p>The source block size $k$. The default value is $k = 1$.</p> </li> <li> <code>policy</code> (<code>Literal['high', 'low']</code>)         \u2013          <p>The policy to be used when constructing the code. It must be either <code>'high'</code> (move combined symbols as high as possible) or <code>'low'</code> (move combined symbols as low as possible). The default value is <code>'high'</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pmf = [0.7, 0.15, 0.15]\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.HuffmanCode(pmf)\n&gt;&gt;&gt; code.enc_mapping\n{(0,): (0,),\n (1,): (1, 1),\n (2,): (1, 0)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(1.3)\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.HuffmanCode(pmf, 2)\n&gt;&gt;&gt; code.enc_mapping\n{(0, 0): (1,),\n (0, 1): (0, 0, 0, 0),\n (0, 2): (0, 1, 1),\n (1, 0): (0, 1, 0),\n (1, 1): (0, 0, 0, 1, 1, 1),\n (1, 2): (0, 0, 0, 1, 1, 0),\n (2, 0): (0, 0, 1),\n (2, 1): (0, 0, 0, 1, 0, 1),\n (2, 2): (0, 0, 0, 1, 0, 0)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(1.1975)\n</code></pre>"},{"location":"ref/KasamiSequence/","title":"komm.KasamiSequence","text":"<p>Kasami sequence [Not implemented yet].</p>"},{"location":"ref/LFSRSequence/","title":"komm.LFSRSequence","text":"<p>Linear-feedback shift register (LFSR) sequence. It is a binary sequence obtained from the output of a LFSR. The LFSR feedback taps are specified as a binary polynomial $p(X)$ of degree $n$, called the feedback polynomial. More specifically: if bit $i$ of the LFSR is tapped, for $i \\in [1 : n]$, then the coefficient of $X^i$ in $p(X)$ is $1$; otherwise, it is $0$; moreover, the coefficient of $X^0$ in $p(X)$ is always $1$. For example, the feedback polynomial corresponding to the LFSR in the figure below is $p(X) = X^5 + X^2 + 1$, whose integer representation is <code>0b100101</code>.</p> <p></p> <p>The start state of the machine is specified by the so called start state polynomial. More specifically, the coefficient of $X^i$ in the start state polynomial is equal to the initial value of bit $i$ of the LFSR. For more details, see Wikipedia: Linear-feedback shift register and Wikipedia: Maximum-length sequence.</p> <p>The default constructor of this takes the following parameters:</p> <p>Parameters:</p> <ul> <li> <code>feedback_polynomial</code> (<code>BinaryPolynomial | int</code>)         \u2013          <p>The feedback polynomial $p(X)$ of the LFSR, specified either as a binary polynomial or as an integer to be converted to the former.</p> </li> <li> <code>start_state_polynomial</code> (<code>BinaryPolynomial | int</code>)         \u2013          <p>The start state polynomial of the LFSR, specified either as a binary polynomial or as an integer to be converted to the former. The default value is <code>0b1</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lfsr = komm.LFSRSequence(feedback_polynomial=0b100101)\n&gt;&gt;&gt; lfsr.bit_sequence\narray([0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1])\n&gt;&gt;&gt; lfsr.cyclic_autocorrelation()\narray([31, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n</code></pre> Maximum-length sequences <p>If the feedback polynomial $p(X)$ is primitive, then the corresponding LFSR sequence will be a maximum-length sequence. Such sequences have the following cyclic autocorrelation: $$     \\tilde{R}[\\ell] =     \\begin{cases}         L, &amp; \\ell = 0, \\, \\pm L, \\, \\pm 2L, \\ldots, \\\\         -1, &amp; \\text{otherwise},     \\end{cases} $$ where $L$ is the length of the sequence. See the class method <code>maximum_length_sequence</code> for a convenient way to construct a maximum-length sequence.</p>"},{"location":"ref/LFSRSequence/#maximum_length_sequence","title":"<code>maximum_length_sequence()</code>  <code>classmethod</code>","text":"<p>Constructs a maximum-length sequences of a given degree. The feedback polynomial $p(X)$ is chosen from the list of default primitive polynomials.</p> <p>Parameters:</p> <ul> <li> <code>degree</code> (<code>int</code>)         \u2013          <p>The degree $n$ of the maximum-length-sequence. Only degrees in the range $[1 : 24]$ are implemented.</p> </li> <li> <code>start_state_polynomial</code> (<code>BinaryPolynomial | int</code>)         \u2013          <p>See the corresponding parameter of the default constructor.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.LFSRSequence.maximum_length_sequence(degree=5)\nLFSRSequence(feedback_polynomial=0b100101, start_state_polynomial=0b1)\n</code></pre>"},{"location":"ref/LempelZiv78Code/","title":"komm.LempelZiv78Code","text":"<p>Lempel\u2013Ziv 78 (LZ78 or LZ2) code. It is a lossless data compression algorithm which is asymptotically optimal for ergodic sources. For more details, see Say06, Sec. 5.4.2 and CT06, Sec. 13.4.2.</p> <p>Parameters:</p> <ul> <li> <code>source_cardinality</code> (<code>int</code>)         \u2013          <p>The source cardinality $S$. Must be an integer greater than or equal to $2$.</p> </li> <li> <code>target_cardinality</code> (<code>int</code>)         \u2013          <p>The target cardinality $T$. Must be an integer greater than or equal to $2$. Default is $2$ (binary).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lz78 = komm.LempelZiv78Code(2)  # Binary source, binary target\n&gt;&gt;&gt; lz78 = komm.LempelZiv78Code(3, 4)  # Ternary source, quaternary target\n</code></pre>"},{"location":"ref/LempelZiv78Code/#encode","title":"<code>encode()</code>","text":"<p>Encodes a sequence of source symbols using the LZ78 encoding algorithm.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be encoded. Must be a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of encoded symbols. It is a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lz78 = komm.LempelZiv78Code(2)\n&gt;&gt;&gt; lz78.encode(np.zeros(15, dtype=int))\narray([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; lz78 = komm.LempelZiv78Code(2, 8)\n&gt;&gt;&gt; lz78.encode(np.zeros(15, dtype=int))\narray([0, 1, 0, 2, 0, 3, 0, 4, 0])\n</code></pre>"},{"location":"ref/LempelZiv78Code/#decode","title":"<code>decode()</code>","text":"<p>Decodes a sequence of encoded symbols using the LZ78 decoding algorithm.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be decoded. Must be a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code). Also, the sequence must be a valid output of the <code>encode</code> method.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of decoded symbols. It is a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lz78 = komm.LempelZiv78Code(2)\n&gt;&gt;&gt; lz78.decode([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0])\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; lz78 = komm.LempelZiv78Code(2, 8)\n&gt;&gt;&gt; lz78.decode([0, 1, 0, 2, 0, 3, 0, 4, 0])\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n</code></pre>"},{"location":"ref/LempelZivWelchCode/","title":"komm.LempelZivWelchCode","text":"<p>Lempel\u2013Ziv\u2013Welch (LZW) code. It is a lossless data compression algorithm which is variation of the Lempel\u2013Ziv 78 algorithm. For more details, see Say06, Sec. 5.4.2.</p> <p>Parameters:</p> <ul> <li> <code>source_cardinality</code> (<code>int</code>)         \u2013          <p>The source cardinality $S$. Must be an integer greater than or equal to $2$.</p> </li> <li> <code>target_cardinality</code> (<code>int</code>)         \u2013          <p>The target cardinality $T$. Must be an integer greater than or equal to $2$. Default is $2$ (binary).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lzw = komm.LempelZivWelchCode(2)  # Binary source, binary target\n&gt;&gt;&gt; lzw = komm.LempelZivWelchCode(3, 4)  # Ternary source, quaternary target\n</code></pre>"},{"location":"ref/LempelZivWelchCode/#encode","title":"<code>encode()</code>","text":"<p>Encodes a sequence of source symbols using the LZW encoding algorithm.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be encoded. Must be a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of encoded symbols. It is a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lzw = komm.LempelZivWelchCode(2)\n&gt;&gt;&gt; lzw.encode(np.zeros(15, dtype=int))\narray([0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1])\n</code></pre> <pre><code>&gt;&gt;&gt; lzw = komm.LempelZivWelchCode(2, 8)\n&gt;&gt;&gt; lzw.encode(np.zeros(15, dtype=int))\narray([0, 2, 3, 4, 5])\n</code></pre>"},{"location":"ref/LempelZivWelchCode/#decode","title":"<code>decode()</code>","text":"<p>Decodes a sequence of encoded symbols using the LZW decoding algorithm.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be decoded. Must be a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code). Also, the sequence must be a valid output of the <code>encode</code> method.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of decoded symbols. It is a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; lzw = komm.LempelZivWelchCode(2)\n&gt;&gt;&gt; lzw.decode([0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1])\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; lzw = komm.LempelZivWelchCode(2, 8)\n&gt;&gt;&gt; lzw.decode([0, 2, 3, 4, 5])\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n</code></pre>"},{"location":"ref/Lexicode/","title":"komm.Lexicode","text":"<p>Lexicographic code (lexicode). For a given length $n$ and minimum distance $d$, it is the linear block code obtained by starting with the all-zero codeword and adding all binary $n$-tuples (in lexicographic order) that are at least at distance $d$ from all codewords already in the code.</p> <p>Parameters:</p> <ul> <li> <code>n</code> (<code>int</code>)         \u2013          <p>The length $n$ of the code.</p> </li> <li> <code>d</code> (<code>int</code>)         \u2013          <p>The minimum distance $d$ of the code.</p> </li> </ul> <p>For more details, see HP03, Sec. 2.11.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.Lexicode(7, 3)  # Hamming (7, 4)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(7, 4, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[0, 0, 0, 0, 1, 1, 1],\n       [0, 0, 1, 1, 0, 0, 1],\n       [0, 1, 0, 1, 0, 1, 0],\n       [1, 0, 0, 1, 0, 1, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n3\n</code></pre>"},{"location":"ref/LloydMaxQuantizer/","title":"komm.LloydMaxQuantizer","text":"<p>Lloyd\u2013Max scalar quantizer. It is a scalar quantizer that minimizes the mean squared error (MSE) between the input signal $X$ and its quantized version. For more details, see Say06, Sec. 9.6.1.</p> <p>Parameters:</p> <ul> <li> <code>input_pdf</code> (<code>Callable[[NDArray[floating]], NDArray[floating]]</code>)         \u2013          <p>The probability density function $f_X(x)$ of the input signal.</p> </li> <li> <code>input_range</code> (<code>tuple[float, float]</code>)         \u2013          <p>The range $(x_\\mathrm{min}, x_\\mathrm{max})$ of the input signal.</p> </li> <li> <code>num_levels</code> (<code>int</code>)         \u2013          <p>The number $L$ of quantization levels. It must be greater than $1$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; uniform_pdf = lambda x: 1/8 * (np.abs(x) &lt;= 4)\n&gt;&gt;&gt; quantizer = komm.LloydMaxQuantizer(\n...     input_pdf=uniform_pdf,\n...     input_range=(-4, 4),\n...     num_levels=8,\n... )\n&gt;&gt;&gt; quantizer.levels\narray([-3.5, -2.5, -1.5, -0.5,  0.5,  1.5,  2.5,  3.5])\n&gt;&gt;&gt; quantizer.thresholds\narray([-3., -2., -1.,  0.,  1.,  2.,  3.])\n</code></pre> <pre><code>&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer = komm.LloydMaxQuantizer(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n...     num_levels=8,\n... )\n&gt;&gt;&gt; quantizer.levels.round(3)\narray([-2.152, -1.344, -0.756, -0.245,  0.245,  0.756,  1.344,  2.152])\n&gt;&gt;&gt; quantizer.thresholds.round(3)\narray([-1.748, -1.05 , -0.501,  0.   ,  0.501,  1.05 ,  1.748])\n</code></pre>"},{"location":"ref/LloydMaxQuantizer/#levels","title":"<code>levels</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The quantizer levels $v_0, v_1, \\ldots, v_{L-1}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer = komm.LloydMaxQuantizer(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n...     num_levels=8,\n... )\n&gt;&gt;&gt; quantizer.levels.round(3)\narray([-2.152, -1.344, -0.756, -0.245,  0.245,  0.756,  1.344,  2.152])\n</code></pre>"},{"location":"ref/LloydMaxQuantizer/#thresholds","title":"<code>thresholds</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The quantizer finite thresholds $t_1, t_2, \\ldots, t_{L-1}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer = komm.LloydMaxQuantizer(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n...     num_levels=8,\n... )\n&gt;&gt;&gt; quantizer.thresholds.round(3)\narray([-1.748, -1.05 , -0.501,  0.   ,  0.501,  1.05 ,  1.748])\n</code></pre>"},{"location":"ref/LloydMaxQuantizer/#mean_squared_error","title":"<code>mean_squared_error()</code>","text":"<p>Computes the mean squared (quantization) error (MSE) of the quantizer for a given input probability density function (pdf). It is defined as $$     \\mse = \\int_{-\\infty}^{\\infty} (x - y)^2 f_X(x) \\, dx $$ where $y$ is the quantized signal and $f_X(x)$ is the pdf of the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input_pdf</code> (<code>Callable[[NDArray[floating]], NDArray[floating]]</code>)         \u2013          <p>The probability density function $f_X(x)$ of the input signal.</p> </li> <li> <code>input_range</code> (<code>tuple[float, float]</code>)         \u2013          <p>The range $(x_\\mathrm{min}, x_\\mathrm{max})$ of the input signal.</p> </li> <li> <code>points_per_interval</code> (<code>int</code>)         \u2013          <p>The number of points per interval for numerical integration (default: 4096).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>mse</code>  (<code>float</code>)          \u2013          <p>The mean square quantization error.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer = komm.LloydMaxQuantizer(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n...     num_levels=8,\n... )\n&gt;&gt;&gt; quantizer.mean_squared_error(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n... )\n0.034542475663845607\n</code></pre>"},{"location":"ref/LloydMaxQuantizer/#digitize","title":"<code>digitize()</code>","text":"<p>Returns the quantization indices for the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input signal $x$ to be digitized.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The integer indices of the quantization levels for each input sample.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer = komm.LloydMaxQuantizer(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n...     num_levels=8,\n... )\n&gt;&gt;&gt; quantizer.digitize([0, 1, 2, 3, 4, 5, 6, 7])\narray([4, 5, 7, 7, 7, 7, 7, 7])\n</code></pre>"},{"location":"ref/LloydMaxQuantizer/#quantize","title":"<code>quantize()</code>","text":"<p>Quantizes the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input signal $x$ to be quantized.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The quantized signal $y$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer = komm.LloydMaxQuantizer(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n...     num_levels=8,\n... )\n&gt;&gt;&gt; quantizer.quantize([0, 1, 2, 3, 4, 5, 6, 7]).round(3)\narray([0.245, 0.756, 2.152, 2.152, 2.152, 2.152, 2.152, 2.152])\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/","title":"komm.LowRateConvolutionalCode","text":"<p>Low-rate convolutional encoder. It is an $(n, 1)$ non-recursive non-systematic convolutional encoder defined by a single generator row $g(D) \\in \\mathbb{F}_2[D]^n$ and realized in controllable canonical form.</p> <p>Parameters:</p> <ul> <li> <code>g_row</code> (<code>ArrayLike</code>)         \u2013          <p>The generator row $g(D)$ of the encoder. Must be an $n$-vector whose entries are either binary polynomials or integers to be converted to the former.</p> </li> </ul> <p>Examples:</p> <p>Consider the low-rate convolutional encoder with $(n, k, \\sigma) = (2, 1, 6)$ depicted below.</p> <p></p> <p>Its generator row is given by $$     g(D) =     \\begin{bmatrix}         D^6 + D^3 + D^2 + D + 1  &amp;&amp;  D^6 + D^5 + D^3 + D^2 + 1     \\end{bmatrix}. $$</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0b1001111, 0b1101101])\n&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n</code></pre> <p>Please refer to the table of optimal low-rate convolutional codes.</p>"},{"location":"ref/LowRateConvolutionalCode/#num_input_bits","title":"<code>num_input_bits</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of input bits per block, $k$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.num_input_bits\n1\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#num_output_bits","title":"<code>num_output_bits</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of output bits per block, $n$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.num_output_bits\n2\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#degree","title":"<code>degree</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The degree $\\sigma$ of the encoder. This corresponds to the number of delay elements in the encoder realization.</p> <p>For a low-rate convolutional encoder realized in controllable canonical form, the degree $\\sigma$ is the maximum degree of the polynomials in the generator row $g(D)$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.degree\n6\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#generator_matrix","title":"<code>generator_matrix</code><code>  Array2D[object_] </code>  <code>cached</code> <code>property</code>","text":"<p>Returns the (transform-domain) generator matrix (also known as transfer function matrix) $G(D)$ of the encoder. This is a $k \\times n$ array of binary polynomial fractions.</p> <p>For a low-rate convolutional code, it is given by $$     G(D) = \\big[ ~ g(D) ~ \\big]. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; for row in code.generator_matrix:\n...     print(\"[\" + \", \".join(str(x) for x in row) + \"]\")\n[0b1001111/0b1, 0b1101101/0b1]\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#constraint_lengths","title":"<code>constraint_lengths</code><code>  Array1D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The constraint lengths $\\nu_i$ of the encoder, for $i \\in [0 : k)$. These are defined by $$     \\nu_i = \\max \\{ \\deg p_{i,0}(D), \\deg p_{i,1}(D), \\ldots, \\deg p_{i,n-1}(D), \\deg q_i(D) \\}, $$ where $p_{i,j}(D) / q_i(D)$ are the entries of the $i$-th row of the generator matrix $G(D)$, satisfying $$     \\gcd(p_{i,0}(D), p_{i,1}(D), \\ldots, p_{i,n-1}(D), q_i(D)) = 1. $$ This is a $k$-array of integers.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.constraint_lengths\narray([6])\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#overall_constraint_length","title":"<code>overall_constraint_length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The overall constraint length $\\nu$ of the encoder, defined by $$     \\nu = \\sum_{i \\in [0:k)} \\nu_i, $$ where $\\nu_i$ are the constraint lengths of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.overall_constraint_length\n6\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#memory_order","title":"<code>memory_order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The memory order $\\mu$ of the encoder. It is given by $$     \\mu = \\max_{i \\in [0:k)} \\nu_i, $$ where $\\nu_i$ are the constraint lengths of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.memory_order\n6\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#state_space_representation","title":"<code>state_space_representation()</code>  <code>cached</code>","text":"<p>Returns the matrices $(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\mathbf{D})$ corresponding to the state-space representation of the encoder realization. The state-space representation of the encoder is given by $$ \\begin{aligned}     s_{t+1} &amp; = s_t \\mathbf{A} + u_t \\mathbf{B}, \\\\     v_t &amp; = s_t \\mathbf{C} + u_t \\mathbf{D}, \\end{aligned} $$ where</p> <ul> <li>$u_t \\in \\mathbb{B}^k$ is the input block,</li> <li>$v_t \\in \\mathbb{B}^n$ is the output block,</li> <li>$s_t \\in \\mathbb{B}^\\sigma$ is the state,</li> <li>$\\mathbf{A} \\in \\mathbb{B}^{\\sigma \\times \\sigma}$ is the state matrix,</li> <li>$\\mathbf{B} \\in \\mathbb{B}^{k \\times \\sigma}$ is the control matrix,</li> <li>$\\mathbf{C} \\in \\mathbb{B}^{\\sigma \\times n}$ is the observation matrix,</li> <li>$\\mathbf{D} \\in \\mathbb{B}^{k \\times n}$ is the transition matrix.</li> </ul> <p>Returns:</p> <ul> <li> <code>state_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The state matrix $\\mathbf{A}$ of the encoder.</p> </li> <li> <code>control_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The control matrix $\\mathbf{B}$ of the encoder.</p> </li> <li> <code>observation_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The observation matrix $\\mathbf{C}$ of the encoder.</p> </li> <li> <code>transition_matrix</code>  (<code>Array2D[integer]</code>)          \u2013          <p>The transition matrix $\\mathbf{D}$ of the encoder.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; A_mat, B_mat, C_mat, D_mat = code.state_space_representation()\n&gt;&gt;&gt; A_mat\narray([[0, 1, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0]])\n&gt;&gt;&gt; B_mat\narray([[1, 0, 0, 0, 0, 0]])\n&gt;&gt;&gt; C_mat\narray([[1, 0],\n       [1, 1],\n       [1, 1],\n       [0, 0],\n       [0, 1],\n       [1, 1]])\n&gt;&gt;&gt; D_mat\narray([[1, 1]])\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#finite_state_machine","title":"<code>finite_state_machine()</code>  <code>cached</code>","text":"<p>Returns the finite-state (Mealy) machine of the encoder.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; fsm = code.finite_state_machine()\n&gt;&gt;&gt; (fsm.num_input_symbols, fsm.num_output_symbols, fsm.num_states)\n(2, 4, 64)\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#is_catastrophic","title":"<code>is_catastrophic()</code>  <code>cached</code>","text":"<p>Returns whether the encoder is catastrophic. A convolutional encoder is catastrophic if there exists an infinite-weight input sequence that generates a finite-weight output sequence.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.is_catastrophic()\nFalse\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#free_distance","title":"<code>free_distance()</code>  <code>cached</code>","text":"<p>Returns the free distance $d_\\mathrm{free}$ of the code. This is equal to the minimum Hamming weight among all possible non-zero output sequences.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.free_distance()\n10\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#encode","title":"<code>encode()</code>","text":"<p>Encodes a given bit sequence, starting from the all-zero state.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The bit sequence to be encoded. Must be a 1D-array of bits, with length multiple of $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The encoded bit sequence. It is a 1D-array of bits, with length multiple of $n$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.encode([1, 1, 1, 1])\narray([1, 1, 0, 1, 1, 0, 0, 1])\n</code></pre>"},{"location":"ref/LowRateConvolutionalCode/#encode_with_state","title":"<code>encode_with_state()</code>","text":"<p>Encodes a given bit sequence, starting from a given state.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The bit sequence to be encoded. Must be a 1D-array of bits, with length multiple of $k$.</p> </li> <li> <code>initial_state</code> (<code>ArrayLike</code>)         \u2013          <p>The initial state. Must be a 1D-array of length $\\sigma$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The encoded bit sequence. It is a 1D-array of bits, with length multiple of $n$.</p> </li> <li> <code>final_state</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The final state. It is a 1D-array of length $\\sigma$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.LowRateConvolutionalCode([0o117, 0o155])\n&gt;&gt;&gt; code.encode_with_state([1, 1, 1, 1], [0, 0, 0, 0, 0, 0])\n(array([1, 1, 0, 1, 1, 0, 0, 1]), array([1, 1, 1, 1, 0, 0]))\n&gt;&gt;&gt; code.encode_with_state([1, 1, 1, 1], [1, 1, 1, 1, 0, 0])\n(array([0, 1, 0, 0, 1, 1, 1, 1]), array([1, 1, 1, 1, 1, 1]))\n</code></pre>"},{"location":"ref/ManchesterPulse/","title":"komm.ManchesterPulse","text":"<p>Manchester pulse. It is a pulse with waveform given by $$     p(t) =     \\begin{cases}         -1, &amp; 0 \\leq t &lt;  1/2, \\\\         1, &amp; 1/2 \\leq t &lt; 1, \\\\         0, &amp; \\text{otherwise},     \\end{cases} $$</p> <p>The waveform of the Manchester pulse is depicted below.</p> <p></p> <p>Parameters:</p> <p>(No parameters)</p>"},{"location":"ref/ManchesterPulse/#waveform","title":"<code>waveform()</code>","text":"<p>The waveform $p(t)$ of the pulse.</p> <p>For the Manchester pulse, it is given by $$     p(t) = -\\rect\\left(\\frac{t - 1/4}{1/2}\\right) + \\rect\\left(\\frac{t - 3/4}{1/2}\\right). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.ManchesterPulse()\n&gt;&gt;&gt; pulse.waveform(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([ 0.,  0.,  0.,  0., -1., -1.,  1.,  1.,  0.])\n</code></pre>"},{"location":"ref/ManchesterPulse/#spectrum","title":"<code>spectrum()</code>","text":"<p>The spectrum $\\hat{p}(f)$ of the pulse.</p> <p>For the Manchester pulse, it is given by $$     \\hat{p}(f) = \\sinc \\left( \\frac{f}{2} \\right) \\, \\sin \\left( 2 \\pi \\frac{f}{4} \\right) \\mathrm{e}^{-\\mathrm{j} 2 \\pi (f/2\\,+\\,1/4)}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.ManchesterPulse()\n&gt;&gt;&gt; np.abs(pulse.spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )).round(3)\narray([0.637, 0.725, 0.637, 0.373, 0.   , 0.373, 0.637, 0.725, 0.637])\n</code></pre>"},{"location":"ref/ManchesterPulse/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>The autocorrelation function $R(\\tau)$ of the pulse.</p> <p>For the Manchester pulse, it is given $$     R(\\tau) = \\tri \\left( \\frac{\\tau}{1/2} \\right) - \\frac{1}{2} \\tri \\left( \\frac{\\tau + 1/2}{1/2} \\right) - \\frac{1}{2} \\tri \\left( \\frac{\\tau - 1/2}{1/2} \\right). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.ManchesterPulse()\n&gt;&gt;&gt; pulse.autocorrelation(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([ 0.  , -0.25, -0.5 ,  0.25,  1.  ,  0.25, -0.5 , -0.25,  0.  ])\n</code></pre>"},{"location":"ref/ManchesterPulse/#energy_density_spectrum","title":"<code>energy_density_spectrum()</code>","text":"<p>The energy density spectrum $S(f)$ of the pulse.</p> <p>For the Manchester pulse, it is given by $$     S(f) = \\sinc^2 \\left( \\frac{f}{2} \\right) \\, \\sin^2 \\left( 2 \\pi \\frac{f}{4} \\right). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.ManchesterPulse()\n&gt;&gt;&gt; pulse.energy_density_spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.405, 0.525, 0.405, 0.139, 0.   , 0.139, 0.405, 0.525, 0.405])\n</code></pre>"},{"location":"ref/ManchesterPulse/#support","title":"<code>support</code><code>  tuple[float, float] </code>  <code>cached</code> <code>property</code>","text":"<p>The support of the pulse waveform $p(t)$, defined as the interval $[a, b]$ where $p(t)$ is non-zero.</p> <p>For the Manchester pulse, the support is given by $[0, 1]$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.ManchesterPulse()\n&gt;&gt;&gt; pulse.support\n(0.0, 1.0)\n</code></pre>"},{"location":"ref/ManchesterPulse/#taps","title":"<code>taps()</code>","text":"<p>Returns the FIR taps of the pulse.</p> <p>Parameters:</p> <ul> <li> <code>samples_per_symbol</code> (<code>int</code>)         \u2013          <p>The number of samples per symbol.</p> </li> <li> <code>span</code> (<code>tuple[int, int] | None</code>)         \u2013          <p>The time span to consider for the taps. This parameter is optional for pulses with finite support (defaults to $[0, 1]$), but required for pulses with infinite support.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.ManchesterPulse()\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4)  # Default span is [0, 1]\narray([-1., -1.,  1.,  1.,  0.])\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-1, 1))\narray([ 0., 0., 0., 0., -1., -1.,  1.,  1.,  0.])\n</code></pre>"},{"location":"ref/MealyMachine/","title":"komm.MealyMachine","text":"<p>Finite-state Mealy machine. It is defined by a set of states $\\mathcal{S}$, an input alphabet $\\mathcal{X}$, an output alphabet $\\mathcal{Y}$, a transition function $T : \\mathcal{S} \\times \\mathcal{X} \\to \\mathcal{S}$, and an output function $G : \\mathcal{S} \\times \\mathcal{X} \\to \\mathcal{Y}$. Here, for simplicity, the set of states, the input alphabet, and the output alphabet are taken as $\\mathcal{S} = [0 : |\\mathcal{S}|)$, $\\mathcal{X} = [0 : |\\mathcal{X}|)$, and $\\mathcal{Y} = [0 : |\\mathcal{Y}|)$, respectively. more details, see Wikipedia: Mealy machine.</p> <p>Parameters:</p> <ul> <li> <code>transitions</code> (<code>ArrayLike</code>)         \u2013          <p>The matrix of transitions of the machine, of shape $|\\mathcal{S}| \\times |\\mathcal{X}|$. The element in row $s \\in \\mathcal{S}$ and column $x \\in \\mathcal{X}$ should be $T(s, x) \\in \\mathcal{S}$, that is, the next state of the machine given that the current state is $s$ and the input is $x$.</p> </li> <li> <code>outputs</code> (<code>ArrayLike</code>)         \u2013          <p>The matrix of outputs of the machine, of shape $|\\mathcal{S}| \\times |\\mathcal{X}|$. The element in row $s \\in \\mathcal{S}$ and column $x \\in \\mathcal{X}$ should be $G(s, x) \\in \\mathcal{Y}$, that is, the output of the machine given that the current state is $s$ and the input is $x$.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>Consider the finite-state Mealy machine whose state diagram depicted in the figure below.</p> <p> </p> <p>It has set of states $\\mathcal{S} = \\{ 0, 1, 2, 3 \\}$, input alphabet $\\mathcal{X} = \\{ 0, 1 \\}$, output alphabet $\\mathcal{Y} = \\{ 0, 1, 2, 3 \\}$. The transition function $T$ and output function $G$ are given by the table below.</p> State $s$ Input $x$ Transition $T(s, x)$ Output $G(s, x)$ $0$ $0$ $0$ $0$ $0$ $1$ $1$ $3$ $1$ $0$ $2$ $1$ $1$ $1$ $3$ $2$ $2$ $0$ $0$ $3$ $2$ $1$ $1$ $0$ $3$ $0$ $2$ $2$ $3$ $1$ $3$ $1$ <pre><code>&gt;&gt;&gt; machine = komm.MealyMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[[0, 3], [1, 2], [3, 0], [2, 1]],\n... )\n</code></pre> </li> </ol>"},{"location":"ref/MealyMachine/#num_states","title":"<code>num_states</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of states of the machine.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MealyMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[[0, 3], [1, 2], [3, 0], [2, 1]],\n... )\n&gt;&gt;&gt; machine.num_states\n4\n</code></pre>"},{"location":"ref/MealyMachine/#num_input_symbols","title":"<code>num_input_symbols</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The size (cardinality) of the input alphabet $\\mathcal{X}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MealyMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[[0, 3], [1, 2], [3, 0], [2, 1]],\n... )\n&gt;&gt;&gt; machine.num_input_symbols\n2\n</code></pre>"},{"location":"ref/MealyMachine/#num_output_symbols","title":"<code>num_output_symbols</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The size (cardinality) of the output alphabet $\\mathcal{Y}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MealyMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[[0, 3], [1, 2], [3, 0], [2, 1]],\n... )\n&gt;&gt;&gt; machine.num_output_symbols\n4\n</code></pre>"},{"location":"ref/MealyMachine/#input_edges","title":"<code>input_edges</code><code>  NDArray[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The matrix of input edges of the machine. It has shape $|\\mathcal{S}| \\times |\\mathcal{S}|$. If there is an edge from $s_0 \\in \\mathcal{S}$ to $s_1 \\in \\mathcal{S}$, then the element in row $s_0$ and column $s_1$ is the input associated with that edge (an element of $\\mathcal{X}$); if there is no such edge, then the element is $-1$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MealyMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[[0, 3], [1, 2], [3, 0], [2, 1]],\n... )\n&gt;&gt;&gt; machine.input_edges\narray([[ 0,  1, -1, -1],\n       [-1, -1,  0,  1],\n       [ 0,  1, -1, -1],\n       [-1, -1,  0,  1]])\n</code></pre>"},{"location":"ref/MealyMachine/#output_edges","title":"<code>output_edges</code><code>  NDArray[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The matrix of output edges of the machine. It has shape $|\\mathcal{S}| \\times |\\mathcal{S}|$. If there is an edge from $s_0 \\in \\mathcal{S}$ to $s_1 \\in \\mathcal{S}$, then the element in row $s_0$ and column $s_1$ is the output associated with that edge (an element of $\\mathcal{Y}$); if there is no such edge, then the element is $-1$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MealyMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[[0, 3], [1, 2], [3, 0], [2, 1]],\n... )\n&gt;&gt;&gt; machine.output_edges\narray([[ 0,  3, -1, -1],\n       [-1, -1,  1,  2],\n       [ 3,  0, -1, -1],\n       [-1, -1,  2,  1]])\n</code></pre>"},{"location":"ref/MealyMachine/#process","title":"<code>process()</code>","text":"<p>Returns the output sequence corresponding to a given input sequence. It assumes the machine starts at a given initial state $s_\\mathrm{i}$. The input sequence and the output sequence are denoted by $x = (x_0, x_1, \\ldots, x_{L-1}) \\in \\mathcal{X}^L$ and $y = (y_0, y_1, \\ldots, y_{L-1}) \\in \\mathcal{Y}^L$, respectively.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence $x \\in \\mathcal{X}^L$. It should be a 1D-array with elements in $\\mathcal{X}$.</p> </li> <li> <code>initial_state</code> (<code>int</code>)         \u2013          <p>The initial state $s_\\mathrm{i}$ of the machine. Should be an integer in $\\mathcal{S}$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence $y \\in \\mathcal{Y}^L$ corresponding to <code>input</code>, assuming the machine starts at the state given by <code>initial_state</code>. It is a 1D-array with elements in $\\mathcal{Y}$.</p> </li> <li> <code>final_state</code>  (<code>int</code>)          \u2013          <p>The final state $s_\\mathrm{f}$ of the machine. It is an integer in $\\mathcal{S}$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MealyMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[[0, 3], [1, 2], [3, 0], [2, 1]],\n... )\n&gt;&gt;&gt; input, initial_state = [1, 1, 0, 1, 0], 0\n&gt;&gt;&gt; output, final_state = machine.process(input, initial_state)\n&gt;&gt;&gt; output\narray([3, 2, 2, 0, 1])\n&gt;&gt;&gt; final_state\n2\n</code></pre>"},{"location":"ref/MealyMachine/#viterbi","title":"<code>viterbi()</code>","text":"<p>Applies the Viterbi algorithm on a given observed sequence. The Viterbi algorithm finds the most probable input sequence $\\hat{x} \\in \\mathcal{X}^L$ ending in state $s$, for all $s \\in \\mathcal{S}$, given an observed sequence $z \\in \\mathcal{Z}^L$. It is assumed uniform input priors. See LC04, Sec. 12.1.</p> <p>Parameters:</p> <ul> <li> <code>observed</code> (<code>ArrayLike</code>)         \u2013          <p>The observed sequence $z \\in \\mathcal{Z}^L$.</p> </li> <li> <code>metric_function</code> (<code>Callable[[int, Any], float]</code>)         \u2013          <p>The metric function $\\mathcal{Y} \\times \\mathcal{Z} \\to \\mathbb{R}$.</p> </li> <li> <code>initial_metrics</code> (<code>ArrayLike | None</code>)         \u2013          <p>The initial metrics for each state. It must be a 1D-array of length $|\\mathcal{S}|$. The default value is <code>0.0</code> for all states.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>input_hat</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The most probable input sequence $\\hat{x} \\in \\mathcal{X}^L$ ending in state $s$, for all $s \\in \\mathcal{S}$. It is a 2D-array of shape $L \\times |\\mathcal{S}|$, in which column $s$ is equal to $\\hat{x}$.</p> </li> <li> <code>final_metrics</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The final metrics for each state. It is a 1D-array of length $|\\mathcal{S}|$.</p> </li> </ul>"},{"location":"ref/MealyMachine/#viterbi_streaming","title":"<code>viterbi_streaming()</code>","text":"<p>Applies the streaming version of the Viterbi algorithm on a given observed sequence. The path memory (or traceback length) is denoted by $\\tau$. It chooses the survivor with best metric and selects the information block on this path. See LC04, Sec. 12.3.</p> <p>Parameters:</p> <ul> <li> <code>observed</code> (<code>ArrayLike</code>)         \u2013          <p>The observed sequence $z \\in \\mathcal{Z}^L$.</p> </li> <li> <code>metric_function</code> (<code>Callable[[int, Any], float]</code>)         \u2013          <p>The metric function $\\mathcal{Y} \\times \\mathcal{Z} \\to \\mathbb{R}$.</p> </li> <li> <code>memory</code> (<code>MetricMemory</code>)         \u2013          <p>The metrics for each state. It must be a dictionary containing two keys: <code>'paths'</code>, a 2D-array of integers of shape $|\\mathcal{S}| \\times (\\tau + 1)$; and <code>'metrics'</code>, a 2D-array of floats of shape $|\\mathcal{S}| \\times (\\tau + 1)$. This dictionary is updated in-place by this method.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>input_hat</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The most probable input sequence $\\hat{x} \\in \\mathcal{X}^L$</p> </li> </ul>"},{"location":"ref/MealyMachine/#forward_backward","title":"<code>forward_backward()</code>","text":"<p>Applies the forward-backward algorithm on a given observed sequence. The forward-backward algorithm computes the posterior pmf of each input $x_0, x_1, \\ldots, x_{L-1} \\in \\mathcal{X}$ given an observed sequence $z = (z_0, z_1, \\ldots, z_{L-1}) \\in \\mathcal{Z}^L$. The prior pmf of each input may also be provided. See LC04, 12.6.</p> <p>Parameters:</p> <ul> <li> <code>observed</code> (<code>ArrayLike</code>)         \u2013          <p>The observed sequence $z \\in \\mathcal{Z}^L$.</p> </li> <li> <code>metric_function</code> (<code>Callable[[int, Any], float]</code>)         \u2013          <p>The metric function $\\mathcal{Y} \\times \\mathcal{Z} \\to \\mathbb{R}$.</p> </li> <li> <code>input_priors</code> (<code>ArrayLike | None</code>)         \u2013          <p>The prior pmf of each input, of shape $L \\times |\\mathcal{X}|$. The element in row $t \\in [0 : L)$ and column $x \\in \\mathcal{X}$ should be $p(x_t = x)$. The default value yields uniform priors.</p> </li> <li> <code>initial_state_distribution</code> (<code>ArrayLike | None</code>)         \u2013          <p>The pmf of the initial state of the machine. It must be a 1D-array of length $|\\mathcal{S}|$. The default value is uniform over all states.</p> </li> <li> <code>final_state_distribution</code> (<code>ArrayLike | None</code>)         \u2013          <p>The pmf of the final state of the machine. It must be a 1D-array of length $|\\mathcal{S}|$. The default value is uniform over all states.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>input_posteriors</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The posterior pmf of each input, given the observed sequence, of shape $L \\times |\\mathcal{X}|$. The element in row $t \\in [0 : L)$ and column $x \\in \\mathcal{X}$ is $p(x_t = x \\mid z)$.</p> </li> </ul>"},{"location":"ref/Modulation/","title":"komm.Modulation","text":"<p>General modulation scheme. A modulation scheme of order $M = 2^m$ is defined by a constellation $\\mathbf{X}$, which is a real or complex vector of length $M$, and a binary labeling $\\mathbf{Q}$, which is an $M \\times m$ binary matrix whose rows are all distinct. The $i$-th element of $\\mathbf{X}$, for $i \\in [0:M)$, is denoted by $x_i$ and is called the $i$-th constellation symbol. The $i$-th row of $\\mathbf{Q}$, for $i \\in [0:M)$, is called the binary representation of the $i$-th constellation symbol. For more details, see SA15, Sec. 2.5.</p> <p>Parameters:</p> <ul> <li> <code>constellation</code> (<code>ArrayLike</code>)         \u2013          <p>The constellation $\\mathbf{X}$ of the modulation. Must be a 1D-array containing $M$ real or complex numbers.</p> </li> <li> <code>labeling</code> (<code>ArrayLike</code>)         \u2013          <p>The binary labeling $\\mathbf{Q}$ of the modulation. Must be a 2D-array of shape $(M, m)$ where each row is a distinct binary $m$-tuple.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>The real modulation scheme depicted in the figure below has $M = 4$ and $m = 2$.           The constellation and labeling are given, respectively, by     $$     \\mathbf{X} = \\begin{bmatrix}         -0.5 \\\\         0.0 \\\\         0.5 \\\\         2.0     \\end{bmatrix}     \\qquad\\text{and}\\qquad     \\mathbf{Q} = \\begin{bmatrix}         1 &amp; 0 \\\\         1 &amp; 1 \\\\         0 &amp; 1 \\\\         0 &amp; 0     \\end{bmatrix}.     $$</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n</code></pre> </li> <li> <p>The complex modulation scheme depicted in the figure below has $M = 4$ and $m = 2$.           The constellation and labeling are given, respectively, by     $$     \\mathbf{X} = \\begin{bmatrix}         0 \\\\         -1 \\\\         1 \\\\         \\mathrm{j}     \\end{bmatrix}     \\qquad\\text{and}\\qquad     \\mathbf{Q} = \\begin{bmatrix}         0 &amp; 0 \\\\         0 &amp; 1 \\\\         1 &amp; 0 \\\\         1 &amp; 1     \\end{bmatrix}.     $$</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[0, -1, 1, 1j],\n...     labeling=[[0, 0], [0, 1], [1, 0], [1, 1]],\n... )\n</code></pre> </li> </ol>"},{"location":"ref/Modulation/#constellation","title":"<code>constellation</code><code>  Array1D[T] </code>  <code>cached</code> <code>property</code>","text":"<p>The constellation $\\mathbf{X}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.constellation\narray([-0.5,  0. ,  0.5,  2. ])\n</code></pre>"},{"location":"ref/Modulation/#labeling","title":"<code>labeling</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The labeling $\\mathbf{Q}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.labeling\narray([[1, 0],\n       [1, 1],\n       [0, 1],\n       [0, 0]])\n</code></pre>"},{"location":"ref/Modulation/#inverse_labeling","title":"<code>inverse_labeling</code><code>  dict[tuple[int, ...], int] </code>  <code>cached</code> <code>property</code>","text":"<p>The inverse labeling of the modulation. It is a dictionary that maps each binary tuple to the corresponding constellation index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.inverse_labeling\n{(1, 0): 0, (1, 1): 1, (0, 1): 2, (0, 0): 3}\n</code></pre>"},{"location":"ref/Modulation/#order","title":"<code>order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The order $M$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.order\n4\n</code></pre>"},{"location":"ref/Modulation/#bits_per_symbol","title":"<code>bits_per_symbol</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number $m$ of bits per symbol of the modulation. It is given by $$     m = \\log_2 M, $$ where $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.bits_per_symbol\n2\n</code></pre>"},{"location":"ref/Modulation/#energy_per_symbol","title":"<code>energy_per_symbol</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average symbol energy $E_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   E_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} \\lVert x_i \\rVert^2, $$ where $\\lVert x_i \\rVert^2$ is the energy of constellation symbol $x_i$, and $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.energy_per_symbol\n1.125\n</code></pre> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[0, -1, 1, 1j],\n...     labeling=[[0, 0], [0, 1], [1, 0], [1, 1]],\n... )\n&gt;&gt;&gt; modulation.energy_per_symbol\n0.75\n</code></pre>"},{"location":"ref/Modulation/#energy_per_bit","title":"<code>energy_per_bit</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average bit energy $E_\\mathrm{b}$ of the constellation. It assumes equiprobable symbols. It is given by $$     E_\\mathrm{b} = \\frac{E_\\mathrm{s}}{m}, $$ where $E_\\mathrm{s}$ is the average symbol energy, and $m$ is the number of bits per symbol of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.energy_per_bit\n0.5625\n</code></pre> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[0, -1, 1, 1j],\n...     labeling=[[0, 0], [0, 1], [1, 0], [1, 1]],\n... )\n&gt;&gt;&gt; modulation.energy_per_bit\n0.375\n</code></pre>"},{"location":"ref/Modulation/#symbol_mean","title":"<code>symbol_mean</code><code>  float | complex </code>  <code>cached</code> <code>property</code>","text":"<p>The mean $\\mu_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   \\mu_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} x_i. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.symbol_mean\n0.5\n</code></pre> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[0, -1, 1, 1j],\n...     labeling=[[0, 0], [0, 1], [1, 0], [1, 1]],\n... )\n&gt;&gt;&gt; modulation.symbol_mean\n0.25j\n</code></pre>"},{"location":"ref/Modulation/#minimum_distance","title":"<code>minimum_distance</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The minimum Euclidean distance $d_\\mathrm{min}$ of the constellation. It is given by $$     d_\\mathrm{min} = \\min_ { i, j \\in [0:M), ~ i \\neq j } \\lVert x_i - x_j \\rVert. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.minimum_distance\n0.5\n</code></pre> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[0, -1, 1, 1j],\n...     labeling=[[0, 0], [0, 1], [1, 0], [1, 1]],\n... )\n&gt;&gt;&gt; modulation.minimum_distance\n1.0\n</code></pre>"},{"location":"ref/Modulation/#modulate","title":"<code>modulate()</code>","text":"<p>Modulates one or more sequences of bits to their corresponding constellation symbols.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $m$, or a multidimensional array where the last dimension is a multiple of $m$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[T]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension divided by $m$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.modulate([0, 0, 1, 1, 0, 0, 1, 0])\narray([ 2. ,  0. ,  2. , -0.5])\n&gt;&gt;&gt; modulation.modulate([[0, 0, 1, 1], [0, 0, 1, 0]])\narray([[ 2. ,  0. ],\n       [ 2. , -0.5]])\n</code></pre>"},{"location":"ref/Modulation/#demodulate_hard","title":"<code>demodulate_hard()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of hard bits ($\\mathtt{0}$ or $\\mathtt{1}$) using hard-decision decoding.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul> Note <p>This method implements the general minimum Euclidean distance hard demodulator, assuming uniformly distributed symbols.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.demodulate_hard([2.17, -0.06, 1.94, -0.61])\narray([0, 0, 1, 1, 0, 0, 1, 0])\n&gt;&gt;&gt; modulation.demodulate_hard([[2.17, -0.06], [1.94, -0.61]])\narray([[0, 0, 1, 1],\n       [0, 0, 1, 0]])\n</code></pre>"},{"location":"ref/Modulation/#demodulate_soft","title":"<code>demodulate_soft()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of soft bits (L-values) using soft-decision decoding. The soft bits are the log-likelihood ratios of the bits, where positive values correspond to bit $\\mathtt{0}$ and negative values correspond to bit $\\mathtt{1}$.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The received sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> <li> <code>snr</code> (<code>float</code>)         \u2013          <p>The signal-to-noise ratio (SNR) of the channel. It should be a positive real number. The default value is <code>1.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul> Note <p>This method implements the general soft demodulator, assuming uniformly distributed symbols.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; modulation = komm.Modulation(\n...     constellation=[-0.5, 0.0, 0.5, 2.0],\n...     labeling=[[1, 0], [1, 1], [0, 1], [0, 0]],\n... )\n&gt;&gt;&gt; modulation.demodulate_soft([2.17, -0.06, 1.94, -0.61], snr=100.0).round(1)\narray([ 416. ,  245.3,  -27.6,  -16.9,  334.2,  184. , -108.4,   32. ])\n&gt;&gt;&gt; modulation.demodulate_soft([[2.17, -0.06], [1.94, -0.61]], snr=100.0).round(1)\narray([[ 416. ,  245.3,  -27.6,  -16.9],\n       [ 334.2,  184. , -108.4,   32. ]])\n</code></pre>"},{"location":"ref/MooreMachine/","title":"komm.MooreMachine","text":"<p>Finite-state Moore machine. It is defined by a set of states $\\mathcal{S}$, an input alphabet $\\mathcal{X}$, an output alphabet $\\mathcal{Y}$, a transition function $T : \\mathcal{S} \\times \\mathcal{X} \\to \\mathcal{S}$, and an output function $G : \\mathcal{S} \\to \\mathcal{Y}$. Here, for simplicity, the set of states, the input alphabet, and the output alphabet are taken as $\\mathcal{S} = [0 : |\\mathcal{S}|)$, $\\mathcal{X} = [0 : |\\mathcal{X}|)$, and $\\mathcal{Y} = [0 : |\\mathcal{Y}|)$, respectively. more details, see Wikipedia: Moore machine.</p> <p>Parameters:</p> <ul> <li> <code>transitions</code> (<code>ArrayLike</code>)         \u2013          <p>The matrix of transitions of the machine, of shape $|\\mathcal{S}| \\times |\\mathcal{X}|$. The element in row $s \\in \\mathcal{S}$ and column $x \\in \\mathcal{X}$ should be $T(s, x) \\in \\mathcal{S}$, that is, the next state of the machine given that the current state is $s$ and the input is $x$.</p> </li> <li> <code>outputs</code> (<code>ArrayLike</code>)         \u2013          <p>The vector of outputs of the machine, of shape $|\\mathcal{S}|$. The element in position $s \\in \\mathcal{S}$ should be $G(s) \\in \\mathcal{Y}$, that is, the output of the machine given that the current state is $s$.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>Consider the finite-state Moore machine whose state diagram depicted in the figure below.</p> <p> </p> <p>It has set of states $\\mathcal{S} = \\{ 0, 1, 2, 3 \\}$, input alphabet $\\mathcal{X} = \\{ 0, 1 \\}$, output alphabet $\\mathcal{Y} = \\{ 0, 1 \\}$. The transition function $T$ and output function $G$ are given by the tables below.</p> <p> State $s$ Input $x$ Transition $T(s, x)$ $0$ $0$ $0$ $0$ $1$ $1$ $1$ $0$ $2$ $1$ $1$ $3$ $2$ $0$ $0$ $2$ $1$ $1$ $3$ $0$ $2$ $3$ $1$ $3$ <p> State $s$ Output $G(s)$ $0$ $0$ $1$ $0$ $2$ $1$ $3$ $1$ <p> </p> <pre><code>&gt;&gt;&gt; machine = komm.MooreMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[0, 0, 1, 1],\n... )\n</code></pre>"},{"location":"ref/MooreMachine/#num_states","title":"<code>num_states</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of states of the machine.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MooreMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[0, 0, 1, 1],\n... )\n&gt;&gt;&gt; machine.num_states\n4\n</code></pre>"},{"location":"ref/MooreMachine/#num_input_symbols","title":"<code>num_input_symbols</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The size (cardinality) of the input alphabet $\\mathcal{X}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MooreMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[0, 0, 1, 1],\n... )\n&gt;&gt;&gt; machine.num_input_symbols\n2\n</code></pre>"},{"location":"ref/MooreMachine/#num_output_symbols","title":"<code>num_output_symbols</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The size (cardinality) of the output alphabet $\\mathcal{Y}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MooreMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[0, 0, 1, 1],\n... )\n&gt;&gt;&gt; machine.num_output_symbols\n2\n</code></pre>"},{"location":"ref/MooreMachine/#process","title":"<code>process()</code>","text":"<p>Returns the output sequence corresponding to a given input sequence. It assumes the machine starts at a given initial state $s_\\mathrm{i}$. The input sequence and the output sequence are denoted by $x = (x_0, x_1, \\ldots, x_{L-1}) \\in \\mathcal{X}^L$ and $y = (y_0, y_1, \\ldots, y_{L-1}) \\in \\mathcal{Y}^{L}$, respectively.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence $x \\in \\mathcal{X}^L$. It should be a 1D-array with elements in $\\mathcal{X}$.</p> </li> <li> <code>initial_state</code> (<code>int</code>)         \u2013          <p>The initial state $s_\\mathrm{i}$ of the machine. Should be an integer in $\\mathcal{S}$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence $y \\in \\mathcal{Y}^{L}$ corresponding to <code>input</code>, assuming the machine starts at the state given by <code>initial_state</code>. It is a 1D-array with elements in $\\mathcal{Y}$.</p> </li> <li> <code>final_state</code>  (<code>int</code>)          \u2013          <p>The final state $s_\\mathrm{f}$ of the machine. It is an integer in $\\mathcal{S}$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; machine = komm.MooreMachine(\n...     transitions=[[0, 1], [2, 3], [0, 1], [2, 3]],\n...     outputs=[0, 0, 1, 1],\n... )\n&gt;&gt;&gt; input, initial_state = [1, 1, 0, 1, 0], 0\n&gt;&gt;&gt; output, final_state = machine.process(input, initial_state)\n&gt;&gt;&gt; output\narray([0, 1, 1, 0, 1])\n&gt;&gt;&gt; final_state\n2\n</code></pre>"},{"location":"ref/PAModulation/","title":"komm.PAModulation","text":"<p>Pulse-amplitude modulation (PAM). It is a real modulation scheme in which the constellation symbols are uniformly arranged in the real line and have zero mean. More precisely, the the $i$-th constellation symbol is given by $$     x_i = A \\left( 2i - M + 1 \\right), \\quad i \\in [0 : M), $$ where $M$ is the order (a power of $2$), and $A$ is the base amplitude of the modulation.</p> <p>Parameters:</p> <ul> <li> <code>order</code> (<code>int</code>)         \u2013          <p>The order $M$ of the modulation. It must be a power of $2$.</p> </li> <li> <code>base_amplitude</code> (<code>float</code>)         \u2013          <p>The base amplitude $A$ of the constellation. The default value is <code>1.0</code>.</p> </li> <li> <code>labeling</code> (<code>Literal['natural', 'reflected'] | ArrayLike</code>)         \u2013          <p>The binary labeling of the modulation. Can be specified either as a 2D-array of integers (see base class for details), or as a string. In the latter case, the string must be either <code>'natural'</code> or <code>'reflected'</code>. The default value is <code>'reflected'</code>, corresponding to the Gray labeling.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>The $4$-PAM modulation with base amplitude $A = 1$ and natural labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4, labeling=\"natural\")\n&gt;&gt;&gt; pam.constellation\narray([-3., -1.,  1.,  3.])\n&gt;&gt;&gt; pam.labeling\narray([[0, 0],\n       [0, 1],\n       [1, 0],\n       [1, 1]])\n</code></pre> </li> <li> <p>The $8$-PAM modulation with base amplitude $A = 0.5$ and Gray labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(8, base_amplitude=0.5)\n&gt;&gt;&gt; pam.constellation\narray([-3.5, -2.5, -1.5, -0.5,  0.5,  1.5,  2.5,  3.5])\n&gt;&gt;&gt; pam.labeling\narray([[0, 0, 0],\n       [0, 0, 1],\n       [0, 1, 1],\n       [0, 1, 0],\n       [1, 1, 0],\n       [1, 1, 1],\n       [1, 0, 1],\n       [1, 0, 0]])\n</code></pre> </li> </ol>"},{"location":"ref/PAModulation/#constellation","title":"<code>constellation</code><code>  Array1D[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The constellation $\\mathbf{X}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.constellation\narray([-3., -1.,  1.,  3.])\n</code></pre>"},{"location":"ref/PAModulation/#labeling","title":"<code>labeling</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The labeling $\\mathbf{Q}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.labeling\narray([[0, 0],\n       [0, 1],\n       [1, 1],\n       [1, 0]])\n</code></pre>"},{"location":"ref/PAModulation/#inverse_labeling","title":"<code>inverse_labeling</code><code>  dict[tuple[int, ...], int] </code>  <code>cached</code> <code>property</code>","text":"<p>The inverse labeling of the modulation. It is a dictionary that maps each binary tuple to the corresponding constellation index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.inverse_labeling\n{(0, 0): 0, (0, 1): 1, (1, 1): 2, (1, 0): 3}\n</code></pre>"},{"location":"ref/PAModulation/#order","title":"<code>order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The order $M$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.order\n4\n</code></pre>"},{"location":"ref/PAModulation/#bits_per_symbol","title":"<code>bits_per_symbol</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number $m$ of bits per symbol of the modulation. It is given by $$     m = \\log_2 M, $$ where $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.bits_per_symbol\n2\n</code></pre>"},{"location":"ref/PAModulation/#energy_per_symbol","title":"<code>energy_per_symbol</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average symbol energy $E_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   E_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} \\lVert x_i \\rVert^2, $$ where $\\lVert x_i \\rVert^2$ is the energy of constellation symbol $x_i$, and $M$ is the order of the modulation.</p> <p>For the PAM, it is given by $$     E_\\mathrm{s} = \\frac{A^2}{3}(M^2 - 1). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.energy_per_symbol\n5.0\n</code></pre>"},{"location":"ref/PAModulation/#energy_per_bit","title":"<code>energy_per_bit</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average bit energy $E_\\mathrm{b}$ of the constellation. It assumes equiprobable symbols. It is given by $$     E_\\mathrm{b} = \\frac{E_\\mathrm{s}}{m}, $$ where $E_\\mathrm{s}$ is the average symbol energy, and $m$ is the number of bits per symbol of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.energy_per_bit\n2.5\n</code></pre>"},{"location":"ref/PAModulation/#symbol_mean","title":"<code>symbol_mean</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The mean $\\mu_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   \\mu_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} x_i. $$</p> <p>For the PAM, it is given by $$     \\mu_\\mathrm{s} = 0. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.symbol_mean\n0.0\n</code></pre>"},{"location":"ref/PAModulation/#minimum_distance","title":"<code>minimum_distance</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The minimum Euclidean distance $d_\\mathrm{min}$ of the constellation. It is given by $$     d_\\mathrm{min} = \\min_ { i, j \\in [0:M), ~ i \\neq j } \\lVert x_i - x_j \\rVert. $$</p> <p>For the PAM, it is given by $$     d_\\mathrm{min} = 2A. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.minimum_distance\n2.0\n</code></pre>"},{"location":"ref/PAModulation/#modulate","title":"<code>modulate()</code>","text":"<p>Modulates one or more sequences of bits to their corresponding constellation symbols.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $m$, or a multidimensional array where the last dimension is a multiple of $m$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension divided by $m$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = komm.PAModulation(4)\n&gt;&gt;&gt; pam.modulate([0, 0, 1, 1, 0, 0, 0, 1])\narray([-3.,  1., -3., -1.])\n</code></pre>"},{"location":"ref/PAModulation/#demodulate_hard","title":"<code>demodulate_hard()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of hard bits ($\\mathtt{0}$ or $\\mathtt{1}$) using hard-decision decoding.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/PAModulation/#demodulate_soft","title":"<code>demodulate_soft()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of soft bits (L-values) using soft-decision decoding. The soft bits are the log-likelihood ratios of the bits, where positive values correspond to bit $\\mathtt{0}$ and negative values correspond to bit $\\mathtt{1}$.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The received sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> <li> <code>snr</code> (<code>float</code>)         \u2013          <p>The signal-to-noise ratio (SNR) of the channel. It should be a positive real number. The default value is <code>1.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/PSKModulation/","title":"komm.PSKModulation","text":"<p>Phase-shift keying (PSK) modulation. It is a complex modulation scheme in which the constellation symbols are uniformly arranged in a circle. More precisely, the the $i$-th constellation symbol is given by $$     x_i = A \\exp \\left( \\mathrm{j} \\frac{2 \\pi i}{M} \\right) \\exp(\\mathrm{j} \\phi), \\quad i \\in [0 : M), $$ where $M$ is the order (a power of $2$), $A$ is the amplitude, and $\\phi$ is the phase offset of the modulation.</p> <p>Parameters:</p> <ul> <li> <code>order</code> (<code>int</code>)         \u2013          <p>The order $M$ of the modulation. It must be a power of $2$.</p> </li> <li> <code>amplitude</code> (<code>float</code>)         \u2013          <p>The amplitude $A$ of the constellation. The default value is <code>1.0</code>.</p> </li> <li> <code>phase_offset</code> (<code>float</code>)         \u2013          <p>The phase offset $\\phi$ of the constellation. The default value is <code>0.0</code>.</p> </li> <li> <code>labeling</code> (<code>Literal['natural', 'reflected'] | ArrayLike</code>)         \u2013          <p>The binary labeling of the modulation. Can be specified either as a 2D-array of integers (see base class for details), or as a string. In the latter case, the string must be either <code>'natural'</code> or <code>'reflected'</code>. The default value is <code>'reflected'</code>, corresponding to the Gray labeling.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>The $4$-PSK modulation with base amplitude $A = 1$, phase offset $\\phi = 0$, and Gray labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.constellation\narray([ 1.+0.j,  0.+1.j, -1.+0.j, -0.-1.j])\n&gt;&gt;&gt; psk.labeling\narray([[0, 0],\n       [0, 1],\n       [1, 1],\n       [1, 0]])\n</code></pre> </li> <li> <p>The $8$-PSK modulation with base amplitude $A = 0.5$, phase offset $\\phi = \\pi/8$, and natural labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(\n...     order=8,\n...     amplitude=0.5,\n...     phase_offset=np.pi/8,\n...     labeling='natural',\n... )\n&gt;&gt;&gt; psk.constellation.round(3)\narray([ 0.462+0.191j,  0.191+0.462j, -0.191+0.462j, -0.462+0.191j,\n       -0.462-0.191j, -0.191-0.462j,  0.191-0.462j,  0.462-0.191j])\n&gt;&gt;&gt; psk.labeling\narray([[0, 0, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 1, 1],\n       [1, 0, 0],\n       [1, 0, 1],\n       [1, 1, 0],\n       [1, 1, 1]])\n</code></pre> </li> </ol>"},{"location":"ref/PSKModulation/#constellation","title":"<code>constellation</code><code>  Array1D[complexfloating] </code>  <code>cached</code> <code>property</code>","text":"<p>The constellation $\\mathbf{X}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.constellation\narray([ 1.+0.j,  0.+1.j, -1.+0.j, -0.-1.j])\n</code></pre>"},{"location":"ref/PSKModulation/#labeling","title":"<code>labeling</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The labeling $\\mathbf{Q}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.labeling\narray([[0, 0],\n       [0, 1],\n       [1, 1],\n       [1, 0]])\n</code></pre>"},{"location":"ref/PSKModulation/#inverse_labeling","title":"<code>inverse_labeling</code><code>  dict[tuple[int, ...], int] </code>  <code>cached</code> <code>property</code>","text":"<p>The inverse labeling of the modulation. It is a dictionary that maps each binary tuple to the corresponding constellation index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.inverse_labeling\n{(0, 0): 0, (0, 1): 1, (1, 1): 2, (1, 0): 3}\n</code></pre>"},{"location":"ref/PSKModulation/#order","title":"<code>order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The order $M$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.order\n4\n</code></pre>"},{"location":"ref/PSKModulation/#bits_per_symbol","title":"<code>bits_per_symbol</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number $m$ of bits per symbol of the modulation. It is given by $$     m = \\log_2 M, $$ where $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.bits_per_symbol\n2\n</code></pre>"},{"location":"ref/PSKModulation/#energy_per_symbol","title":"<code>energy_per_symbol</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average symbol energy $E_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   E_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} \\lVert x_i \\rVert^2, $$ where $\\lVert x_i \\rVert^2$ is the energy of constellation symbol $x_i$, and $M$ is the order of the modulation.</p> <p>For the PSK, it is given by $$     E_\\mathrm{s} = A^2. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.energy_per_symbol\n1.0\n</code></pre>"},{"location":"ref/PSKModulation/#energy_per_bit","title":"<code>energy_per_bit</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average bit energy $E_\\mathrm{b}$ of the constellation. It assumes equiprobable symbols. It is given by $$     E_\\mathrm{b} = \\frac{E_\\mathrm{s}}{m}, $$ where $E_\\mathrm{s}$ is the average symbol energy, and $m$ is the number of bits per symbol of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.energy_per_bit\n0.5\n</code></pre>"},{"location":"ref/PSKModulation/#symbol_mean","title":"<code>symbol_mean</code><code>  complex </code>  <code>cached</code> <code>property</code>","text":"<p>The mean $\\mu_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   \\mu_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} x_i. $$</p> <p>For the PSK, it is given by $$     \\mu_\\mathrm{s} = 0. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.symbol_mean\n0j\n</code></pre>"},{"location":"ref/PSKModulation/#minimum_distance","title":"<code>minimum_distance</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The minimum Euclidean distance $d_\\mathrm{min}$ of the constellation. It is given by $$     d_\\mathrm{min} = \\min_ { i, j \\in [0:M), ~ i \\neq j } \\lVert x_i - x_j \\rVert. $$</p> <p>For the PSK, it is given by $$     d_\\mathrm{min} = 2A\\sin\\left(\\frac{\\pi}{M}\\right). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.minimum_distance\n1.414213562373095\n</code></pre>"},{"location":"ref/PSKModulation/#modulate","title":"<code>modulate()</code>","text":"<p>Modulates one or more sequences of bits to their corresponding constellation symbols.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $m$, or a multidimensional array where the last dimension is a multiple of $m$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[complexfloating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension divided by $m$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; psk = komm.PSKModulation(4)\n&gt;&gt;&gt; psk.modulate([0, 0, 1, 1, 0, 0, 0, 1])\narray([ 1.+0.j, -1.+0.j,  1.+0.j,  0.+1.j])\n</code></pre>"},{"location":"ref/PSKModulation/#demodulate_hard","title":"<code>demodulate_hard()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of hard bits ($\\mathtt{0}$ or $\\mathtt{1}$) using hard-decision decoding.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/PSKModulation/#demodulate_soft","title":"<code>demodulate_soft()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of soft bits (L-values) using soft-decision decoding. The soft bits are the log-likelihood ratios of the bits, where positive values correspond to bit $\\mathtt{0}$ and negative values correspond to bit $\\mathtt{1}$.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The received sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> <li> <code>snr</code> (<code>float</code>)         \u2013          <p>The signal-to-noise ratio (SNR) of the channel. It should be a positive real number. The default value is <code>1.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/PolarCode/","title":"komm.PolarCode","text":"<p>Polar (Ar\u0131kan) code. Let $\\mu \\geq 1$ be an integer, and $\\mathcal{F}$ (called the frozen bit indices) be a subset of $[0 : 2^\\mu)$. Define $\\mathcal{A} = [0 : 2^\\mu) \\setminus \\mathcal{F}$ (called the active bit indices). The polar code with parameters $(\\mu, \\mathcal{F})$ is the linear block code whose generator matrix is obtained by selecting the rows of the order-$2^\\mu$ Walsh-Hadamard matrix, $$ H_{2^\\mu} = \\begin{bmatrix} 1 &amp; 0 \\\\ 1 &amp; 1 \\end{bmatrix} ^ {\\otimes \\mu}, $$ corresponding to the active bit indices, where $\\otimes$ denotes the Kronecker product. The resulting code has the following parameters:</p> <ul> <li>Length: $n = 2^{\\mu}$</li> <li>Dimension: $k = |\\mathcal{A}|$</li> <li>Redundancy: $m = |\\mathcal{F}|$</li> </ul> <p>Parameters:</p> <ul> <li> <code>mu</code> (<code>int</code>)         \u2013          <p>The parameter $\\mu$ of the code.</p> </li> <li> <code>frozen</code> (<code>ArrayLike</code>)         \u2013          <p>The frozen bit indices $\\mathcal{F}$ of the code.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.PolarCode(4, [0, 1, 2, 3, 4, 8])\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(16, 10, 6)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n       [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n       [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n       [1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0],\n       [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n4\n</code></pre>"},{"location":"ref/Pulse/","title":"komm.Pulse","text":"<p>General pulse [Not implemented yet].</p>"},{"location":"ref/QAModulation/","title":"komm.QAModulation","text":"<p>Quadrature-amplitude modulation (QAM). It is a complex modulation scheme in which the constellation is given as a Cartesian product of two PAM constellations, namely, the in-phase constellation, and the quadrature constellation. More precisely, the $i$-th constellation symbol is given by $$     \\begin{aligned}         x_i = \\left[ A_\\mathrm{I} \\left( 2i_\\mathrm{I} - M_\\mathrm{I} + 1 \\right) + \\mathrm{j} A_\\mathrm{Q} \\left( 2i_\\mathrm{Q} - M_\\mathrm{Q} + 1 \\right) \\right] \\exp(\\mathrm{j}\\phi), \\quad             &amp;  i \\in [0 : M), \\\\             &amp; i_\\mathrm{I} = i \\bmod M_\\mathrm{I}, \\\\             &amp; i_\\mathrm{Q} = \\lfloor i / M_\\mathrm{I} \\rfloor,     \\end{aligned} $$ where $M_\\mathrm{I}$ and $M_\\mathrm{Q}$ are the orders (powers of $2$), and $A_\\mathrm{I}$ and $A_\\mathrm{Q}$ are the base amplitudes of the in-phase and quadrature constellations, respectively. Also, $\\phi$ is the phase offset. The order of the resulting complex-valued constellation is $M = M_\\mathrm{I} M_\\mathrm{Q}$, a power of $2$.</p> <p>Parameters:</p> <ul> <li> <code>orders</code> (<code>tuple[int, int] | int</code>)         \u2013          <p>A tuple $(M_\\mathrm{I}, M_\\mathrm{Q})$ with the orders of the in-phase and quadrature constellations, respectively; both $M_\\mathrm{I}$ and $M_\\mathrm{Q}$ must be powers of $2$. If specified as a single integer $M$, then it is assumed that $M_\\mathrm{I} = M_\\mathrm{Q} = \\sqrt{M}$; in this case, $M$ must be an square power of $2$.</p> </li> <li> <code>base_amplitudes</code> (<code>tuple[float, float] | float</code>)         \u2013          <p>A tuple $(A_\\mathrm{I}, A_\\mathrm{Q})$ with the base amplitudes of the in-phase and quadrature constellations, respectively. If specified as a single float $A$, then it is assumed that $A_\\mathrm{I} = A_\\mathrm{Q} = A$. The default value is $1.0$.</p> </li> <li> <code>phase_offset</code> (<code>float</code>)         \u2013          <p>The phase offset $\\phi$ of the constellation. The default value is <code>0.0</code>.</p> </li> <li> <code>labeling</code> (<code>Literal['natural_2d', 'reflected_2d'] | ArrayLike</code>)         \u2013          <p>The binary labeling of the modulation. Can be specified either as a 2D-array of integers (see base class for details), or as a string. In the latter case, the string must be either <code>'natural_2d'</code> or <code>'reflected_2d'</code>. The default value is <code>'reflected_2d'</code>, corresponding to the Gray labeling.</p> </li> </ul> <p>Examples:</p> <ol> <li> <p>The square $16$-QAM modulation with $(M_\\mathrm{I}, M_\\mathrm{Q}) = (4, 4)$ and $(A_\\mathrm{I}, A_\\mathrm{Q}) = (1, 1)$, and Gray labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.constellation\narray([-3.-3.j, -1.-3.j,  1.-3.j,  3.-3.j,\n       -3.-1.j, -1.-1.j,  1.-1.j,  3.-1.j,\n       -3.+1.j, -1.+1.j,  1.+1.j,  3.+1.j,\n       -3.+3.j, -1.+3.j,  1.+3.j,  3.+3.j])\n&gt;&gt;&gt; qam.labeling\narray([[0, 0, 0, 0], [0, 1, 0, 0], [1, 1, 0, 0], [1, 0, 0, 0],\n       [0, 0, 0, 1], [0, 1, 0, 1], [1, 1, 0, 1], [1, 0, 0, 1],\n       [0, 0, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 1],\n       [0, 0, 1, 0], [0, 1, 1, 0], [1, 1, 1, 0], [1, 0, 1, 0]])\n</code></pre> </li> <li> <p>The rectangular $8$-QAM modulation with $(M_\\mathrm{I}, M_\\mathrm{Q}) = (4, 2)$ and $(A_\\mathrm{I}, A_\\mathrm{Q}) = (1, 2)$, and natural labeling is depicted below.      </p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(\n...     orders=(4, 2),\n...     base_amplitudes=(1.0, 2.0),\n...     labeling=\"natural_2d\"\n... )\n&gt;&gt;&gt; qam.constellation\narray([-3.-2.j, -1.-2.j,  1.-2.j,  3.-2.j,\n       -3.+2.j, -1.+2.j,  1.+2.j,  3.+2.j])\n&gt;&gt;&gt; qam.labeling\narray([[0, 0, 0], [0, 1, 0], [1, 0, 0], [1, 1, 0],\n       [0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n</code></pre> </li> </ol>"},{"location":"ref/QAModulation/#constellation","title":"<code>constellation</code><code>  Array1D[complexfloating] </code>  <code>cached</code> <code>property</code>","text":"<p>The constellation $\\mathbf{X}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.constellation\narray([-3.-3.j, -1.-3.j,  1.-3.j,  3.-3.j,\n       -3.-1.j, -1.-1.j,  1.-1.j,  3.-1.j,\n       -3.+1.j, -1.+1.j,  1.+1.j,  3.+1.j,\n       -3.+3.j, -1.+3.j,  1.+3.j,  3.+3.j])\n</code></pre>"},{"location":"ref/QAModulation/#labeling","title":"<code>labeling</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The labeling $\\mathbf{Q}$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.labeling\narray([[0, 0, 0, 0], [0, 1, 0, 0], [1, 1, 0, 0], [1, 0, 0, 0],\n       [0, 0, 0, 1], [0, 1, 0, 1], [1, 1, 0, 1], [1, 0, 0, 1],\n       [0, 0, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1], [1, 0, 1, 1],\n       [0, 0, 1, 0], [0, 1, 1, 0], [1, 1, 1, 0], [1, 0, 1, 0]])\n</code></pre>"},{"location":"ref/QAModulation/#inverse_labeling","title":"<code>inverse_labeling</code><code>  dict[tuple[int, ...], int] </code>  <code>cached</code> <code>property</code>","text":"<p>The inverse labeling of the modulation. It is a dictionary that maps each binary tuple to the corresponding constellation index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.inverse_labeling\n{(0, 0, 0, 0): 0,  (0, 1, 0, 0): 1,  (1, 1, 0, 0): 2,  (1, 0, 0, 0): 3,\n (0, 0, 0, 1): 4,  (0, 1, 0, 1): 5,  (1, 1, 0, 1): 6,  (1, 0, 0, 1): 7,\n (0, 0, 1, 1): 8,  (0, 1, 1, 1): 9,  (1, 1, 1, 1): 10, (1, 0, 1, 1): 11,\n (0, 0, 1, 0): 12, (0, 1, 1, 0): 13, (1, 1, 1, 0): 14, (1, 0, 1, 0): 15}\n</code></pre>"},{"location":"ref/QAModulation/#order","title":"<code>order</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The order $M$ of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.order\n16\n</code></pre>"},{"location":"ref/QAModulation/#bits_per_symbol","title":"<code>bits_per_symbol</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number $m$ of bits per symbol of the modulation. It is given by $$     m = \\log_2 M, $$ where $M$ is the order of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.bits_per_symbol\n4\n</code></pre>"},{"location":"ref/QAModulation/#energy_per_symbol","title":"<code>energy_per_symbol</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average symbol energy $E_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   E_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} \\lVert x_i \\rVert^2, $$ where $\\lVert x_i \\rVert^2$ is the energy of constellation symbol $x_i$, and $M$ is the order of the modulation.</p> <p>For the QAM, it is given by $$     E_\\mathrm{s} = \\frac{A_\\mathrm{I}^2}{3} \\left( M_\\mathrm{I}^2 - 1 \\right) + \\frac{A_\\mathrm{Q}^2}{3} \\left( M_\\mathrm{Q}^2 - 1 \\right). $$ For the special case of a square QAM, it simplifies to $$     E_\\mathrm{s} = \\frac{2A^2}{3}(M - 1). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.energy_per_symbol\n10.0\n</code></pre>"},{"location":"ref/QAModulation/#energy_per_bit","title":"<code>energy_per_bit</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The average bit energy $E_\\mathrm{b}$ of the constellation. It assumes equiprobable symbols. It is given by $$     E_\\mathrm{b} = \\frac{E_\\mathrm{s}}{m}, $$ where $E_\\mathrm{s}$ is the average symbol energy, and $m$ is the number of bits per symbol of the modulation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.energy_per_bit\n2.5\n</code></pre>"},{"location":"ref/QAModulation/#symbol_mean","title":"<code>symbol_mean</code><code>  complex </code>  <code>cached</code> <code>property</code>","text":"<p>The mean $\\mu_\\mathrm{s}$ of the constellation. It assumes equiprobable symbols. It is given by $$   \\mu_\\mathrm{s} = \\frac{1}{M} \\sum_{i \\in [0:M)} x_i. $$</p> <p>For the QAM, it is given by $$     \\mu_\\mathrm{s} = 0. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.symbol_mean\n0j\n</code></pre>"},{"location":"ref/QAModulation/#minimum_distance","title":"<code>minimum_distance</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The minimum Euclidean distance $d_\\mathrm{min}$ of the constellation. It is given by $$     d_\\mathrm{min} = \\min_ { i, j \\in [0:M), ~ i \\neq j } \\lVert x_i - x_j \\rVert. $$</p> <p>For the QAM, it is given by $$     d_\\mathrm{min} = 2 \\min(A_\\mathrm{I}, A_\\mathrm{Q}). $$ For the special case of a square QAM, it simplifies to $$     d_\\mathrm{min} = 2 A. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.minimum_distance\n2.0\n</code></pre>"},{"location":"ref/QAModulation/#modulate","title":"<code>modulate()</code>","text":"<p>Modulates one or more sequences of bits to their corresponding constellation symbols.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $m$, or a multidimensional array where the last dimension is a multiple of $m$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[complexfloating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension divided by $m$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; qam = komm.QAModulation(16)\n&gt;&gt;&gt; qam.modulate([0, 0, 1, 1, 0, 0, 0, 1])\narray([-3.+1.j, -3.-1.j])\n</code></pre>"},{"location":"ref/QAModulation/#demodulate_hard","title":"<code>demodulate_hard()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of hard bits ($\\mathtt{0}$ or $\\mathtt{1}$) using hard-decision decoding.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/QAModulation/#demodulate_soft","title":"<code>demodulate_soft()</code>","text":"<p>Demodulates one or more sequences of received points to their corresponding sequences of soft bits (L-values) using soft-decision decoding. The soft bits are the log-likelihood ratios of the bits, where positive values correspond to bit $\\mathtt{0}$ and negative values correspond to bit $\\mathtt{1}$.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The received sequence(s). Can be either a single sequence, or a multidimensional array.</p> </li> <li> <code>snr</code> (<code>float</code>)         \u2013          <p>The signal-to-noise ratio (SNR) of the channel. It should be a positive real number. The default value is <code>1.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension multiplied by $m$.</p> </li> </ul>"},{"location":"ref/RaisedCosinePulse/","title":"komm.RaisedCosinePulse","text":"<p>Raised-cosine pulse. For a given roll-off factor $\\alpha$ satisfing $0 \\leq \\alpha \\leq 1$, it is a pulse with spectrum given by $$     \\hat{p}(f) = \\begin{cases}         1, &amp; |f| \\leq f_1, \\\\[1ex]         \\dfrac{1}{2} \\left( 1 + \\cos \\left( \\pi \\dfrac{|f| - f_1}{f_2 - f_1}\\right) \\right), &amp; f_1 \\leq |f| \\leq f_2, \\\\[1ex]         0, &amp; \\text{otherwise}.     \\end{cases} $$ where $f_1 = (1 - \\alpha) / 2$ and $f_2 = (1 + \\alpha) / 2$.</p> <p>The waveform of the raised-cosine pulse is depicted below for $\\alpha = 0.25$, and for $\\alpha = 0.75$.</p> <p> </p> <p>For more details, see Wikipedia: Raised-cosine filter.</p> Notes <ul> <li>For $\\alpha = 0$ it reduces to the sinc pulse.</li> <li>For $\\alpha = 1$ it becomes what is known as the full cosine roll-off pulse.</li> </ul> <p>Parameters:</p> <ul> <li> <code>rolloff</code> (<code>float</code>)         \u2013          <p>The roll-off factor $\\alpha$ of the pulse. Must satisfy $0 \\leq \\alpha \\leq 1$. The default value is <code>1.0</code>.</p> </li> </ul>"},{"location":"ref/RaisedCosinePulse/#waveform","title":"<code>waveform()</code>","text":"<p>The waveform $p(t)$ of the pulse.</p> <p>For the raised-cosine pulse, it is given by $$     p(t) = \\sinc(t) \\frac{\\cos(\\pi \\alpha t)}{1 - (2 \\alpha t)^2}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.waveform(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.   , 0.29 , 0.627, 0.897, 1.   , 0.897, 0.627, 0.29 , 0.   ])\n</code></pre>"},{"location":"ref/RaisedCosinePulse/#spectrum","title":"<code>spectrum()</code>","text":"<p>The spectrum $\\hat{p}(f)$ of the pulse.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; np.abs(pulse.spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ))\narray([0. , 0. , 0.5, 1. , 1. , 1. , 0.5, 0. , 0. ])\n</code></pre>"},{"location":"ref/RaisedCosinePulse/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>The autocorrelation function $R(\\tau)$ of the pulse.</p> <p>For the raised-cosine pulse, it is given by $$     R(\\tau) = \\sinc(\\tau) \\frac{\\cos(\\pi \\alpha \\tau)}{1 - (2 \\alpha \\tau)^2} - \\frac{\\alpha}{4} \\sinc(\\alpha \\tau) \\frac{\\cos(\\pi \\tau)}{1 - (\\alpha \\tau)^2}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.autocorrelation(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.06 , 0.334, 0.627, 0.853, 0.938, 0.853, 0.627, 0.334, 0.06 ])\n</code></pre>"},{"location":"ref/RaisedCosinePulse/#energy_density_spectrum","title":"<code>energy_density_spectrum()</code>","text":"<p>The energy density spectrum $S(f)$ of the pulse.</p> <p>For the raised-cosine pulse, it is given by $$     S(f) = \\begin{cases}         1, &amp; |f| \\leq f_1, \\\\[1ex]         \\dfrac{1}{4} \\left( 1 + \\cos \\left( \\pi \\dfrac{|f| - f_1}{f_2 - f_1}\\right) \\right)^2, &amp; f_1 \\leq |f| \\leq f_2, \\\\[1ex]         0, &amp; \\text{otherwise}.     \\end{cases} $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.energy_density_spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([0.  , 0.  , 0.25, 1.  , 1.  , 1.  , 0.25, 0.  , 0.  ])\n</code></pre>"},{"location":"ref/RaisedCosinePulse/#support","title":"<code>support</code><code>  tuple[float, float] </code>  <code>cached</code> <code>property</code>","text":"<p>The support of the pulse waveform $p(t)$, defined as the interval $[a, b]$ where $p(t)$ is non-zero.</p> <p>For the raised-cosine pulse, the support is given by $(-\\infty, \\infty)$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.support\n(-inf, inf)\n</code></pre>"},{"location":"ref/RaisedCosinePulse/#taps","title":"<code>taps()</code>","text":"<p>Returns the FIR taps of the pulse.</p> <p>Parameters:</p> <ul> <li> <code>samples_per_symbol</code> (<code>int</code>)         \u2013          <p>The number of samples per symbol.</p> </li> <li> <code>span</code> (<code>tuple[int, int] | None</code>)         \u2013          <p>The time span to consider for the taps. This parameter is optional for pulses with finite support (defaults to $[0, 1]$), but required for pulses with infinite support.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-1, 1)).round(3)\narray([0.   , 0.29 , 0.627, 0.897, 1.   , 0.897, 0.627, 0.29 , 0.   ])\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-16, 16)).shape\n(129,)\n</code></pre>"},{"location":"ref/RectangularPulse/","title":"komm.RectangularPulse","text":"<p>Rectangular pulse. It is a pulse with waveform given by $$     p(t) =     \\begin{cases}         1, &amp; 0 \\leq t &lt; w, \\\\         0, &amp; \\text{otherwise},     \\end{cases} $$ where $w$ is the relative width of the pulse, which must satisfy $0 &lt; w \\leq 1$.</p> <p>The waveform of the rectangular pulse is depicted below for $w = 1$, and for $w = 0.5$.</p> <p> </p> Notes <ul> <li>For $w = 1$ it is also called the NRZ pulse.</li> <li>For $w = 0.5$ it is also called the halfway RZ pulse.</li> </ul> <p>Parameters:</p> <ul> <li> <code>width</code> (<code>float</code>)         \u2013          <p>The relative width $w$ of the pulse. Must satisfy $0 &lt; w \\leq 1$. The default value is <code>1.0</code>.</p> </li> </ul>"},{"location":"ref/RectangularPulse/#waveform","title":"<code>waveform()</code>","text":"<p>The waveform $p(t)$ of the pulse.</p> <p>For the rectangular pulse, it is given by $$     p(t) = \\rect\\left(\\frac{t - w/2}{w}\\right). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=1.0)  # NRZ pulse\n&gt;&gt;&gt; pulse.waveform(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([0., 0., 0., 0., 1., 1., 1., 1., 0.])\n</code></pre> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=0.5)  # Halfway RZ pulse\n&gt;&gt;&gt; pulse.waveform(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([0., 0., 0., 0., 1., 1., 0., 0., 0.])\n</code></pre>"},{"location":"ref/RectangularPulse/#spectrum","title":"<code>spectrum()</code>","text":"<p>The spectrum $\\hat{p}(f)$ of the pulse.</p> <p>For the rectangular pulse, it is given by $$     \\hat{p}(f) = w \\sinc(w f) \\mathrm{e}^{-\\mathrm{j} 2 \\pi (w/2) f}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=1.0)  # NRZ pulse\n&gt;&gt;&gt; np.abs(pulse.spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )).round(3)\narray([0.   , 0.3  , 0.637, 0.9  , 1.   , 0.9  , 0.637, 0.3  , 0.   ])\n</code></pre> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=0.5)  # Halfway RZ pulse\n&gt;&gt;&gt; np.abs(pulse.spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )).round(3)\narray([0.318, 0.392, 0.45 , 0.487, 0.5  , 0.487, 0.45 , 0.392, 0.318])\n</code></pre>"},{"location":"ref/RectangularPulse/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>The autocorrelation function $R(\\tau)$ of the pulse.</p> <p>For the rectangular pulse, it is given by $$     R(\\tau) = w \\tri\\left(\\frac{\\tau}{w}\\right). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=1.0)  # NRZ pulse\n&gt;&gt;&gt; pulse.autocorrelation(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([0.  , 0.25, 0.5 , 0.75, 1.  , 0.75, 0.5 , 0.25, 0.  ])\n</code></pre> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=0.5)  # Halfway RZ pulse\n&gt;&gt;&gt; pulse.autocorrelation(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([0.  , 0.  , 0.  , 0.25, 0.5 , 0.25, 0.  , 0.  , 0.  ])\n</code></pre>"},{"location":"ref/RectangularPulse/#energy_density_spectrum","title":"<code>energy_density_spectrum()</code>","text":"<p>The energy density spectrum $S(f)$ of the pulse.</p> <p>For the rectangular pulse, it is given by $$     S(f) = w^2 \\sinc^2(w f). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=1.0)  # NRZ pulse\n&gt;&gt;&gt; pulse.energy_density_spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.   , 0.09 , 0.405, 0.811, 1.   , 0.811, 0.405, 0.09 , 0.   ])\n</code></pre> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=0.5)  # Halfway RZ pulse\n&gt;&gt;&gt; pulse.energy_density_spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.101, 0.154, 0.203, 0.237, 0.25 , 0.237, 0.203, 0.154, 0.101])\n</code></pre>"},{"location":"ref/RectangularPulse/#support","title":"<code>support</code><code>  tuple[float, float] </code>  <code>cached</code> <code>property</code>","text":"<p>The support of the pulse waveform $p(t)$, defined as the interval $[a, b]$ where $p(t)$ is non-zero.</p> <p>For the rectangular pulse, the support is given by $[0, w]$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=1.0)\n&gt;&gt;&gt; pulse.support\n(0.0, 1.0)\n</code></pre> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=0.5)\n&gt;&gt;&gt; pulse.support\n(0.0, 0.5)\n</code></pre>"},{"location":"ref/RectangularPulse/#taps","title":"<code>taps()</code>","text":"<p>Returns the FIR taps of the pulse.</p> <p>Parameters:</p> <ul> <li> <code>samples_per_symbol</code> (<code>int</code>)         \u2013          <p>The number of samples per symbol.</p> </li> <li> <code>span</code> (<code>tuple[int, int] | None</code>)         \u2013          <p>The time span to consider for the taps. This parameter is optional for pulses with finite support (defaults to $[0, 1]$), but required for pulses with infinite support.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RectangularPulse(width=1.0)\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4)  # Default span is [0, 1]\narray([1., 1., 1., 1., 0.])\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-1, 1))\narray([0., 0., 0., 0., 1., 1., 1., 1., 0.])\n</code></pre>"},{"location":"ref/ReedDecoder/","title":"komm.ReedDecoder","text":"<p>Reed decoder for Reed-Muller codes. It's a majority-logic decoding algorithm. For more details, see [LC04, Sec 4.3 and 10.9.1] for hard-decision decoding, and [LC04, Sec 10.9.2] for soft-decision decoding.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>ReedMullerCode</code>)         \u2013          <p>The Reed-Muller code to be used for decoding.</p> </li> <li> <code>input_type</code> (<code>Literal['hard', 'soft']</code>)         \u2013          <p>The type of the input. Either <code>'hard'</code> or <code>'soft'</code>. Default is <code>'hard'</code>.</p> </li> </ul> Notes <ul> <li>Input type: <code>hard</code> (bits) or <code>soft</code> (either L-values or channel outputs).</li> <li>Output type: <code>hard</code> (bits).</li> </ul>"},{"location":"ref/ReedDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ReedMullerCode(1, 3)\n&gt;&gt;&gt; decoder = komm.ReedDecoder(code, input_type=\"hard\")\n&gt;&gt;&gt; decoder([[0, 0, 0, 0, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 1, 1]])\narray([[0, 0, 0, 0],\n       [0, 0, 0, 1]])\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.ReedMullerCode(1, 3)\n&gt;&gt;&gt; decoder = komm.ReedDecoder(code, input_type=\"soft\")\n&gt;&gt;&gt; decoder([+1.3, +1.0, +0.9, +0.4, -0.8, +0.2, +0.3, +0.8])\narray([0, 0, 0, 0])\n</code></pre>"},{"location":"ref/ReedMullerCode/","title":"komm.ReedMullerCode","text":"<p>Reed\u2013Muller code. Let $\\mu$ and $\\rho$ be two integers such that $0 \\leq \\rho &lt; \\mu$. The Reed\u2013Muller code with parameters $(\\rho, \\mu)$ is the linear block code whose generator matrix rows are $$     \\mathbf{1}, \\, v_1, \\ldots, v_m, \\, v_1 v_2, v_1 v_3, \\ldots, v_{\\mu} v_{\\mu - 1}, \\, \\ldots \\, \\text{(up to products of degree $\\rho$)}, $$ where $\\mathbf{1}$ is the all-one $2^\\mu$-tuple, $v_i$ is the binary $2^\\mu$-tuple composed of $2^{\\mu-i}$ repetitions of alternating blocks of zeros and ones, each block of length $2^i$, for $1 \\leq i \\leq \\mu$, and $v_i v_j$ denotes the component-wise product (logical AND) of $v_i$ and $v_j$. Here we take the rows in reverse order. The resulting code has the following parameters:</p> <ul> <li>Length: $n = 2^{\\mu}$</li> <li>Dimension: $k = 1 + {\\mu \\choose 1} + \\cdots + {\\mu \\choose \\rho}$</li> <li>Redundancy: $m = 1 + {\\mu \\choose 1} + \\cdots + {\\mu \\choose \\mu - \\rho - 1}$</li> <li>Minimum distance: $d = 2^{\\mu - \\rho}$</li> </ul> <p>For more details, see LC04, Sec. 4.3.</p> Notes <ul> <li>For $\\rho = 0$ it reduces to a repetition code.</li> <li>For $\\rho = 1$ it reduces to a lengthened simplex code.</li> <li>For $\\rho = \\mu - 2$ it reduces to an extended Hamming code.</li> <li>For $\\rho = \\mu - 1$ it reduces to a single parity-check code.</li> </ul> <p>Parameters:</p> <ul> <li> <code>rho</code> (<code>int</code>)         \u2013          <p>The parameter $\\rho$ of the code.</p> </li> <li> <code>mu</code> (<code>int</code>)         \u2013          <p>The parameter $\\mu$ of the code.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ReedMullerCode(2, 4)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(16, 11, 5)\n&gt;&gt;&gt; code.generator_matrix\narray([[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1],\n       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n       [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n       [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n       [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n4\n</code></pre>"},{"location":"ref/ReedMullerCode/#reed_partitions","title":"<code>reed_partitions()</code>  <code>cached</code>","text":"<p>The Reed partitions of the code. See LC04, Sec. 4.3.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.ReedMullerCode(2, 4)\n&gt;&gt;&gt; reed_partitions = code.reed_partitions()\n&gt;&gt;&gt; reed_partitions[1]\narray([[ 0,  1,  4,  5],\n       [ 2,  3,  6,  7],\n       [ 8,  9, 12, 13],\n       [10, 11, 14, 15]])\n&gt;&gt;&gt; reed_partitions[8]\narray([[ 0,  4],\n       [ 1,  5],\n       [ 2,  6],\n       [ 3,  7],\n       [ 8, 12],\n       [ 9, 13],\n       [10, 14],\n       [11, 15]])\n</code></pre>"},{"location":"ref/RepetitionCode/","title":"komm.RepetitionCode","text":"<p>Repetition code. For a given length $n \\geq 1$, it is the linear block code whose only two codewords are $00 \\cdots 0$ and $11 \\cdots 1$. The repetition code has the following parameters:</p> <ul> <li>Length: $n$</li> <li>Dimension: $k = 1$</li> <li>Redundancy: $m = n - 1$</li> <li>Minimum distance: $d = n$</li> </ul> Notes <ul> <li>Its dual is the single parity-check code.</li> </ul> <p>Parameters:</p> <ul> <li> <code>n</code> (<code>int</code>)         \u2013          <p>The length $n$ of the code. Must be a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.RepetitionCode(5)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(5, 1, 4)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 1, 1, 1, 1]])\n&gt;&gt;&gt; code.check_matrix\narray([[1, 1, 0, 0, 0],\n       [1, 0, 1, 0, 0],\n       [1, 0, 0, 1, 0],\n       [1, 0, 0, 0, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n5\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.RepetitionCode(16)\n&gt;&gt;&gt; code.codeword_weight_distribution()\narray([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n&gt;&gt;&gt; code.coset_leader_weight_distribution()\narray([    1,    16,   120,   560,  1820,  4368,  8008, 11440,  6435,\n           0,     0,     0,     0,     0,     0,     0,     0])\n</code></pre>"},{"location":"ref/RootRaisedCosinePulse/","title":"komm.RootRaisedCosinePulse","text":"<p>Root-raised-cosine pulse. It is a pulse whose spectrum is given by the square root of the spectrum of the raised cosine pulse with same roll-off factor.</p> <p>The waveform of the root-raised cosine pulse is depicted below for $\\alpha = 0.25$, and for $\\alpha = 0.75$.</p> <p> </p> <p>For more details, see Wikipedia: Root-raised-cosine filter.</p> <p>Parameters:</p> <ul> <li> <code>rolloff</code> (<code>float</code>)         \u2013          <p>The roll-off factor $\\alpha$ of the pulse. Must satisfy $0 \\leq \\alpha \\leq 1$. The default value is <code>1.0</code>.</p> </li> </ul>"},{"location":"ref/RootRaisedCosinePulse/#waveform","title":"<code>waveform()</code>","text":"<p>The waveform $p(t)$ of the pulse.</p> <p>For the root-raised-cosine pulse, it is given by $$   p(t) = \\frac{\\sin ( 2 \\pi f_1 t ) + 4 \\alpha t \\cos ( 2 \\pi f_2 t )}{\\pi t ( 1 - (4 \\alpha t)^2 )}, $$ where $\\alpha$ is the roll-off factor, $f_1 = (1 - \\alpha) / 2$, and $f_2 = (1 + \\alpha) / 2$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RootRaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.waveform(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([-0.064,  0.238,  0.622,  0.943,  1.068,  0.943,  0.622,  0.238,\n       -0.064])\n</code></pre>"},{"location":"ref/RootRaisedCosinePulse/#spectrum","title":"<code>spectrum()</code>","text":"<p>The spectrum $\\hat{p}(f)$ of the pulse.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RootRaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; np.abs(pulse.spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )).round(3)\narray([0.   , 0.   , 0.707, 1.   , 1.   , 1.   , 0.707, 0.   , 0.   ])\n</code></pre>"},{"location":"ref/RootRaisedCosinePulse/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>The autocorrelation function $R(\\tau)$ of the pulse.</p> <p>For the root-raised-cosine pulse, it is given by $$     R(\\tau) = \\sinc(\\tau) \\frac{\\cos(\\pi \\alpha \\tau)}{1 - (2 \\alpha \\tau)^2}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RootRaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.autocorrelation(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.   , 0.29 , 0.627, 0.897, 1.   , 0.897, 0.627, 0.29 , 0.   ])\n</code></pre>"},{"location":"ref/RootRaisedCosinePulse/#energy_density_spectrum","title":"<code>energy_density_spectrum()</code>","text":"<p>The energy density spectrum $S(f)$ of the pulse.</p> <p>For the root-raised-cosine pulse, it is given by $$     S(f) = \\begin{cases}         1, &amp; |f| \\leq f_1, \\\\[1ex]         \\dfrac{1}{2} \\left( 1 + \\cos \\left( \\pi \\dfrac{|f| - f_1}{f_2 - f_1}\\right) \\right), &amp; f_1 \\leq |f| \\leq f_2, \\\\[1ex]         0, &amp; \\text{otherwise}.     \\end{cases} $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RootRaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.energy_density_spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0. , 0. , 0.5, 1. , 1. , 1. , 0.5, 0. , 0. ])\n</code></pre>"},{"location":"ref/RootRaisedCosinePulse/#support","title":"<code>support</code><code>  tuple[float, float] </code>  <code>cached</code> <code>property</code>","text":"<p>The support of the pulse waveform $p(t)$, defined as the interval $[a, b]$ where $p(t)$ is non-zero.</p> <p>For the root-raised-cosine pulse, the support is given by $(-\\infty, \\infty)$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RootRaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.support\n(-inf, inf)\n</code></pre>"},{"location":"ref/RootRaisedCosinePulse/#taps","title":"<code>taps()</code>","text":"<p>Returns the FIR taps of the pulse.</p> <p>Parameters:</p> <ul> <li> <code>samples_per_symbol</code> (<code>int</code>)         \u2013          <p>The number of samples per symbol.</p> </li> <li> <code>span</code> (<code>tuple[int, int] | None</code>)         \u2013          <p>The time span to consider for the taps. This parameter is optional for pulses with finite support (defaults to $[0, 1]$), but required for pulses with infinite support.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.RootRaisedCosinePulse(rolloff=0.25)\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-1, 1)).round(3)\narray([-0.064,  0.238,  0.622,  0.943,  1.068,  0.943,  0.622,  0.238,\n       -0.064])\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-16, 16)).shape\n(129,)\n</code></pre>"},{"location":"ref/SCDecoder/","title":"komm.SCDecoder","text":"<p>Successive cancellation decoder for Polar codes.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>PolarCode</code>)         \u2013          <p>The Polar code to be used for decoding.</p> </li> <li> <code>output_type</code> (<code>Literal['hard', 'soft']</code>)         \u2013          <p>The type of the output. Either <code>'hard'</code> or <code>'soft'</code>. Default is <code>'soft'</code>.</p> </li> </ul> Notes <ul> <li>Input type: <code>soft</code> (L-values).</li> <li>Output type: <code>hard</code> (bits) or <code>soft</code> (L-values).</li> </ul>"},{"location":"ref/SCDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.PolarCode(3, [0, 1, 2, 4])\n</code></pre> <pre><code>&gt;&gt;&gt; decoder = komm.SCDecoder(code)\n&gt;&gt;&gt; decoder([1, -4, -3, 2, -2, 3, 4, -1])\narray([ -6.84595089,  -5.96379094,  -9.30685282, -20.        ])\n</code></pre> <pre><code>&gt;&gt;&gt; decoder = komm.SCDecoder(code, output_type=\"hard\")\n&gt;&gt;&gt; decoder([1, -4, -3, 2, -2, 3, 4, -1])\narray([1, 1, 1, 1])\n</code></pre>"},{"location":"ref/ScalarQuantizer/","title":"komm.ScalarQuantizer","text":"<p>General scalar quantizer. It is defined by a list of levels, $v_0, v_1, \\ldots, v_{L-1}$, and a list of thresholds, $t_0, t_1, \\ldots, t_L$, satisfying $$     -\\infty = t_0 &lt; v_0 &lt; t_1 &lt; v_1 &lt; \\cdots &lt; t_{L - 1} &lt; v_{L - 1} &lt; t_L = +\\infty. $$ Given an input $x \\in \\mathbb{R}$, the output of the quantizer is given by $y = v_i$ if and only if $t_i \\leq x &lt; t_{i+1}$, where $i \\in [0:L)$. For more details, see Say06, Ch. 9.</p> <p>Parameters:</p> <ul> <li> <code>levels</code> (<code>ArrayLike</code>)         \u2013          <p>The quantizer levels $v_0, v_1, \\ldots, v_{L-1}$. It should be a list floats of length $L$.</p> </li> <li> <code>thresholds</code> (<code>ArrayLike</code>)         \u2013          <p>The quantizer finite thresholds $t_1, t_2, \\ldots, t_{L-1}$. It should be a list of floats of length $L - 1$.</p> </li> </ul> <p>Examples:</p> <p>The $5$-level scalar quantizer whose characteristic (input \u00d7 output) curve is depicted in the figure below has levels $$     v_0 = -2, ~ v_1 = -1, ~ v_2 = 0, ~ v_3 = 1, ~ v_4 = 2, $$ and thresholds $$     t_0 = -\\infty, ~ t_1 = -1.5, ~ t_2 = -0.3, ~ t_3 = 0.8, ~ t_4 = 1.4, ~ t_5 = \\infty. $$</p> <p></p> <pre><code>&gt;&gt;&gt; quantizer = komm.ScalarQuantizer(\n...     levels=[-2.0, -1.0, 0.0, 1.0, 2.0],\n...     thresholds=[-1.5, -0.3, 0.8, 1.4],\n... )\n</code></pre>"},{"location":"ref/ScalarQuantizer/#levels","title":"<code>levels</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The quantizer levels $v_0, v_1, \\ldots, v_{L-1}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.ScalarQuantizer(\n...     levels=[-2.0, -1.0, 0.0, 1.0, 2.0],\n...     thresholds=[-1.5, -0.3, 0.8, 1.4],\n... )\n&gt;&gt;&gt; quantizer.levels\narray([-2., -1.,  0.,  1.,  2.])\n</code></pre>"},{"location":"ref/ScalarQuantizer/#thresholds","title":"<code>thresholds</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The quantizer finite thresholds $t_1, t_2, \\ldots, t_{L-1}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.ScalarQuantizer(\n...     levels=[-2.0, -1.0, 0.0, 1.0, 2.0],\n...     thresholds=[-1.5, -0.3, 0.8, 1.4],\n... )\n&gt;&gt;&gt; quantizer.thresholds\narray([-1.5, -0.3,  0.8,  1.4])\n</code></pre>"},{"location":"ref/ScalarQuantizer/#mean_squared_error","title":"<code>mean_squared_error()</code>","text":"<p>Computes the mean squared (quantization) error (MSE) of the quantizer for a given input probability density function (pdf). It is defined as $$     \\mse = \\int_{-\\infty}^{\\infty} (x - y)^2 f_X(x) \\, dx $$ where $y$ is the quantized signal and $f_X(x)$ is the pdf of the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input_pdf</code> (<code>Callable[[NDArray[floating]], NDArray[floating]]</code>)         \u2013          <p>The probability density function $f_X(x)$ of the input signal.</p> </li> <li> <code>input_range</code> (<code>tuple[float, float]</code>)         \u2013          <p>The range $(x_\\mathrm{min}, x_\\mathrm{max})$ of the input signal.</p> </li> <li> <code>points_per_interval</code> (<code>int</code>)         \u2013          <p>The number of points per interval for numerical integration (default: 4096).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>mse</code>  (<code>float</code>)          \u2013          <p>The mean square quantization error.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.ScalarQuantizer(\n...     levels=[-2.0, -1.0, 0.0, 1.0, 2.0],\n...     thresholds=[-1.5, -0.3, 0.8, 1.4],\n... )\n&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer.mean_squared_error(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n... )\n0.13598089455499335\n</code></pre>"},{"location":"ref/ScalarQuantizer/#digitize","title":"<code>digitize()</code>","text":"<p>Returns the quantization indices for the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input signal $x$ to be digitized.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The integer indices of the quantization levels for each input sample.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.ScalarQuantizer(\n...     levels=[-2.0, -1.0, 0.0, 1.0, 2.0],\n...     thresholds=[-1.5, -0.3, 0.8, 1.4],\n... )\n&gt;&gt;&gt; quantizer.digitize([-2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5])\narray([0, 0, 1, 1, 1, 2, 2, 3, 4, 4, 4])\n</code></pre>"},{"location":"ref/ScalarQuantizer/#quantize","title":"<code>quantize()</code>","text":"<p>Quantizes the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input signal $x$ to be quantized.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The quantized signal $y$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.ScalarQuantizer(\n...     levels=[-2.0, -1.0, 0.0, 1.0, 2.0],\n...     thresholds=[-1.5, -0.3, 0.8, 1.4],\n... )\n&gt;&gt;&gt; quantizer.quantize([-2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5])\narray([-2., -2., -1., -1., -1.,  0.,  0.,  1.,  2.,  2.,  2.])\n</code></pre>"},{"location":"ref/ShannonCode/","title":"komm.ShannonCode","text":"<p>Binary Shannon code. It is a fixed-to-variable length code in which the length of the codeword $\\Enc(u)$ for a source symbol $u \\in \\mathcal{S}^k$ is given by $$     \\ell_u = \\left\\lceil \\log_2 \\frac{1}{p_u} \\right\\rceil, $$ where $p_u$ is the probability of the source symbol $u$. This function implements the lexicographic order assignment as described in Wikipedia: Shannon\u2013Fano coding.</p> Notes <p>Shannon codes are always prefix-free (hence uniquely decodable).</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function of the source.</p> </li> <li> <code>source_block_size</code> (<code>int</code>)         \u2013          <p>The source block size $k$. The default value is $k = 1$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pmf = [0.7, 0.15, 0.15]\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.ShannonCode(pmf, 1)\n&gt;&gt;&gt; code.enc_mapping\n{(0,): (0,),\n (1,): (1, 0, 0),\n (2,): (1, 0, 1)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(1.6)\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.ShannonCode(pmf, 2)\n&gt;&gt;&gt; code.enc_mapping\n{(0, 0): (0, 0),\n (0, 1): (0, 1, 0, 0),\n (0, 2): (0, 1, 0, 1),\n (1, 0): (0, 1, 1, 0),\n (1, 1): (1, 0, 0, 0, 0, 0),\n (1, 2): (1, 0, 0, 0, 0, 1),\n (2, 0): (0, 1, 1, 1),\n (2, 1): (1, 0, 0, 0, 1, 0),\n (2, 2): (1, 0, 0, 0, 1, 1)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(1.6)\n</code></pre>"},{"location":"ref/SimplexCode/","title":"komm.SimplexCode","text":"<p>Simplex (maximum-length) code. For a given parameter $\\kappa \\geq 2$, it is the linear block code with generator matrix whose columns are all the $2^\\kappa - 1$ nonzero binary $\\kappa$-tuples. The simplex code (also known as maximum-length code) has the following parameters:</p> <ul> <li>Length: $n = 2^\\kappa - 1$</li> <li>Dimension: $k = \\kappa$</li> <li>Redundancy: $m = 2^\\kappa - \\kappa - 1$</li> <li>Minimum distance: $d = 2^{\\kappa - 1}$</li> </ul> <p>In its extended version, the simplex code has the following parameters:</p> <ul> <li>Length: $n = 2^\\kappa$</li> <li>Dimension: $k = \\kappa + 1$</li> <li>Redundancy: $m = 2^\\kappa - \\kappa - 1$</li> <li>Minimum distance: $d = 2^{\\kappa - 1}$</li> </ul> Notes <ul> <li>For $\\kappa = 2$ it reduces to the single parity-check code of length $3$.</li> <li>Its dual is the Hamming code.</li> <li>Simplex codes are constant-weight codes.</li> </ul> <p>Parameters:</p> <ul> <li> <code>kappa</code> (<code>int</code>)         \u2013          <p>The parameter $\\kappa$ of the code. Must satisfy $\\kappa \\geq 2$.</p> </li> <li> <code>extended</code> (<code>bool</code>)         \u2013          <p>Whether to use the extended version of the Simplex code. Default is <code>False</code>.</p> </li> </ul> <p>This class represents the code in systematic form, with the information set on the left.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SimplexCode(3)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(7, 3, 4)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 1, 1, 0, 1],\n       [0, 1, 0, 1, 0, 1, 1],\n       [0, 0, 1, 0, 1, 1, 1]])\n&gt;&gt;&gt; code.check_matrix\narray([[1, 1, 0, 1, 0, 0, 0],\n       [1, 0, 1, 0, 1, 0, 0],\n       [0, 1, 1, 0, 0, 1, 0],\n       [1, 1, 1, 0, 0, 0, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n4\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.SimplexCode(3, extended=True)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(8, 4, 4)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 0, 1, 1, 0, 1],\n       [0, 1, 0, 0, 1, 0, 1, 1],\n       [0, 0, 1, 0, 0, 1, 1, 1],\n       [0, 0, 0, 1, 1, 1, 1, 0]])\n&gt;&gt;&gt; code.check_matrix\narray([[1, 1, 0, 1, 1, 0, 0, 0],\n       [1, 0, 1, 1, 0, 1, 0, 0],\n       [0, 1, 1, 1, 0, 0, 1, 0],\n       [1, 1, 1, 0, 0, 0, 0, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n4\n</code></pre>"},{"location":"ref/SincPulse/","title":"komm.SincPulse","text":"<p>Sinc pulse. It is a pulse with waveform given by $$     p(t) = \\frac{\\sin(\\pi t)}{\\pi t} = \\sinc(t). $$</p> <p>The waveform of the sinc pulse is depicted below.</p> <p></p> <p>Parameters:</p> <p>(No parameters)</p>"},{"location":"ref/SincPulse/#waveform","title":"<code>waveform()</code>","text":"<p>The waveform $p(t)$ of the pulse.</p> <p>For the sinc pulse, it is given by $$     p(t) = \\sinc(t). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.SincPulse()\n&gt;&gt;&gt; pulse.waveform(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.   , 0.3  , 0.637, 0.9  , 1.   , 0.9  , 0.637, 0.3  , 0.   ])\n</code></pre>"},{"location":"ref/SincPulse/#spectrum","title":"<code>spectrum()</code>","text":"<p>The spectrum $\\hat{p}(f)$ of the pulse.</p> <p>For the sinc pulse, it is given by $$     \\hat{p}(f) = \\rect(f). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.SincPulse()\n&gt;&gt;&gt; np.abs(pulse.spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ))\narray([0., 0., 1., 1., 1., 1., 0., 0., 0.])\n</code></pre>"},{"location":"ref/SincPulse/#autocorrelation","title":"<code>autocorrelation()</code>","text":"<p>The autocorrelation function $R(\\tau)$ of the pulse.</p> <p>For the sinc pulse, it is given by $$     R(\\tau) = \\sinc(\\tau). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.SincPulse()\n&gt;&gt;&gt; pulse.autocorrelation(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... ).round(3)\narray([0.   , 0.3  , 0.637, 0.9  , 1.   , 0.9  , 0.637, 0.3  , 0.   ])\n</code></pre>"},{"location":"ref/SincPulse/#energy_density_spectrum","title":"<code>energy_density_spectrum()</code>","text":"<p>The energy density spectrum $S(f)$ of the pulse.</p> <p>For the sinc pulse, it is given by $$     S(f) = \\rect(f). $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.SincPulse()\n&gt;&gt;&gt; pulse.energy_density_spectrum(\n...     [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0],\n... )\narray([0., 0., 1., 1., 1., 1., 0., 0., 0.])\n</code></pre>"},{"location":"ref/SincPulse/#support","title":"<code>support</code><code>  tuple[float, float] </code>  <code>cached</code> <code>property</code>","text":"<p>The support of the pulse waveform $p(t)$, defined as the interval $[a, b]$ where $p(t)$ is non-zero.</p> <p>For the sinc pulse, the support is given by $(-\\infty, \\infty)$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.SincPulse()\n&gt;&gt;&gt; pulse.support\n(-inf, inf)\n</code></pre>"},{"location":"ref/SincPulse/#taps","title":"<code>taps()</code>","text":"<p>Returns the FIR taps of the pulse.</p> <p>Parameters:</p> <ul> <li> <code>samples_per_symbol</code> (<code>int</code>)         \u2013          <p>The number of samples per symbol.</p> </li> <li> <code>span</code> (<code>tuple[int, int] | None</code>)         \u2013          <p>The time span to consider for the taps. This parameter is optional for pulses with finite support (defaults to $[0, 1]$), but required for pulses with infinite support.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pulse = komm.SincPulse()\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-1, 1)).round(3)\narray([0.   , 0.3  , 0.637, 0.9  , 1.   , 0.9  , 0.637, 0.3  , 0.   ])\n&gt;&gt;&gt; pulse.taps(samples_per_symbol=4, span=(-16, 16)).shape\n(129,)\n</code></pre>"},{"location":"ref/SingleParityCheckCode/","title":"komm.SingleParityCheckCode","text":"<p>Single parity-check code. For a given length $n \\geq 1$, it is the linear block code whose codewords are obtained by extending $n - 1$ information bits with a single parity-check bit. The repetition code has the following parameters:</p> <ul> <li>Length: $n$.</li> <li>Dimension: $k = n - 1$.</li> <li>Redundancy: $m = 1$.</li> <li>Minimum distance: $d = 2$.</li> </ul> Notes <ul> <li>Its dual is the repetition code.</li> </ul> <p>Parameters:</p> <ul> <li> <code>n</code> (<code>int</code>)         \u2013          <p>The length $n$ of the code. Must be a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SingleParityCheckCode(5)\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(5, 4, 1)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 0, 1],\n       [0, 1, 0, 0, 1],\n       [0, 0, 1, 0, 1],\n       [0, 0, 0, 1, 1]])\n&gt;&gt;&gt; code.check_matrix\narray([[1, 1, 1, 1, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n2\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.SingleParityCheckCode(16)\n&gt;&gt;&gt; code.codeword_weight_distribution()\narray([    1,     0,   120,     0,  1820,     0,  8008,     0, 12870,\n           0,  8008,     0,  1820,     0,   120,     0,     1])\n&gt;&gt;&gt; code.coset_leader_weight_distribution()\narray([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n</code></pre>"},{"location":"ref/SlepianArray/","title":"komm.SlepianArray","text":"<p>Slepian array (standard array) for a linear block code. It is a table with $2^m$ rows and $2^k$ columns, where $m$ is the redundancy, and $k$ is the dimension of the code. Each row corresponds to a coset of the group of codewords, in which:</p> <ul> <li> <p>The first row is the group of codewords itself.</p> </li> <li> <p>The first column contains coset leaders (i.e., elements of minimal weight in its coset).</p> </li> </ul> <p>In this implementation:</p> <ul> <li> <p>A row's index $i$ corresponds to the $m$-bit syndrome obtained by expressing $i$ in binary (MSB on the right).</p> </li> <li> <p>A column's index $j$ corresponds to the $k$-bit message obtained by expressing $j$ in binary (MSB on the right).</p> </li> </ul> <p>For more details, see LC04, Sec. 3.5.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>BlockCode</code>)         \u2013          <p>The linear block code for which the Slepian array is generated.</p> </li> </ul>"},{"location":"ref/SlepianArray/#entry","title":"<code>entry()</code>","text":"<p>The entry at the $i$-th row and $j$-th column of the Slepian array.</p> <p>Parameters:</p> <ul> <li> <code>i</code> (<code>int</code>)         \u2013          <p>The index of the row.</p> </li> <li> <code>j</code> (<code>int</code>)         \u2013          <p>The index of the column.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[[1, 0, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1], [0, 0, 1, 1, 1, 0]])\n&gt;&gt;&gt; sa = komm.SlepianArray(code)\n&gt;&gt;&gt; binlist2str = lambda binlist: \"\".join(str(bit) for bit in binlist)\n&gt;&gt;&gt; m, k = code.redundancy, code.dimension\n&gt;&gt;&gt; for i in range(2**m):\n...     for j in range(2**k):\n...         print(binlist2str(sa.entry(i, j)), end=\" \")\n...     print()\n000000 100011 010101 110110 001110 101101 011011 111000\n000100 100111 010001 110010 001010 101001 011111 111100\n000010 100001 010111 110100 001100 101111 011001 111010\n001000 101011 011101 111110 000110 100101 010011 110000\n000001 100010 010100 110111 001111 101100 011010 111001\n010000 110011 000101 100110 011110 111101 001011 101000\n100000 000011 110101 010110 101110 001101 111011 011000\n100100 000111 110001 010010 101010 001001 111111 011100\n</code></pre>"},{"location":"ref/SlepianArray/#row","title":"<code>row()</code>","text":"<p>The $i$-th row of the Slepian array.</p> <p>Parameters:</p> <ul> <li> <code>i</code> (<code>int</code>)         \u2013          <p>The index of the row.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[[1, 0, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1], [0, 0, 1, 1, 1, 0]])\n&gt;&gt;&gt; sa = komm.SlepianArray(code)\n&gt;&gt;&gt; sa.row(0)  # The codewords\narray([[0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 1, 1],\n       [0, 1, 0, 1, 0, 1],\n       [1, 1, 0, 1, 1, 0],\n       [0, 0, 1, 1, 1, 0],\n       [1, 0, 1, 1, 0, 1],\n       [0, 1, 1, 0, 1, 1],\n       [1, 1, 1, 0, 0, 0]])\n</code></pre>"},{"location":"ref/SlepianArray/#col","title":"<code>col()</code>","text":"<p>The $j$-th column of the Slepian array.</p> <p>Parameters:</p> <ul> <li> <code>j</code> (<code>int</code>)         \u2013          <p>The index of the column.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.BlockCode(generator_matrix=[[1, 0, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1], [0, 0, 1, 1, 1, 0]])\n&gt;&gt;&gt; sa = komm.SlepianArray(code)\n&gt;&gt;&gt; sa.col(0)  # The coset leaders\narray([[0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 1, 0],\n       [0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1],\n       [0, 1, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0],\n       [1, 0, 0, 1, 0, 0]])\n</code></pre>"},{"location":"ref/SyndromeTableDecoder/","title":"komm.SyndromeTableDecoder","text":"<p>Syndrome table decoder for general block codes. This decoder implements syndrome-based hard-decision decoding using a precomputed table of coset leaders.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>BlockCode</code>)         \u2013          <p>The block code to be used for decoding.</p> </li> </ul> Notes <ul> <li>Input type: <code>hard</code> (bits).</li> <li>Output type: <code>hard</code> (bits).</li> </ul>"},{"location":"ref/SyndromeTableDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.HammingCode(3)\n&gt;&gt;&gt; decoder = komm.SyndromeTableDecoder(code)\n&gt;&gt;&gt; decoder([[1, 1, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0]])\narray([[1, 1, 0, 0],\n       [1, 0, 1, 1]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/","title":"komm.SystematicBlockCode","text":"<p>Systematic linear block code. A systematic linear block code is a linear block code in which the information bits can be found in predefined positions in the codeword, called the information set $\\mathcal{K}$, which is a $k$-sublist of $[0 : n)$; the remaining positions are called the parity set $\\mathcal{M}$, which is a $m$-sublist of $[0 : n)$. In this case, the generator matrix then has the property that the columns indexed by $\\mathcal{K}$ are equal to $I_k$, and the columns indexed by $\\mathcal{M}$ are equal to $P$. The check matrix has the property that the columns indexed by $\\mathcal{M}$ are equal to $I_m$, and the columns indexed by $\\mathcal{K}$ are equal to $P^\\transpose$. The matrix $P \\in \\mathbb{B}^{k \\times m}$ is called the parity submatrix of the code.</p> <p>The constructor expects the parity submatrix and the information set.</p> <p>Parameters:</p> <ul> <li> <code>parity_submatrix</code> (<code>ArrayLike</code>)         \u2013          <p>The parity submatrix $P$ the code, which is a $k \\times m$ binary matrix.</p> </li> <li> <code>information_set</code> (<code>Literal['left', 'right'] | ArrayLike</code>)         \u2013          <p>Either an array containing the indices of the information positions, which must be a $k$-sublist of $[0 : n)$, or one of the strings <code>'left'</code> or <code>'right'</code>. The default value is <code>'left'</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(5, 2, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0]])\n&gt;&gt;&gt; code.check_matrix\narray([[0, 1, 1, 0, 0],\n       [1, 1, 0, 1, 0],\n       [1, 0, 0, 0, 1]])\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(\n...     parity_submatrix=[[0, 1, 1], [1, 1, 0]],\n...     information_set='right',\n... )\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(5, 2, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[0, 1, 1, 1, 0],\n       [1, 1, 0, 0, 1]])\n&gt;&gt;&gt; code.check_matrix\narray([[1, 0, 0, 0, 1],\n       [0, 1, 0, 1, 1],\n       [0, 0, 1, 1, 0]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#length","title":"<code>length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The length $n$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.length\n5\n</code></pre>"},{"location":"ref/SystematicBlockCode/#dimension","title":"<code>dimension</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The dimension $k$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.dimension\n2\n</code></pre>"},{"location":"ref/SystematicBlockCode/#redundancy","title":"<code>redundancy</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The redundancy $m$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.redundancy\n3\n</code></pre>"},{"location":"ref/SystematicBlockCode/#rate","title":"<code>rate</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The rate $R = k/n$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.rate\n0.4\n</code></pre>"},{"location":"ref/SystematicBlockCode/#generator_matrix","title":"<code>generator_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The generator matrix $G \\in \\mathbb{B}^{k \\times n}$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#check_matrix","title":"<code>check_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The check matrix $H \\in \\mathbb{B}^{m \\times n}$ of the code.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.check_matrix\narray([[0, 1, 1, 0, 0],\n       [1, 1, 0, 1, 0],\n       [1, 0, 0, 0, 1]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#encode","title":"<code>encode()</code>","text":"<p>Applies the encoding mapping $\\Enc : \\mathbb{B}^k \\to \\mathbb{B}^n$ of the code. This method takes one or more sequences of messages and returns their corresponding codeword sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $k$, or a multidimensional array where the last dimension is a multiple of $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension expanded from $bk$ to $bn$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0]])\n&gt;&gt;&gt; code.encode([0, 0])  # Sequence with single message\narray([0, 0, 0, 0, 0])\n&gt;&gt;&gt; code.encode([0, 0, 1, 1])  # Sequence with two messages\narray([0, 0, 0, 0, 0, 1, 1, 1, 0, 1])\n&gt;&gt;&gt; code.encode([[0, 0],  # 2D array of single messages\n...              [1, 1]])\narray([[0, 0, 0, 0, 0],\n       [1, 1, 1, 0, 1]])\n&gt;&gt;&gt; code.encode([[0, 0, 1, 1],  # 2D array of two messages\n...              [1, 1, 1, 0]])\narray([[0, 0, 0, 0, 0, 1, 1, 1, 0, 1],\n       [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#inverse_encode","title":"<code>inverse_encode()</code>","text":"<p>Applies the inverse encoding partial mapping $\\Enc^{-1} : \\mathbb{B}^n \\rightharpoonup \\mathbb{B}^k$ of the code. This method takes one or more sequences of codewords and returns their corresponding message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the input contains any invalid codewords.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.inverse_encode([0, 0, 0, 0, 0])  # Sequence with single codeword\narray([0, 0])\n&gt;&gt;&gt; code.inverse_encode([0, 0, 0, 0, 0, 1, 1, 1, 0, 1])  # Sequence with two codewords\narray([0, 0, 1, 1])\n&gt;&gt;&gt; code.inverse_encode([[0, 0, 0, 0, 0],  # 2D array of single codewords\n...                      [1, 1, 1, 0, 1]])\narray([[0, 0],\n       [1, 1]])\n&gt;&gt;&gt; code.inverse_encode([[0, 0, 0, 0, 0, 1, 1, 1, 0, 1],  # 2D array of two codewords\n...                      [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]])\narray([[0, 0, 1, 1],\n       [1, 1, 1, 0]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#check","title":"<code>check()</code>","text":"<p>Applies the check mapping $\\mathrm{Chk} : \\mathbb{B}^n \\to \\mathbb{B}^m$ of the code. This method takes one or more sequences of received words and returns their corresponding syndrome sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bm$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.check([1, 1, 1, 0, 1])  # Sequence with single received word\narray([0, 0, 0])\n&gt;&gt;&gt; code.check([1, 1, 1, 0, 1, 1, 1, 1, 1, 1])  # Sequence with two received words\narray([0, 0, 0, 0, 1, 0])\n&gt;&gt;&gt; code.check([[1, 1, 1, 0, 1],  # 2D array of single received words\n...             [1, 1, 1, 1, 1]])\narray([[0, 0, 0],\n       [0, 1, 0]])\n&gt;&gt;&gt; code.check([[1, 1, 1, 0, 1, 1, 1, 1, 1, 1],  # 2D array of two received words\n...             [1, 1, 1, 1, 1, 0, 0, 0, 1, 1]])\narray([[0, 0, 0, 0, 1, 0],\n       [0, 1, 0, 0, 1, 1]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#codewords","title":"<code>codewords()</code>  <code>cached</code>","text":"<p>Returns the codewords of the code. This is a $2^k \\times n$ matrix whose rows are all the codewords. The codeword in row $i$ corresponds to the message obtained by expressing $i$ in binary with $k$ bits (MSB in the right).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.codewords()\narray([[0, 0, 0, 0, 0],\n       [1, 0, 0, 1, 1],\n       [0, 1, 1, 1, 0],\n       [1, 1, 1, 0, 1]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#codeword_weight_distribution","title":"<code>codeword_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the codeword weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of codewords of Hamming weight $w$, for $w \\in [0 : n]$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.codeword_weight_distribution()\narray([1, 0, 0, 2, 1, 0])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#minimum_distance","title":"<code>minimum_distance()</code>  <code>cached</code>","text":"<p>Returns the minimum distance $d$ of the code. This is equal to the minimum Hamming weight of the non-zero codewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.minimum_distance()\n3\n</code></pre>"},{"location":"ref/SystematicBlockCode/#coset_leaders","title":"<code>coset_leaders()</code>  <code>cached</code>","text":"<p>Returns the coset leaders of the code. This is a $2^m \\times n$ matrix whose rows are all the coset leaders. The coset leader in row $i$ corresponds to the syndrome obtained by expressing $i$ in binary with $m$ bits (MSB in the right), and whose Hamming weight is minimal. This may be used as a LUT for syndrome-based decoding.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.coset_leaders()\narray([[0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0],\n       [0, 0, 0, 1, 0],\n       [0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 1],\n       [1, 1, 0, 0, 0],\n       [1, 0, 0, 0, 0],\n       [1, 0, 1, 0, 0]])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#coset_leader_weight_distribution","title":"<code>coset_leader_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the coset leader weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of coset leaders of weight $w$, for $w \\in [0 : n]$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.coset_leader_weight_distribution()\narray([1, 5, 2, 0, 0, 0])\n</code></pre>"},{"location":"ref/SystematicBlockCode/#packing_radius","title":"<code>packing_radius()</code>  <code>cached</code>","text":"<p>Returns the packing radius of the code. This is also called the error-correcting capability of the code, and is equal to $\\lfloor (d - 1) / 2 \\rfloor$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.packing_radius()\n1\n</code></pre>"},{"location":"ref/SystematicBlockCode/#covering_radius","title":"<code>covering_radius()</code>  <code>cached</code>","text":"<p>Returns the covering radius of the code. This is equal to the maximum Hamming weight of the coset leaders.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SystematicBlockCode(parity_submatrix=[[0, 1, 1], [1, 1, 0]])\n&gt;&gt;&gt; code.covering_radius()\n2\n</code></pre>"},{"location":"ref/TerminatedConvolutionalCode/","title":"komm.TerminatedConvolutionalCode","text":"<p>Terminated convolutional code. It is a linear block code obtained by terminating a $(n_0, k_0)$ convolutional code. A total of $h$ information blocks (each containing $k_0$ information bits) is encoded. The dimension of the resulting block code is thus $k = h k_0$; its length depends on the termination mode employed. There are three possible termination modes:</p> <ul> <li> <p>Direct truncation. The encoder always starts at state $0$, and its output ends immediately after the last information block. The encoder may not necessarily end in state $0$. The resulting block code will have length $n = h n_0$.</p> </li> <li> <p>Zero termination. The encoder always starts and ends at state $0$. To achieve this, a sequence of $k \\mu$ tail bits is appended to the information bits, where $\\mu$ is the memory order of the convolutional code. The resulting block code will have length $n = (h + \\mu) n_0$.</p> </li> <li> <p>Tail-biting. The encoder always starts and ends at the same state. To achieve this, the initial state of the encoder is chosen as a function of the information bits. The resulting block code will have length $n = h n_0$.</p> </li> </ul> <p>For more details, see LC04, Sec. 12.7 and WBR01.</p> <p>Parameters:</p> <ul> <li> <code>convolutional_code</code> (<code>ConvolutionalCode</code>)         \u2013          <p>The convolutional code to be terminated.</p> </li> <li> <code>num_blocks</code> (<code>int</code>)         \u2013          <p>The number $h$ of information blocks.</p> </li> <li> <code>mode</code> (<code>TerminationMode</code>)         \u2013          <p>The termination mode. It must be one of <code>'direct-truncation'</code> | <code>'zero-termination'</code> | <code>'tail-biting'</code>. The default value is <code>'zero-termination'</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.TerminatedConvolutionalCode(\n...     convolutional_code=komm.ConvolutionalCode([[0b1, 0b11]]),\n...     num_blocks=3,\n...     mode='direct-truncation',\n... )\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(6, 3, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 1, 0, 1, 0, 0],\n       [0, 0, 1, 1, 0, 1],\n       [0, 0, 0, 0, 1, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n2\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.TerminatedConvolutionalCode(\n...     convolutional_code=komm.ConvolutionalCode([[0b1, 0b11]]),\n...     num_blocks=3,\n...     mode='zero-termination',\n... )\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(8, 3, 5)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 1, 0, 1, 0, 0, 0, 0],\n       [0, 0, 1, 1, 0, 1, 0, 0],\n       [0, 0, 0, 0, 1, 1, 0, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n3\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.TerminatedConvolutionalCode(\n...     convolutional_code=komm.ConvolutionalCode([[0b1, 0b11]]),\n...     num_blocks=3,\n...     mode='tail-biting',\n... )\n&gt;&gt;&gt; (code.length, code.dimension, code.redundancy)\n(6, 3, 3)\n&gt;&gt;&gt; code.generator_matrix\narray([[1, 1, 0, 1, 0, 0],\n       [0, 0, 1, 1, 0, 1],\n       [0, 1, 0, 0, 1, 1]])\n&gt;&gt;&gt; code.minimum_distance()\n3\n</code></pre>"},{"location":"ref/TerminatedConvolutionalCode/#length","title":"<code>length</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The length $n$ of the code.</p>"},{"location":"ref/TerminatedConvolutionalCode/#dimension","title":"<code>dimension</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The dimension $k$ of the code.</p>"},{"location":"ref/TerminatedConvolutionalCode/#redundancy","title":"<code>redundancy</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The redundancy $m$ of the code.</p>"},{"location":"ref/TerminatedConvolutionalCode/#rate","title":"<code>rate</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The rate $R = k/n$ of the code.</p>"},{"location":"ref/TerminatedConvolutionalCode/#generator_matrix","title":"<code>generator_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The generator matrix $G \\in \\mathbb{B}^{k \\times n}$ of the code.</p>"},{"location":"ref/TerminatedConvolutionalCode/#check_matrix","title":"<code>check_matrix</code><code>  Array2D[integer] </code>  <code>cached</code> <code>property</code>","text":"<p>The check matrix $H \\in \\mathbb{B}^{m \\times n}$ of the code.</p>"},{"location":"ref/TerminatedConvolutionalCode/#encode","title":"<code>encode()</code>","text":"<p>Applies the encoding mapping $\\Enc : \\mathbb{B}^k \\to \\mathbb{B}^n$ of the code. This method takes one or more sequences of messages and returns their corresponding codeword sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $k$, or a multidimensional array where the last dimension is a multiple of $k$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension expanded from $bk$ to $bn$, where $b$ is a positive integer.</p> </li> </ul>"},{"location":"ref/TerminatedConvolutionalCode/#inverse_encode","title":"<code>inverse_encode()</code>","text":"<p>Applies the inverse encoding partial mapping $\\Enc^{-1} : \\mathbb{B}^n \\rightharpoonup \\mathbb{B}^k$ of the code. This method takes one or more sequences of codewords and returns their corresponding message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the input contains any invalid codewords.</p> </li> </ul>"},{"location":"ref/TerminatedConvolutionalCode/#check","title":"<code>check()</code>","text":"<p>Applies the check mapping $\\mathrm{Chk} : \\mathbb{B}^n \\to \\mathbb{B}^m$ of the code. This method takes one or more sequences of received words and returns their corresponding syndrome sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bm$, where $b$ is a positive integer.</p> </li> </ul>"},{"location":"ref/TerminatedConvolutionalCode/#codewords","title":"<code>codewords()</code>  <code>cached</code>","text":"<p>Returns the codewords of the code. This is a $2^k \\times n$ matrix whose rows are all the codewords. The codeword in row $i$ corresponds to the message obtained by expressing $i$ in binary with $k$ bits (MSB in the right).</p>"},{"location":"ref/TerminatedConvolutionalCode/#codeword_weight_distribution","title":"<code>codeword_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the codeword weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of codewords of Hamming weight $w$, for $w \\in [0 : n]$.</p>"},{"location":"ref/TerminatedConvolutionalCode/#minimum_distance","title":"<code>minimum_distance()</code>  <code>cached</code>","text":"<p>Returns the minimum distance $d$ of the code. This is equal to the minimum Hamming weight of the non-zero codewords.</p>"},{"location":"ref/TerminatedConvolutionalCode/#coset_leaders","title":"<code>coset_leaders()</code>  <code>cached</code>","text":"<p>Returns the coset leaders of the code. This is a $2^m \\times n$ matrix whose rows are all the coset leaders. The coset leader in row $i$ corresponds to the syndrome obtained by expressing $i$ in binary with $m$ bits (MSB in the right), and whose Hamming weight is minimal. This may be used as a LUT for syndrome-based decoding.</p>"},{"location":"ref/TerminatedConvolutionalCode/#coset_leader_weight_distribution","title":"<code>coset_leader_weight_distribution()</code>  <code>cached</code>","text":"<p>Returns the coset leader weight distribution of the code. This is an array of shape $(n + 1)$ in which element in position $w$ is equal to the number of coset leaders of weight $w$, for $w \\in [0 : n]$.</p>"},{"location":"ref/TerminatedConvolutionalCode/#packing_radius","title":"<code>packing_radius()</code>  <code>cached</code>","text":"<p>Returns the packing radius of the code. This is also called the error-correcting capability of the code, and is equal to $\\lfloor (d - 1) / 2 \\rfloor$.</p>"},{"location":"ref/TerminatedConvolutionalCode/#covering_radius","title":"<code>covering_radius()</code>  <code>cached</code>","text":"<p>Returns the covering radius of the code. This is equal to the maximum Hamming weight of the coset leaders.</p>"},{"location":"ref/TunstallCode/","title":"komm.TunstallCode","text":"<p>Binary Tunstall code. It is an optimal (minimal expected rate) variable-to-fixed length code for a given probability mass function. For more details, see Say06, Sec. 3.7.</p> Notes <p>Tunstall codes are always prefix-free (hence uniquely encodable) and fully covering.</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function of the source.</p> </li> <li> <code>target_block_size</code> (<code>int | None</code>)         \u2013          <p>The target block size $n$. Must satisfy $2^n \\geq S$, where $S$ is the cardinality of the source alphabet, given by <code>len(pmf)</code>. The default value is $n = \\lceil \\log_2 S \\rceil$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pmf = [0.7, 0.15, 0.15]\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.TunstallCode(pmf)\n&gt;&gt;&gt; code.dec_mapping\n{(0, 0): (0,),\n (0, 1): (1,),\n (1, 0): (2,)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(2.0)\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.TunstallCode(pmf, 3)\n&gt;&gt;&gt; code.dec_mapping\n{(0, 0, 0): (0, 0, 0),\n (0, 0, 1): (0, 0, 1),\n (0, 1, 0): (0, 0, 2),\n (0, 1, 1): (0, 1),\n (1, 0, 0): (0, 2),\n (1, 0, 1): (1,),\n (1, 1, 0): (2,)}\n&gt;&gt;&gt; code.rate(pmf)\nnp.float64(1.3698630137)\n</code></pre>"},{"location":"ref/UnaryCode/","title":"komm.UnaryCode","text":"<p>Unary code. It is an integer code. For the definition of this code, see Wikipedia: Unary coding.</p>"},{"location":"ref/UnaryCode/#encode","title":"<code>encode()</code>","text":"<p>Encode the input integer array.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input integer array. It must be a one-dimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of bits corresponding to the input integer array.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.UnaryCode()\n&gt;&gt;&gt; code.encode([4, 1, 3])\narray([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0])\n</code></pre>"},{"location":"ref/UnaryCode/#decode","title":"<code>decode()</code>","text":"<p>Decode the input bit array.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input bit array. It must be a one-dimensional array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of integers corresponding to the input bit array.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.UnaryCode()\n&gt;&gt;&gt; code.decode([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0])\narray([4, 1, 3])\n</code></pre>"},{"location":"ref/UniformQuantizer/","title":"komm.UniformQuantizer","text":"<p>Uniform scalar quantizer. It is a scalar quantizer in which the separation between levels is constant, $\\Delta$, and the thresholds are the mid-point between adjacent levels. For more details, see Say06, Sec. 9.4.</p> <p>Parameters:</p> <ul> <li> <code>num_levels</code> (<code>int</code>)         \u2013          <p>The number of quantization levels $L$. It must be greater than $1$.</p> </li> <li> <code>input_range</code> (<code>tuple[float, float]</code>)         \u2013          <p>The range $(x_\\mathrm{min}, x_\\mathrm{max})$ of the input signal. Default is $(-1.0, 1.0)$.</p> </li> <li> <code>choice</code> (<code>Literal['mid-riser', 'mid-tread']</code>)         \u2013          <p>The choice for the uniform quantizer. Must be either <code>'mid-riser'</code> or <code>'mid-tread'</code>. Default is <code>'mid-riser'</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(\n...     num_levels=4,\n...     input_range=(-1.0, 1.0),\n...     choice='mid-riser',\n... )\n&gt;&gt;&gt; quantizer.levels\narray([-0.75, -0.25,  0.25,  0.75])\n&gt;&gt;&gt; quantizer.thresholds\narray([-0.5,  0. ,  0.5])\n</code></pre> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(\n...     num_levels=4,\n...     input_range=(-1.0, 1.0),\n...     choice='mid-tread',\n... )\n&gt;&gt;&gt; quantizer.levels\narray([-1. , -0.5,  0. ,  0.5])\n&gt;&gt;&gt; quantizer.thresholds\narray([-0.75, -0.25,  0.25])\n</code></pre> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(\n...     num_levels=4,\n...     input_range=(0.0, 1.0),\n...     choice='mid-tread',\n... )\n&gt;&gt;&gt; quantizer.levels\narray([0.  , 0.25, 0.5 , 0.75])\n&gt;&gt;&gt; quantizer.thresholds\narray([0.125, 0.375, 0.625])\n</code></pre>"},{"location":"ref/UniformQuantizer/#quantization_step","title":"<code>quantization_step</code><code>  float </code>  <code>cached</code> <code>property</code>","text":"<p>The quantization step $\\Delta$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(num_levels=4, input_range=(-4, 4))\n&gt;&gt;&gt; quantizer.quantization_step\n2.0\n</code></pre>"},{"location":"ref/UniformQuantizer/#levels","title":"<code>levels</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The quantizer levels $v_0, v_1, \\ldots, v_{L-1}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(num_levels=4, input_range=(-4, 4))\n&gt;&gt;&gt; quantizer.levels\narray([-3., -1.,  1.,  3.])\n</code></pre>"},{"location":"ref/UniformQuantizer/#thresholds","title":"<code>thresholds</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The quantizer finite thresholds $t_1, t_2, \\ldots, t_{L-1}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(num_levels=4, input_range=(-4, 4))\n&gt;&gt;&gt; quantizer.thresholds\narray([-2.,  0.,  2.])\n</code></pre>"},{"location":"ref/UniformQuantizer/#mean_squared_error","title":"<code>mean_squared_error()</code>","text":"<p>Computes the mean squared (quantization) error (MSE) of the quantizer for a given input probability density function (pdf). It is defined as $$     \\mse = \\int_{-\\infty}^{\\infty} (x - y)^2 f_X(x) \\, dx $$ where $y$ is the quantized signal and $f_X(x)$ is the pdf of the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input_pdf</code> (<code>Callable[[NDArray[floating]], NDArray[floating]]</code>)         \u2013          <p>The probability density function $f_X(x)$ of the input signal.</p> </li> <li> <code>input_range</code> (<code>tuple[float, float]</code>)         \u2013          <p>The range $(x_\\mathrm{min}, x_\\mathrm{max})$ of the input signal.</p> </li> <li> <code>points_per_interval</code> (<code>int</code>)         \u2013          <p>The number of points per interval for numerical integration (default: 4096).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>mse</code>  (<code>float</code>)          \u2013          <p>The mean square quantization error.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(num_levels=4, input_range=(-4, 4))\n&gt;&gt;&gt; gaussian_pdf = lambda x: 1/np.sqrt(2*np.pi) * np.exp(-x**2/2)\n&gt;&gt;&gt; quantizer.mean_squared_error(\n...     input_pdf=gaussian_pdf,\n...     input_range=(-5, 5),\n... )\n0.3363025489037716\n&gt;&gt;&gt; uniform_pdf = lambda x: 1/8 * (np.abs(x) &lt;= 4)\n&gt;&gt;&gt; quantizer.mean_squared_error(\n...     input_pdf=uniform_pdf,\n...     input_range=(-4, 4),\n... )\n0.3333333730891729\n&gt;&gt;&gt; quantizer.quantization_step**2 / 12\n0.3333333333333333\n</code></pre>"},{"location":"ref/UniformQuantizer/#digitize","title":"<code>digitize()</code>","text":"<p>Returns the quantization indices for the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input signal $x$ to be digitized.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The integer indices of the quantization levels for each input sample.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(num_levels=4, input_range=(-4, 4))\n&gt;&gt;&gt; quantizer.digitize([-2.4,  0.8,  3.2])\narray([0, 2, 3])\n</code></pre>"},{"location":"ref/UniformQuantizer/#quantize","title":"<code>quantize()</code>","text":"<p>Quantizes the input signal.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input signal $x$ to be quantized.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The quantized signal $y$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quantizer = komm.UniformQuantizer(num_levels=4, input_range=(-4, 4))\n&gt;&gt;&gt; quantizer.quantize([-2.4,  0.8,  3.2])\narray([-3.,  1.,  3.])\n</code></pre>"},{"location":"ref/VariableToFixedCode/","title":"komm.VariableToFixedCode","text":"<p>General variable-to-fixed length code. A variable-to-fixed length code with target alphabet $\\mathcal{T}$, source alphabet $\\mathcal{S}$, and target block size $n$ is defined by a (possibly partial) decoding mapping $\\mathrm{Dec} : \\mathcal{T}^n \\rightharpoonup \\mathcal{S}^+$, where the domain is the set of all $n$-tuples with entries in $\\mathcal{T}$, and the co-domain is the set of all finite-length, non-empty tuples with entries in $\\mathcal{S}$. Here, we assume that $\\mathcal{T} = [0:T)$ and $\\mathcal{S} = [0:S)$, for integers $T \\geq 2$ and $S \\geq 2$. The elements in the image of $\\mathrm{Dec}$ are called sourcewords.</p>"},{"location":"ref/VariableToFixedCode/#from_dec_mapping","title":"<code>from_dec_mapping()</code>  <code>classmethod</code>","text":"<p>Constructs a variable-to-fixed length code from the decoding mapping $\\Dec$.</p> <p>Parameters:</p> <ul> <li> <code>dec_mapping</code> (<code>dict[Word, Word]</code>)         \u2013          <p>The decoding mapping $\\Dec$. Must be a dictionary of length at most $S^n$ whose keys are $n$-tuples of integers in $[0:T)$ and whose values are non-empty tuples of integers in $[0:S)$.</p> </li> </ul> Notes <p>The target block size $n$ is inferred from the domain of the decoding mapping, and the target and source cardinalities $T$ and $S$ are inferred from the maximum values in the domain and co-domain, respectively.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_dec_mapping({\n...     (0, 0): (0, 0, 0),\n...     (0, 1): (0, 0, 1),\n...     (1, 0): (0, 1),\n...     (1, 1): (1,),\n... })\n&gt;&gt;&gt; code.target_cardinality, code.source_cardinality, code.target_block_size\n(2, 2, 2)\n&gt;&gt;&gt; code.sourcewords\n[(0, 0, 0), (0, 0, 1), (0, 1), (1,)]\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_dec_mapping({\n...     (0, 0, 0): (1, ),\n...     (0, 0, 1): (2, ),\n...     (0, 1, 0): (0, 1),\n...     (0, 1, 1): (0, 2),\n...     (1, 0, 0): (0, 0, 0),\n...     (1, 0, 1): (0, 0, 1),\n...     (1, 1, 0): (0, 0, 2),\n... })  # Incomplete mapping\n&gt;&gt;&gt; code.target_cardinality, code.source_cardinality, code.target_block_size\n(2, 3, 3)\n&gt;&gt;&gt; code.sourcewords\n[(1,), (2,), (0, 1), (0, 2), (0, 0, 0), (0, 0, 1), (0, 0, 2)]\n</code></pre>"},{"location":"ref/VariableToFixedCode/#from_sourcewords","title":"<code>from_sourcewords()</code>  <code>classmethod</code>","text":"<p>Constructs a variable-to-fixed length code from the target cardinality $T$ and a list of sourcewords.</p> <p>Parameters:</p> <ul> <li> <code>target_cardinality</code> (<code>int</code>)         \u2013          <p>The target cardinality $T$. Must be an integer greater than or equal to $2$.</p> </li> <li> <code>sourcewords</code> (<code>list[Word]</code>)         \u2013          <p>The sourcewords of the code. Must be a list of length at most $T^n$ containing tuples of integers in $[0:S)$, where $S$ is the source cardinality of the code. The tuple in position $i$ must be equal to $\\mathrm{Dec}(v)$, where $v$ is the $i$-th element in the lexicographic ordering of $[0:T)^n$.</p> </li> </ul> Note <p>The target block size $n$ is inferred from the length of the sourcewords, and the source cardinality $S$ is inferred from the maximum value in the sourcewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(\n...     target_cardinality=2,\n...     sourcewords=[(0,0,0), (0,0,1), (0,1), (1,)],\n... )\n&gt;&gt;&gt; code.target_cardinality, code.source_cardinality, code.target_block_size\n(2, 2, 2)\n&gt;&gt;&gt; code.dec_mapping\n{(0, 0): (0, 0, 0),\n (0, 1): (0, 0, 1),\n (1, 0): (0, 1),\n (1, 1): (1,)}\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(\n...     target_cardinality=2,\n...     sourcewords=[(1,), (2,), (0,1), (0,2), (0,0,0), (0,0,1), (0,0,2)],\n... )\n&gt;&gt;&gt; code.target_cardinality, code.source_cardinality, code.target_block_size\n(2, 3, 3)\n&gt;&gt;&gt; code.dec_mapping\n{(0, 0, 0): (1,),\n (0, 0, 1): (2,),\n (0, 1, 0): (0, 1),\n (0, 1, 1): (0, 2),\n (1, 0, 0): (0, 0, 0),\n (1, 0, 1): (0, 0, 1),\n (1, 1, 0): (0, 0, 2)}\n</code></pre>"},{"location":"ref/VariableToFixedCode/#target_cardinality","title":"<code>target_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The target cardinality $T$ of the code. It is the number of symbols in the target alphabet.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.target_cardinality\n2\n</code></pre>"},{"location":"ref/VariableToFixedCode/#source_cardinality","title":"<code>source_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The source cardinality $S$ of the code. It is the number of symbols in the source alphabet.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.source_cardinality\n2\n</code></pre>"},{"location":"ref/VariableToFixedCode/#target_block_size","title":"<code>target_block_size</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The target block size $n$ of the code. It is the number of symbols in each target block.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.target_block_size\n2\n</code></pre>"},{"location":"ref/VariableToFixedCode/#size","title":"<code>size</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The number of sourcewords in the code. It is less than or equal to $T^n$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.size\n3\n</code></pre>"},{"location":"ref/VariableToFixedCode/#dec_mapping","title":"<code>dec_mapping</code><code>  dict[Word, Word] </code>  <code>cached</code> <code>property</code>","text":"<p>The decoding mapping $\\mathrm{Dec}$ of the code. It is a dictionary of length at most $T^n$ whose keys are $n$-tuples of integers in $[0:T)$ and whose values are the corresponding sourcewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.dec_mapping\n{(0, 0): (0,), (0, 1): (1,), (1, 0): (0, 1)}\n</code></pre>"},{"location":"ref/VariableToFixedCode/#sourcewords","title":"<code>sourcewords</code><code>  list[Word] </code>  <code>cached</code> <code>property</code>","text":"<p>The sourcewords of the code. They correspond to the image of the decoding mapping $\\mathrm{Dec}$.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_dec_mapping({\n...     (0, 0): (0,),\n...     (0, 1): (1,),\n...     (1, 0): (0, 1),\n... })\n&gt;&gt;&gt; code.sourcewords\n[(0,), (1,), (0, 1)]\n</code></pre>"},{"location":"ref/VariableToFixedCode/#is_fully_covering","title":"<code>is_fully_covering()</code>  <code>cached</code>","text":"<p>Returns whether the code is fully covering. A code is fully covering if every possible source sequence has a prefix that is a sourceword.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.is_fully_covering()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.is_fully_covering()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,0), (0,1)])\n&gt;&gt;&gt; code.is_fully_covering()  # (1,) is not covered\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (0,1)])\n&gt;&gt;&gt; code.is_fully_covering()  # (1,) is not covered\nFalse\n</code></pre>"},{"location":"ref/VariableToFixedCode/#is_uniquely_encodable","title":"<code>is_uniquely_encodable()</code>  <code>cached</code>","text":"<p>Returns whether the code is uniquely encodable. A code is uniquely encodable if there is a unique way to parse any concatenation of sourcewords.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.is_uniquely_encodable()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.is_uniquely_encodable()  # 01 can be parsed as 0|1 or 01\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,0), (0,1)])\n&gt;&gt;&gt; code.is_uniquely_encodable()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (0,1)])\n&gt;&gt;&gt; code.is_uniquely_encodable()\nTrue\n</code></pre>"},{"location":"ref/VariableToFixedCode/#is_prefix_free","title":"<code>is_prefix_free()</code>  <code>cached</code>","text":"<p>Returns whether the code is prefix-free. A code is prefix-free if no sourceword is a prefix of any other sourceword.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,0), (1,1)])\n&gt;&gt;&gt; code.is_prefix_free()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.is_prefix_free()\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,0), (0,1)])\n&gt;&gt;&gt; code.is_prefix_free()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (0,1)])\n&gt;&gt;&gt; code.is_prefix_free()\nFalse\n</code></pre>"},{"location":"ref/VariableToFixedCode/#rate","title":"<code>rate()</code>","text":"<p>Computes the expected rate $R$ of the code, considering a given pmf. This quantity is given by $$     R = \\frac{n}{\\bar{k}}, $$ where $n$ is the target block size, and $\\bar{k}$ is the expected sourceword length, assuming iid source symbols drawn from $p_X$. It is measured in $T$-ary digits per source symbol.</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The (first-order) probability mass function $p_X$ to be considered.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>rate</code>  (<code>float</code>)          \u2013          <p>The expected rate $R$ of the code.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.rate([2/3, 1/3])\nnp.float64(1.3846153846153846)\n</code></pre>"},{"location":"ref/VariableToFixedCode/#encode","title":"<code>encode()</code>","text":"<p>Encodes a sequence of source symbols using the code, which must be fully covering and uniquely encodable. When the input sequence ends with symbols that form only a partial match with any sourceword, the encoder will complete this last block using any valid sourceword that starts with these remaining symbols.</p> Warning <p>Encoding for non-prefix-free codes is not implemented yet.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be encoded. Must be a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The sequence of encoded symbols. It is a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code) with a length that is a multiple of the target block size $n$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_dec_mapping({\n...     (0, 0): (0, 0, 0),\n...     (0, 1): (0, 0, 1),\n...     (1, 0): (0, 1),\n...     (1, 1): (1,),\n... })\n</code></pre> <pre><code>&gt;&gt;&gt; code.encode([1, 0, 0, 0])  # Parsed as 1|000\narray([1, 1, 0, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; code.encode([1, 0, 0])  # Incomplete input, completed as 1|000\narray([1, 1, 0, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,0), (0,1)])\n&gt;&gt;&gt; code.encode([1, 0, 0, 0])  # Code is not fully covering\nTraceback (most recent call last):\n...\nValueError: code is not fully covering\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.encode([1, 0, 0, 0])  # Code is not uniquely encodable\nTraceback (most recent call last):\n...\nValueError: code is not uniquely encodable\n</code></pre>"},{"location":"ref/VariableToFixedCode/#decode","title":"<code>decode()</code>","text":"<p>Decodes a sequence of target symbols using the code, which must be fully covering and uniquely encodable.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The sequence of symbols to be decoded. Must be a 1D-array with elements in $[0:T)$ (where $T$ is the target cardinality of the code) and have a length that is a multiple of the target block size $n$. Also, the sequence must be a concatenation of target words (i.e., the output of the <code>encode</code> method).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[integer]</code>         \u2013          <p>The sequence of decoded symbols. It is a 1D-array with elements in $[0:S)$ (where $S$ is the source cardinality of the code).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_dec_mapping({\n...     (0, 0): (0,),\n...     (0, 1): (1,),\n...     (1, 0): (2,),\n... })\n&gt;&gt;&gt; code.decode([0, 0, 1, 0])\narray([0, 2])\n</code></pre> <pre><code>&gt;&gt;&gt; code.decode([1, 1, 0, 0, 1])  # Not a multiple of target block size\nTraceback (most recent call last):\n...\nValueError: length of input must be a multiple of block size 2 (got 5)\n</code></pre> <pre><code>&gt;&gt;&gt; code.decode([0, 0, 1, 1])  # 11 is not a valid target word\nTraceback (most recent call last):\n...\nValueError: input contains invalid word\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,0), (0,1)])\n&gt;&gt;&gt; code.decode([0, 0, 0, 1])  # Code is not fully covering\nTraceback (most recent call last):\n...\nValueError: code is not fully covering\n</code></pre> <pre><code>&gt;&gt;&gt; code = komm.VariableToFixedCode.from_sourcewords(2, [(0,), (1,), (0,1)])\n&gt;&gt;&gt; code.decode([0, 0, 0, 1])  # Code is not uniquely encodable\nTraceback (most recent call last):\n...\nValueError: code is not uniquely encodable\n</code></pre>"},{"location":"ref/ViterbiDecoder/","title":"komm.ViterbiDecoder","text":"<p>Viterbi decoder for terminated convolutional codes. For more details, see LC04, Sec. 12.1.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>TerminatedConvolutionalCode</code>)         \u2013          <p>The terminated convolutional code to be used for decoding.</p> </li> <li> <code>input_type</code> (<code>Literal['hard', 'soft']</code>)         \u2013          <p>The type of the input. Either <code>'hard'</code> or <code>'soft'</code>. Default is <code>'hard'</code>.</p> </li> </ul> Notes <ul> <li>Input type: <code>hard</code> (bits) or <code>soft</code> (either L-values or channel outputs).</li> <li>Output type: <code>hard</code> (bits).</li> </ul>"},{"location":"ref/ViterbiDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; convolutional_code = komm.ConvolutionalCode([[0b011, 0b101, 0b111]])\n&gt;&gt;&gt; code = komm.TerminatedConvolutionalCode(\n...     convolutional_code,\n...     num_blocks=5,\n...     mode=\"zero-termination\",\n... )\n&gt;&gt;&gt; decoder = komm.ViterbiDecoder(code, input_type=\"hard\")\n&gt;&gt;&gt; decoder([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1])\narray([1, 1, 0, 0, 1])\n</code></pre> <pre><code>&gt;&gt;&gt; convolutional_code = komm.ConvolutionalCode([[0b111, 0b101]])\n&gt;&gt;&gt; code = komm.TerminatedConvolutionalCode(\n...     convolutional_code,\n...     num_blocks=4,\n...     mode=\"direct-truncation\",\n... )\n&gt;&gt;&gt; decoder = komm.ViterbiDecoder(code, input_type=\"soft\")\n&gt;&gt;&gt; decoder([-0.7, -0.5, -0.8, -0.6, -1.1, +0.4, +0.9, +0.8])\narray([1, 0, 0, 0])\n</code></pre>"},{"location":"ref/ViterbiStreamDecoder/","title":"komm.ViterbiStreamDecoder","text":"<p>Convolutional stream decoder using Viterbi algorithm. Decode a (hard or soft) bit stream given a convolutional code, assuming a traceback length (path memory) of $\\tau$. At time $t$, the decoder chooses the path survivor with best metric at time $t - \\tau$ and outputs the corresponding information bits. The output stream has a delay equal to $k \\tau$, where $k$ is the number of input bits of the convolutional code. As a rule of thumb, the traceback length is chosen as $\\tau = 5\\mu$, where $\\mu$ is the memory order of the convolutional code.</p> <p>Parameters:</p> <ul> <li> <code>convolutional_code</code> (<code>ConvolutionalCode</code>)         \u2013          <p>The convolutional code.</p> </li> <li> <code>traceback_length</code> (<code>int</code>)         \u2013          <p>The traceback length (path memory) $\\tau$ of the decoder.</p> </li> <li> <code>state</code> (<code>int</code>)         \u2013          <p>The current state of the decoder. The default value is <code>0</code>.</p> </li> <li> <code>input_type</code> (<code>Literal['hard', 'soft']</code>)         \u2013          <p>The type of the input sequence, either <code>hard</code> or <code>soft</code>. The default value is <code>hard</code>.</p> </li> </ul>"},{"location":"ref/ViterbiStreamDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The (hard or soft) bit sequence to be decoded.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The decoded bit sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; convolutional_code = komm.ConvolutionalCode([[0o7, 0o5]])\n&gt;&gt;&gt; decoder = komm.ViterbiStreamDecoder(convolutional_code, traceback_length=10)\n&gt;&gt;&gt; decoder([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1])\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n&gt;&gt;&gt; decoder(np.zeros(2*10, dtype=int))\narray([1, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n</code></pre>"},{"location":"ref/WagnerDecoder/","title":"komm.WagnerDecoder","text":"<p>Wagner decoder for single parity-check codes. For more details, see CF07, Sec. III.C.</p> <p>Parameters:</p> <ul> <li> <code>code</code> (<code>SingleParityCheckCode</code>)         \u2013          <p>The single parity-check code to be used for decoding.</p> </li> </ul> Notes <ul> <li>Input type: <code>soft</code> (L-values or channel outputs).</li> <li>Output type: <code>hard</code> (bits).</li> </ul>"},{"location":"ref/WagnerDecoder/#__call__","title":"<code>__call__()</code>","text":"<p>Decode received words. This method takes one or more sequences of received words and returns their corresponding estimated message sequences.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence(s). Can be either a single sequence whose length is a multiple of $n$, or a multidimensional array where the last dimension is a multiple of $n$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer | floating]</code>)          \u2013          <p>The output sequence(s). Has the same shape as the input, with the last dimension contracted from $bn$ to $bk$, where $b$ is a positive integer.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = komm.SingleParityCheckCode(4)\n&gt;&gt;&gt; decoder = komm.WagnerDecoder(code)\n&gt;&gt;&gt; decoder([[1.52, -0.36, 1.56, 0.82], [-0.75,  1.20 , -2.11,  1.73]])\narray([[0, 0, 0],\n       [1, 0, 1]])\n</code></pre>"},{"location":"ref/WalshHadamardSequence/","title":"komm.WalshHadamardSequence","text":"<p>Walsh\u2013Hadamard sequence. Consider the following recursive matrix construction: $$     H_1 =     \\begin{bmatrix}         +1     \\end{bmatrix}, \\qquad     H_{2^n} =     \\begin{bmatrix}         H_{2^{n-1}} &amp; H_{2^{n-1}} \\\\         H_{2^{n-1}} &amp; -H_{2^{n-1}}     \\end{bmatrix}, $$ for $n = 1, 2, \\ldots$. For example, for $n = 3$, $$     H_8 =     \\begin{bmatrix}         +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 \\\\         +1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 &amp; -1 \\\\         +1 &amp; +1 &amp; -1 &amp; -1 &amp; +1 &amp; +1 &amp; -1 &amp; -1 \\\\         +1 &amp; -1 &amp; -1 &amp; +1 &amp; +1 &amp; -1 &amp; -1 &amp; +1 \\\\         +1 &amp; +1 &amp; +1 &amp; +1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 \\\\         +1 &amp; -1 &amp; +1 &amp; -1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 \\\\         +1 &amp; +1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; +1 &amp; +1 \\\\         +1 &amp; -1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 &amp; +1 &amp; -1 \\\\     \\end{bmatrix} $$ The above matrix is said to be in natural ordering. If the rows of the matrix are rearranged by first applying the bit-reversal permutation and then the Gray-code permutation, the following matrix is obtained: $$     H_8^{\\mathrm{s}} =     \\begin{bmatrix}         +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 &amp; +1 \\\\         +1 &amp; +1 &amp; +1 &amp; +1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 \\\\         +1 &amp; +1 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp; +1 &amp; +1 \\\\         +1 &amp; +1 &amp; -1 &amp; -1 &amp; +1 &amp; +1 &amp; -1 &amp; -1 \\\\         +1 &amp; -1 &amp; -1 &amp; +1 &amp; +1 &amp; -1 &amp; -1 &amp; +1 \\\\         +1 &amp; -1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 &amp; +1 &amp; -1 \\\\         +1 &amp; -1 &amp; +1 &amp; -1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 \\\\         +1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 &amp; -1 &amp; +1 &amp; -1 \\\\     \\end{bmatrix} $$ The above matrix is said to be in sequency ordering. It has the property that row $i$ has exactly $i$ sign changes.</p> <p>The Walsh\u2013Hadamard sequence of length $L$ and index $i \\in [0 : L)$ is a binary sequence whose polar format is the $i$-th row of $H_L$, if assuming natural ordering, or $H_L^{\\mathrm{s}}$, if assuming sequency ordering. Fore more details, see Wikipedia: Hadamard matrix and Wikipedia: Walsh matrix.</p> <p>Parameters:</p> <ul> <li> <code>length</code> (<code>int</code>)         \u2013          <p>Length $L$ of the Walsh\u2013Hadamard sequence. Must be a power of two.</p> </li> <li> <code>ordering</code> (<code>Literal['natural', 'sequency', 'dyadic']</code>)         \u2013          <p>Ordering to be assumed. Should be one of <code>'natural'</code>, <code>'sequency'</code>, or <code>'dyadic'</code>. The default value is <code>'natural'</code>.</p> </li> <li> <code>index</code> (<code>int</code>)         \u2013          <p>Index of the Walsh\u2013Hadamard sequence, with respect to the ordering assumed. Must be in the set $[0 : L)$. The default value is <code>0</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; walsh_hadamard = komm.WalshHadamardSequence(length=8, ordering='natural', index=5)\n&gt;&gt;&gt; walsh_hadamard.polar_sequence\narray([ 1, -1,  1, -1, -1,  1, -1,  1])\n</code></pre> <pre><code>&gt;&gt;&gt; walsh_hadamard = komm.WalshHadamardSequence(length=8, ordering='sequency', index=5)\n&gt;&gt;&gt; walsh_hadamard.polar_sequence\narray([ 1, -1, -1,  1, -1,  1,  1, -1])\n</code></pre> <pre><code>&gt;&gt;&gt; walsh_hadamard = komm.WalshHadamardSequence(length=8, ordering='dyadic', index=5)\nTraceback (most recent call last):\n...\nNotImplementedError\n</code></pre>"},{"location":"ref/ZChannel/","title":"komm.ZChannel","text":"<p>Z-channel. It is a discrete memoryless channel with input and output alphabets $\\mathcal{X} = \\mathcal{Y} = \\{ 0, 1 \\}$. The channel is characterized by a parameter $p$, called the decay probability. Bit $0$ is always received correctly, but bit $1$ turns into $0$ with probability $p$. Equivalently, the channel can be modeled as $$     Y_n = A_n X_n, $$ where $A_n$ are iid Bernoulli random variables with $\\Pr[A_n = 0] = p$.</p> <p>Parameters:</p> <ul> <li> <code>decay_probability</code> (<code>float</code>)         \u2013          <p>The channel decay probability $p$. Must satisfy $0 \\leq p \\leq 1$. The default value is <code>0.0</code>, which corresponds to a noiseless channel.</p> </li> </ul>"},{"location":"ref/ZChannel/#input_cardinality","title":"<code>input_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel input cardinality $|\\mathcal{X}|$.</p> <p>For the Z-channel, it is given by $|\\mathcal{X}| = 2$.</p>"},{"location":"ref/ZChannel/#output_cardinality","title":"<code>output_cardinality</code><code>  int </code>  <code>cached</code> <code>property</code>","text":"<p>The channel output cardinality $|\\mathcal{Y}|$.</p> <p>For the Z-channel, it is given by $|\\mathcal{Y}| = 2$.</p>"},{"location":"ref/ZChannel/#transition_matrix","title":"<code>transition_matrix</code><code>  NDArray[floating] </code>  <code>cached</code> <code>property</code>","text":"<p>The channel transition probability matrix $p_{Y \\mid X}$.</p> <p>For the Z-channel, it is given by $$     p_{Y \\mid X} = \\begin{bmatrix} 1 &amp; 0 \\\\ p &amp; 1-p \\end{bmatrix}. $$</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zc = komm.ZChannel(0.2)\n&gt;&gt;&gt; zc.transition_matrix\narray([[1. , 0. ],\n       [0.2, 0.8]])\n</code></pre>"},{"location":"ref/ZChannel/#mutual_information","title":"<code>mutual_information()</code>","text":"<p>Returns the mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$ of the channel.</p> <p>Parameters:</p> <ul> <li> <code>input_pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function $p_X$ of the channel input $X$. It must be a valid pmf, that is, all of its values must be non-negative and sum up to $1$.</p> </li> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The mutual information $\\mathrm{I}(X ; Y)$ between the input $X$ and the output $Y$.</p> </li> </ul> <p>For the Z-channel, it is given by $$     \\mathrm{I}(X ; Y) = \\Hb ( \\pi (1-p) ) - \\pi \\Hb(p), $$ in bits, where $\\pi = \\Pr[X = 1]$, and $\\Hb$ is the binary entropy function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zc = komm.ZChannel(0.2)\n&gt;&gt;&gt; zc.mutual_information([0.5, 0.5])\nnp.float64(0.6099865470109874)\n</code></pre>"},{"location":"ref/ZChannel/#capacity","title":"<code>capacity()</code>","text":"<p>Returns the channel capacity $C$.</p> <p>Parameters:</p> <ul> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The channel capacity $C$.</p> </li> </ul> <p>For the Z-channel, it is given by $$     C = \\log_2 ( 1 + (1-p) p^{p / (1-p)} ), $$ in bits.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zc = komm.ZChannel(0.2)\n&gt;&gt;&gt; zc.capacity()\nnp.float64(0.6182313659549211)\n</code></pre>"},{"location":"ref/ZChannel/#__call__","title":"<code>__call__()</code>","text":"<p>Transmits the input sequence through the channel and returns the output sequence.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input sequence.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[integer]</code>)          \u2013          <p>The output sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zc = komm.ZChannel(0.2)\n&gt;&gt;&gt; zc([1, 1, 1, 0, 0, 0, 1, 0, 1, 0])\narray([1, 1, 1, 0, 0, 0, 1, 0, 0, 0])\n</code></pre>"},{"location":"ref/ZadoffChuSequence/","title":"komm.ZadoffChuSequence","text":"<p>Zadoff\u2013Chu sequence. It is a periodic, complex sequence given by $$     z_{L,q}[n] = \\mathrm{e}^{-\\mathrm{j} \\pi q n (n + 1) / L}, $$ where $L$ is the length (and period) of the sequence (which must be an odd integer) and $q \\in [1:L)$ is called the root index of the sequence.</p> <p>Zadoff\u2013Chu sequences have the following properties:</p> <ol> <li> <p>Constant amplitude: The magnitude of the sequence satisfies $$     |z_{L,q}[n]| = 1, \\quad \\forall n. $$</p> </li> <li> <p>Zero autocorrelation: If $q$ is coprime to $L$, then the cyclic autocorrelation of $z_{L,q}$ satisfies $$     \\tilde{R}_{z_{L,q}}[\\ell] = 0, \\quad \\forall \\ell \\neq 0 \\mod L. $$</p> </li> <li> <p>Constant cross-correlation: If $|q' - q|$ is coprime to $L$, then the magnitude of the cyclic cross-correlation of $z_{L,q}$ and $z_{L,q'}$ satisfies $$     |\\tilde{R}_{z_{L,q}, z_{L,q'}}[\\ell]| = \\sqrt{L}, \\quad \\forall \\ell. $$</p> </li> </ol> <p>For more details, see And22.</p> Notes <ul> <li>Theses sequences are also called Frank\u2013Zadoff\u2013Chu sequences.</li> </ul> <p>Parameters:</p> <ul> <li> <code>length</code> (<code>int</code>)         \u2013          <p>The length $L$ of the Zadoff\u2013Chu sequence. Must be an odd integer.</p> </li> <li> <code>root_index</code> (<code>int</code>)         \u2013          <p>The root index $q$ of the Zadoff\u2013Chu sequence. Must be in $[1:L)$. The default value is $1$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zadoff_chu = ZadoffChuSequence(5, root_index=1)\n&gt;&gt;&gt; zadoff_chu.sequence.round(6)\narray([ 1.      +0.j      ,  0.309017-0.951057j, -0.809017+0.587785j,  0.309017-0.951057j,  1.      +0.j      ])\n&gt;&gt;&gt; zadoff_chu.cyclic_autocorrelation(normalized=True).round(6)\narray([ 1.+0.j, -0.-0.j, -0.-0.j,  0.+0.j, -0.+0.j])\n</code></pre>"},{"location":"ref/autocorrelation/","title":"komm.autocorrelation","text":"<p>Computes the autocorrelation $R[\\ell]$ of a real or complex sequence $x[n]$. This is defined as $$     R[\\ell] = \\sum_{n \\in \\mathbb{Z}} x[n] x^*_\\ell[n], $$ where $x^*_\\ell[n] = x^*[n - \\ell]$ is the complex conjugate of $x[n]$ shifted by $\\ell$ positions. The autocorrelation $R[\\ell]$ is even symmetric and satisfies $R[\\ell] = 0$ for $|\\ell| \\geq L$, where $L$ is the length of the sequence.</p> <p>Parameters:</p> <ul> <li> <code>seq</code> (<code>ArrayLike</code>)         \u2013          <p>A 1D-array containing the sequence $x[n]$, of length $L$.</p> </li> <li> <code>shifts</code> (<code>ArrayLike | None</code>)         \u2013          <p>A 1D-array containing the values of $\\ell$ for which the autocorrelation will be computed. The default value is <code>range(len(seq))</code>, that is, $[0 : L)$.</p> </li> <li> <code>normalized</code> (<code>bool</code>)         \u2013          <p>If <code>True</code>, returns the autocorrelation divided by the sequence energy, so that $R[0] = 1$. The default value is <code>False</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[DType]</code>         \u2013          <p>The autocorrelation $R[\\ell]$ of the sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.autocorrelation([1.0, 2.0, 3.0, 4.0], shifts=[-2, -1, 0, 1, 2])\narray([11., 20., 30., 20., 11.])\n</code></pre>"},{"location":"ref/binary_entropy/","title":"komm.binary_entropy","text":"<p>Computes the binary entropy function. For a given probability $p$, it is defined as $$     \\Hb(p) = p \\log_2 \\frac{1}{p} + (1 - p) \\log_2 \\frac{1}{1 - p}, $$ and corresponds to the entropy of a Bernoulli random variable with parameter $p$.</p> <p>Parameters:</p> <ul> <li> <code>p</code> (<code>float</code>)         \u2013          <p>A probability value. It must satisfy $0 \\leq p \\leq 1$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The value of the binary entropy function $\\Hb(p)$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; [komm.binary_entropy(p) for p in [0.0, 0.25, 0.5, 0.75, 1.0]]\n[0.0, 0.8112781244591328, 1.0, 0.8112781244591328, 0.0]\n</code></pre>"},{"location":"ref/binary_entropy_inv/","title":"komm.binary_entropy_inv","text":"<p>Computes the inverse of the binary entropy function. More precisely, it computes the value of $p \\in [0, 1/2]$ such that $\\Hb(p) = h$.</p> <p>Parameters:</p> <ul> <li> <code>h</code> (<code>float</code>)         \u2013          <p>A value in the interval $[0, 1]$.</p> </li> <li> <code>tol</code> (<code>float</code>)         \u2013          <p>The tolerance for the binary search. The default value is <code>1e-12</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The value of $p \\in [0, 1/2]$ such that $\\Hb(p) = h$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; [komm.binary_entropy_inv(h) for h in [0.0, 0.25, 0.5, 0.75, 1.0]]\n[0.0, 0.04169269027397604, 0.1100278644385071, 0.2145017448597173, 0.5]\n</code></pre>"},{"location":"ref/bits_to_int/","title":"komm.bits_to_int","text":"<p>Converts a bit array to its integer representation (LSB first).</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>An $N$-dimensional array of $0$s and $1$s. The least significant bit (LSB) is the first element in the last dimension.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int | NDArray[integer]</code>         \u2013          <p>An integer or an $(N-1)$-dimensional array of integers. The last dimension of the input is collapsed into an integer representation while all preceding dimensions are preserved.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.bits_to_int([0, 0, 0, 0, 1])\n16\n</code></pre> <pre><code>&gt;&gt;&gt; komm.bits_to_int([0, 1, 0, 1, 1])\n26\n</code></pre> <pre><code>&gt;&gt;&gt; komm.bits_to_int([0, 1, 0, 1, 1, 0, 0, 0])\n26\n</code></pre> <pre><code>&gt;&gt;&gt; komm.bits_to_int([[0, 0], [1, 0], [0, 1], [1, 1]])  # Each row is independently converted to an integer\narray([0, 1, 2, 3])\n</code></pre>"},{"location":"ref/boxplus/","title":"komm.boxplus","text":"<p>Computes the box-plus operation. It is defined by $$     a \\boxplus b = 2 \\operatorname{atanh} \\left( \\tanh\\left(\\frac{a}{2}\\right) \\tanh\\left(\\frac{b}{2}\\right) \\right). $$ If $X, Y$ are independent binary random variables, then $L(X \\oplus Y) = L(X) \\boxplus L(Y)$, where $L$ denotes the L-value and $\\oplus$ denotes the modulo-$2$ sum.</p> <p>Parameters:</p> <ul> <li> <code>a</code> (<code>ArrayLike</code>)         \u2013          <p>A float or array of floats containing L-values.</p> </li> <li> <code>b</code> (<code>ArrayLike</code>)         \u2013          <p>A float or array of floats containing L-values.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[floating]</code>         \u2013          <p>The result of the boxplus operation. It has the same shape as the inputs.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.boxplus(1, 2)\nnp.float64(0.735325664055519)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.boxplus([0, 1, 2], [1, -1, -1])\narray([ 0.        , -0.43378083, -0.73532566])\n</code></pre>"},{"location":"ref/cyclic_autocorrelation/","title":"komm.cyclic_autocorrelation","text":"<p>Computes the cyclic autocorrelation $\\tilde{R}[\\ell]$ of a real or complex sequence $x[n]$. This is defined as $$     \\tilde{R}[\\ell] = \\sum_{n \\in [0:L)} x[n] \\tilde{x}^*_\\ell[n], $$ where $\\tilde{x}^*_\\ell[n]$ is the complex conjugate of $x[n]$ cyclic-shifted by $\\ell$ positions, and $L$ is the period of the sequence. The cyclic autocorrelation $\\tilde{R}[\\ell]$ is even symmetric and periodic with period $L$.</p> <p>Parameters:</p> <ul> <li> <code>seq</code> (<code>ArrayLike</code>)         \u2013          <p>A 1D-array containing the sequence $x[n]$, of length $L$.</p> </li> <li> <code>shifts</code> (<code>ArrayLike | None</code>)         \u2013          <p>A 1D-array containing the values of $\\ell$ for which the cyclic autocorrelation will be computed. The default value is <code>range(len(seq))</code>, that is, $[0 : L)$.</p> </li> <li> <code>normalized</code> (<code>bool</code>)         \u2013          <p>If <code>True</code>, returns the cyclic autocorrelation divided by the sequence energy, so that $R[0] = 1$. The default value is <code>False</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[DType]</code>         \u2013          <p>The cyclic autocorrelation $\\tilde{R}[\\ell]$ of the sequence.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.cyclic_autocorrelation([1.0, 2.0, 3.0, 4.0], shifts=[-2, -1, 0, 1, 2])\narray([22., 24., 30., 24., 22.])\n</code></pre>"},{"location":"ref/entropy/","title":"komm.entropy","text":"<p>Computes the entropy of a random variable with a given pmf. Let $X$ be a random variable with pmf $p_X$ and alphabet $\\mathcal{X}$. Its entropy is given by $$     \\mathrm{H}(X) = \\sum_{x \\in \\mathcal{X}} p_X(x) \\log \\frac{1}{p_X(x)}. $$ By default, the base of the logarithm is $2$, in which case the entropy is measured in bits. For more details, see CT06, Sec. 2.1.</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function $p_X$ of the random variable. It must be a valid pmf, that is, all of its values must be non-negative and sum up to $1$.</p> </li> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The entropy $\\mathrm{H}(X)$ of the random variable.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.entropy([1/4, 1/4, 1/4, 1/4])\nnp.float64(2.0)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.entropy(pmf=[1/3, 1/3, 1/3], base=3.0)\nnp.float64(1.0)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.entropy([0.5, 0.5], base='e')\nnp.float64(0.6931471805599453)\n</code></pre>"},{"location":"ref/fourier_transform/","title":"komm.fourier_transform","text":"<p>Computes the Fourier transform. This function applies a shift to the spectrum (so that the zero frequency component is at the center) and scales the output by a given time step. Both the spectrum and the corresponding frequency bins are returned.</p> Note <p>This is a simple wrapper around <code>numpy.fft</code> functions.</p> <p>Parameters:</p> <ul> <li> <code>waveform</code> (<code>ArrayLike</code>)         \u2013          <p>The input array representing the waveform to be transformed.</p> </li> <li> <code>time_step</code> (<code>float</code>)         \u2013          <p>The time step between samples in the waveform.</p> </li> <li> <code>nfft</code> (<code>int | None</code>)         \u2013          <p>The number of points in the FFT. If <code>None</code>, it defaults to the size of the input along the specified axis.</p> </li> <li> <code>axis</code> (<code>int</code>)         \u2013          <p>The axis along which to compute the Fourier transform. Default is the last axis.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>spectrum</code>  (<code>NDArray[complexfloating]</code>)          \u2013          <p>The spectrum correponding to the input waveform.</p> </li> <li> <code>frequencies</code>  (<code>NDArray[floating]</code>)          \u2013          <p>The corresponding frequency bins.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; spectrum, frequencies = komm.fourier_transform([1, 2, 3, 4], time_step=0.1)\n&gt;&gt;&gt; spectrum\narray([-0.2+0.j , -0.2-0.2j,  1. +0.j , -0.2+0.2j])\n&gt;&gt;&gt; frequencies\narray([-5. , -2.5,  0. ,  2.5])\n</code></pre>"},{"location":"ref/gaussian_q/","title":"komm.gaussian_q","text":"<p>Computes the Gaussian Q-function. It is given by $$     \\mathrm{Q}(x) = \\frac{1}{\\sqrt{2\\pi}} \\int_x^\\infty \\mathrm{e}^{-u^2/2} \\, \\mathrm{d}u. $$ This corresponds to the complementary cumulative distribution function of the standard gaussian distribution. For more details, see Wikipedia: Q-function.</p> <p>Parameters:</p> <ul> <li> <code>x</code> (<code>ArrayLike</code>)         \u2013          <p>The input to the function. Should be a float or array of floats.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>y</code>  (<code>NDArray[floating] | floating</code>)          \u2013          <p>The value $y = \\mathrm{Q}(x)$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.gaussian_q(0.0)\nnp.float64(0.5)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.gaussian_q([[-1.0], [0.0], [1.0]])\narray([[0.84134475],\n       [0.5       ],\n       [0.15865525]])\n</code></pre>"},{"location":"ref/gaussian_q_inv/","title":"komm.gaussian_q_inv","text":"<p>Computes the inverse Gaussian Q-function.</p> <p>Parameters:</p> <ul> <li> <code>y</code> (<code>ArrayLike</code>)         \u2013          <p>The input to the function. Should be a float or array of floats in the real interval $[0, 1]$.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x</code>  (<code>NDArray[floating] | floating</code>)          \u2013          <p>The value $x = \\mathrm{Q^{-1}}(y)$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.gaussian_q_inv(0.5)\nnp.float64(0.0)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.gaussian_q_inv([[0.841344746], [0.5], [0.158655254]])\narray([[-1.],\n       [ 0.],\n       [ 1.]])\n</code></pre>"},{"location":"ref/int_to_bits/","title":"komm.int_to_bits","text":"<p>Converts an integer, or array of integers, to their bit representations (LSB first).</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>An integer or an $N$-dimensional array of integers.</p> </li> <li> <code>width</code> (<code>int</code>)         \u2013          <p>The width of the bit representation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray[integer]</code>         \u2013          <p>An $(N+1)$-dimensional array of $0$s and $1$s, where the last dimension contains the bit representation of the input, with the least significant bit (LSB) as the first element.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.int_to_bits(16, width=5)\narray([0, 0, 0, 0, 1])\n</code></pre> <pre><code>&gt;&gt;&gt; komm.int_to_bits(26, width=5)\narray([0, 1, 0, 1, 1])\n</code></pre> <pre><code>&gt;&gt;&gt; komm.int_to_bits(26, width=8)\narray([0, 1, 0, 1, 1, 0, 0, 0])\n</code></pre> <pre><code>&gt;&gt;&gt; komm.int_to_bits([0, 1, 2, 3], width=2)\narray([[0, 0],\n       [1, 0],\n       [0, 1],\n       [1, 1]])\n</code></pre> <pre><code>&gt;&gt;&gt; komm.int_to_bits([0, 1, 2, 3], width=4)\narray([[0, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [1, 1, 0, 0]])\n</code></pre> <pre><code>&gt;&gt;&gt; komm.int_to_bits([[0, 1], [2, 3]], width=2)\narray([[[0, 0],\n        [1, 0]],\n\n       [[0, 1],\n        [1, 1]]])\n</code></pre>"},{"location":"ref/marcum_q/","title":"komm.marcum_q","text":"<p>Computes the Marcum Q-function. It is given by $$     \\mathrm{Q}_m(a; x) = \\int_x^\\infty u \\left( \\frac{u}{a} \\right)^{m-1}  I_{m-1}(a x) \\exp \\left( -\\frac{u^2 + a^2}{2} \\right) \\mathrm{d}u, $$ where $I_{m-1}$ is the modified Bessel function of the first kind. This corresponds to the complementary cumulative distribution function of the non-central chi distribution with $2m$ degrees of freedom and non-centrality parameter $a$. For more details, see Wikipedia: Marcum Q-function.</p> <p>Parameters:</p> <ul> <li> <code>m</code> (<code>int</code>)         \u2013          <p>The order of the Marcum Q-function. Should be a positive integer.</p> </li> <li> <code>a</code> (<code>ArrayLike</code>)         \u2013          <p>The value of $a$. Should be a float or array of floats.</p> </li> <li> <code>x</code> (<code>ArrayLike</code>)         \u2013          <p>The input to the function. Should be a float or array of floats.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>y</code>  (<code>NDArray[floating] | floating</code>)          \u2013          <p>The value $y = \\mathrm{Q}_m(a; x)$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.marcum_q(1, 1, 1)\nnp.float64(0.7328798037968204)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.marcum_q(2, 0.5, [1.2, 1.4, 1.6])\narray([0.85225816, 0.76472056, 0.66139663])\n</code></pre>"},{"location":"ref/relative_entropy/","title":"komm.relative_entropy","text":"<p>Computes the relative entropy (Kullback\u2013Leibler divergence) between two pmfs. Let $p$ and $q$ be two pmfs over the same alphabet $\\mathcal{X}$. The relative entropy of $p$ with respect to $q$ is defined as $$     \\mathrm{D}(p \\parallel q) = \\sum_{x \\in \\mathcal{X}} p(x) \\log \\frac{p(x)}{q(x)}. $$ Note that, in general, $\\mathrm{D}(p \\parallel q) \\neq \\mathrm{D}(q \\parallel p)$. For more details, see CT06, Sec. 2.3.</p> <p>Parameters:</p> <ul> <li> <code>pmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function $p$. It must be a valid pmf, that is, all of its values must be non-negative and sum up to $1$.</p> </li> <li> <code>qmf</code> (<code>ArrayLike</code>)         \u2013          <p>The probability mass function $q$. It must be a valid pmf, that is, all of its values must be non-negative and sum up to $1$.</p> </li> <li> <code>base</code> (<code>LogBase</code>)         \u2013          <p>The base of the logarithm to be used. It must be a positive float or the string <code>'e'</code>. The default value is <code>2.0</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>The relative entropy $\\mathrm{D}(p \\parallel q)$ between the two pmfs.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.relative_entropy([1/2, 1/2], [1/2, 1/2])\nnp.float64(0.0)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.relative_entropy([1/2, 1/2], [3/4, 1/4])\nnp.float64(0.20751874963942185)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.relative_entropy([3/4, 1/4], [1/2, 1/2])\nnp.float64(0.18872187554086717)\n</code></pre> <pre><code>&gt;&gt;&gt; komm.relative_entropy([1/2, 1/2], [0, 1])\nnp.float64(inf)\n</code></pre>"},{"location":"ref/sampling_rate_compress/","title":"komm.sampling_rate_compress","text":"<p>Performs sampling rate compression (downsampling). For a given input $x[n]$, the output is $$ y[n] = x[n M + \\Delta], $$ where $M$ is the compression factor and $\\Delta \\in [0:M)$ is the offset for the first selected element. In words, the compressor extracts every $M$-th element starting from the offset $\\Delta$ along the specified axis. For more details, see OS99, Sec. 4.6.1.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input array $x[n]$ to be compressed.</p> </li> <li> <code>factor</code> (<code>int</code>)         \u2013          <p>The compression factor $M$.</p> </li> <li> <code>offset</code> (<code>int</code>)         \u2013          <p>The offset $\\Delta$. Must satisfy $\\Delta \\in [0:M)$.</p> </li> <li> <code>axis</code> (<code>int</code>)         \u2013          <p>The axis along which to extract elements. Default is the last axis.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[Any]</code>)          \u2013          <p>The compressed array $y[n]$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.sampling_rate_compress(\n...    [[11, 12, 13, 14, 15],\n...     [16, 17, 18, 19, 20]],\n...    factor=3,\n... )\narray([[11, 14],\n       [16, 19]])\n&gt;&gt;&gt; komm.sampling_rate_compress(\n...    [[11, 12, 13, 14, 15],\n...     [16, 17, 18, 19, 20]],\n...    factor=3,\n...    offset=1,\n... )\narray([[12, 15],\n       [17, 20]])\n&gt;&gt;&gt; komm.sampling_rate_compress(\n...     [[11, 12],\n...      [13, 14],\n...      [15, 16],\n...      [17, 18],\n...      [19, 20]],\n...     factor=3,\n...     axis=0,\n... )\narray([[11, 12],\n       [17, 18]])\n</code></pre>"},{"location":"ref/sampling_rate_expand/","title":"komm.sampling_rate_expand","text":"<p>Performs sampling rate expansion (upsampling). For a given input $x[n]$, the output is $$ y[n] = \\begin{cases} x[n \\operatorname{div} L] &amp; \\text{if } n \\bmod L = \\Delta, \\\\ 0,       &amp; \\text{otherwise} \\end{cases} $$ where $L$ is the expansion factor and $\\Delta \\in [0:L)$ is the offset for the first output element. In words, the expander inserts $L-1$ zeros between each element of the input array along the specified axis, starting from the offset $\\Delta$. For more details, see OS99, Sec. 4.6.2.</p> <p>Parameters:</p> <ul> <li> <code>input</code> (<code>ArrayLike</code>)         \u2013          <p>The input array $x[n]$ to be expanded.</p> </li> <li> <code>factor</code> (<code>int</code>)         \u2013          <p>The expansion factor $L$.</p> </li> <li> <code>offset</code> (<code>int</code>)         \u2013          <p>The offset $\\Delta$. Must satisfy $\\Delta \\in [0:L)$.</p> </li> <li> <code>axis</code> (<code>int</code>)         \u2013          <p>The axis along which to insert zeros. Default is the last axis.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>output</code>  (<code>NDArray[Any]</code>)          \u2013          <p>The expanded array $y[n]$.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; komm.sampling_rate_expand([[1, 2], [3, 4]], factor=3)\narray([[1, 0, 0, 2, 0, 0],\n       [3, 0, 0, 4, 0, 0]])\n&gt;&gt;&gt; komm.sampling_rate_expand([[1, 2], [3, 4]], factor=3, offset=1)\narray([[0, 1, 0, 0, 2, 0],\n       [0, 3, 0, 0, 4, 0]])\n&gt;&gt;&gt; komm.sampling_rate_expand([[1, 2], [3, 4]], factor=3, axis=0)\narray([[1, 2],\n       [0, 0],\n       [0, 0],\n       [3, 4],\n       [0, 0],\n       [0, 0]])\n</code></pre>"},{"location":"res/convolutional-codes/","title":"Tables of convolutional codes","text":""},{"location":"res/convolutional-codes/#low-rate","title":"Optimal low-rate convolutional codes","text":"<p>The table below lists optimal low-rate convolutional codes, for $n \\in \\{ 2, 3, 4 \\}$, and small values of degree $\\sigma$.</p> <p>Source: LC04, Tables 12.1 (a)\u2013(c), p. 539\u2013540.</p> $n$ $\\sigma$ $g(D) = [g_0(D) ~ \\cdots ~ g_{n-1}(D)]$ $d_\\mathrm{free}$ $2$ $1$ <code>[0o3, 0o1]</code> $3$ $2$ $2$ <code>[0o5, 0o7]</code> $5$ $2$ $3$ <code>[0o13, 0o17]</code> $6$ $2$ $4$ <code>[0o27, 0o31]</code> $7$ $2$ $5$ <code>[0o53, 0o75]</code> $8$ $2$ $6$ <code>[0o117, 0o155]</code> $10$ $2$ $7$ <code>[0o247, 0o371]</code> $10$ $2$ $8$ <code>[0o561, 0o753]</code> $12$ $2$ $9$ <code>[0o1131, 0o1537]</code> $12$ $2$ $10$ <code>[0o2473, 0o3217]</code> $14$ $2$ $11$ <code>[0o4325, 0o6747]</code> $15$ $2$ $12$ <code>[0o10627, 0o16765]</code> $16$ $2$ $13$ <code>[0o27251, 0o37363]</code> $16$ $3$ $1$ <code>[0o1, 0o3, 0o3]</code> $5$ $3$ $2$ <code>[0o5, 0o7, 0o7]</code> $8$ $3$ $3$ <code>[0o13, 0o15, 0o17]</code> $10$ $3$ $4$ <code>[0o25, 0o33, 0o37]</code> $12$ $3$ $5$ <code>[0o47, 0o53, 0o75]</code> $13$ $3$ $6$ <code>[0o117, 0o127, 0o155]</code> $15$ $3$ $7$ <code>[0o225, 0o331, 0o367]</code> $16$ $3$ $8$ <code>[0o575, 0o623, 0o727]</code> $18$ $3$ $9$ <code>[0o1167, 0o1375, 0o1545]</code> $20$ $3$ $10$ <code>[0o2325, 0o2731, 0o3747]</code> $22$ $3$ $11$ <code>[0o5745, 0o6471, 0o7553]</code> $24$ $3$ $12$ <code>[0o2371, 0o13725, 0o14733]</code> $24$ $4$ $1$ <code>[0o1, 0o1, 0o3, 0o3]</code> $6$ $4$ $2$ <code>[0o5, 0o5, 0o7, 0o7]</code> $10$ $4$ $3$ <code>[0o13, 0o13, 0o15, 0o17]</code> $13$ $4$ $4$ <code>[0o25, 0o27, 0o33, 0o37]</code> $16$ $4$ $5$ <code>[0o45, 0o53, 0o67, 0o77]</code> $18$ $4$ $6$ <code>[0o117, 0o127, 0o155, 0o171]</code> $20$ $4$ $7$ <code>[0o257, 0o311, 0o337, 0o355]</code> $22$ $4$ $8$ <code>[0o533, 0o575, 0o647, 0o711]</code> $24$ $4$ $9$ <code>[0o1173, 0o1325, 0o1467, 0o1751]</code> $27$"},{"location":"res/convolutional-codes/#high-rate","title":"Optimal high-rate convolutional codes","text":"<p>The table below lists optimal high-rate convolutional codes, for $n \\in \\{ 3, 4 \\}$, and small values of degree $\\sigma$.</p> <p>Source: LC04, Tables 12.1 (d) and (e), p. 540.</p> $n$ $\\sigma$ $h(D) = [h_0(D) ~ \\cdots ~ h_{n-1}(D)]$ $d_\\mathrm{free}$ $3$ $2$ <code>[0o7, 0o5, 0o3]</code> $3$ $3$ $3$ <code>[0o13, 0o15, 0o17]</code> $4$ $3$ $4$ <code>[0o27, 0o31, 0o23]</code> $5$ $3$ $5$ <code>[0o73, 0o57, 0o71]</code> $6$ $3$ $6$ <code>[0o121, 0o147, 0o123]</code> $7$ $3$ $7$ <code>[0o241, 0o227, 0o313]</code> $8$ $3$ $8$ <code>[0o477, 0o631, 0o555]</code> $8$ $3$ $9$ <code>[0o1327, 0o1423, 0o1051]</code> $9$ $3$ $10$ <code>[0o3013, 0o2137, 0o2621]</code> $10$ $4$ $2$ <code>[0o6, 0o7, 0o5, 0o1]</code> $3$ $4$ $3$ <code>[0o12, 0o15, 0o13, 0o11]</code> $4$ $4$ $4$ <code>[0o31, 0o37, 0o25, 0o33]</code> $4$ $4$ $5$ <code>[0o75, 0o57, 0o73, 0o47]</code> $5$ $4$ $6$ <code>[0o141, 0o133, 0o135, 0o107]</code> $6$ $4$ $7$ <code>[0o267, 0o315, 0o341, 0o211]</code> $6$ $4$ $8$ <code>[0o661, 0o733, 0o757, 0o535]</code> $7$ $4$ $9$ <code>[0o1371, 0o1157, 0o1723, 0o1475]</code> $8$"},{"location":"res/primitive-polynomials/","title":"Default primitive polynomials","text":"<p>The table below lists the default primitive polynomials of degree $k$ over $\\mathbb{F}_2$ for $k \\in [1 : 24]$. The polynomial $p(X)$ is represented as a binary number, where the leftmost bit stands for the highest degree term. For example, the polynomial $p(X) = X^3 + X + 1$ is represented as <code>0b1011</code>.</p> <p>Source: LC04, Table 2.7, p. 42.</p> Degree $k$ Primitive polynomial $p(X)$ Degree $k$ Primitive polynomial $p(X)$ $1$ <code>0b11</code> $13$ <code>0b10000000011011</code> $2$ <code>0b111</code> $14$ <code>0b100010001000011</code> $3$ <code>0b1011</code> $15$ <code>0b1000000000000011</code> $4$ <code>0b10011</code> $16$ <code>0b11010000000010001</code> $5$ <code>0b100101</code> $17$ <code>0b100000000000001001</code> $6$ <code>0b1000011</code> $18$ <code>0b1000000000010000001</code> $7$ <code>0b10001001</code> $19$ <code>0b10000000000000100111</code> $8$ <code>0b100011101</code> $20$ <code>0b100000000000000001001</code> $9$ <code>0b1000010001</code> $21$ <code>0b1000000000000000000101</code> $10$ <code>0b10000001001</code> $22$ <code>0b10000000000000000000011</code> $11$ <code>0b100000000101</code> $23$ <code>0b100000000000000000100001</code> $12$ <code>0b1000001010011</code> $24$ <code>0b1000000000000000010000111</code>"}]}